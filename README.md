- [计算机网络](#计算机网络)
  - [7层结构](#7层结构)
  - [输入网址后发生了什么](#输入网址后发生了什么)
  - [为什么DNS用udp](#为什么dns用udp)
  - [网络协议为什么分层](#网络协议为什么分层)
  - [什么是TCP/IP协议](#什么是tcpip协议)
  - [TCP的定义](#tcp的定义)
  - [TCP头部格式](#tcp头部格式)
  - [UDP头部格式](#udp头部格式)
  - [TCP粘包（没写完）](#tcp粘包没写完)
  - [TCP三次握手](#tcp三次握手)
  - [三次握手报文丢失问题](#三次握手报文丢失问题)
  - [三次握手初始序列号](#三次握手初始序列号)
    - [TCP序列号预测攻击原理（没写）](#tcp序列号预测攻击原理没写)
  - [TCP为什么是三次握手](#tcp为什么是三次握手)
  - [四次挥手过程](#四次挥手过程)
  - [为什么客户端关闭连接前要等待2MSL时间？](#为什么客户端关闭连接前要等待2msl时间)
  - [为什么挥手需要四次](#为什么挥手需要四次)
  - [挥手一定需要四次吗？](#挥手一定需要四次吗)
  - [TIME_WAIT状态（没写）](#time_wait状态没写)
  - [SYN Cookies](#syn-cookies)
  - [SYN Flood](#syn-flood)
  - [应对DDoS攻击的方式](#应对ddos攻击的方式)
  - [服务器主动中断](#服务器主动中断)
  - [为什么还需要快速重传机制](#为什么还需要快速重传机制)
  - [拥塞控制](#拥塞控制)
  - [tcp慢开始，为什么指数级别还叫慢开始](#tcp慢开始为什么指数级别还叫慢开始)
  - [流量控制（没写）](#流量控制没写)
  - [TCP快速建立连接](#tcp快速建立连接)
  - [TCP和UDP的区别](#tcp和udp的区别)
  - [TCP确保传输可靠性的方式](#tcp确保传输可靠性的方式)
  - [有一个 IP 的服务器监听了一个端口，它的 TCP 的最大连接数是多少？](#有一个-ip-的服务器监听了一个端口它的-tcp-的最大连接数是多少)
  - [TCP半连接和全连接队列（这个没弄懂）](#tcp半连接和全连接队列这个没弄懂)
  - [TCP Socket编程](#tcp-socket编程)
  - [TCP，UDP数据包大小的限制](#tcpudp数据包大小的限制)
  - [BBR（这个还需要了解）](#bbr这个还需要了解)
  - [快速重传解决的问题](#快速重传解决的问题)
  - [糊涂窗口综合症](#糊涂窗口综合症)
  - [tcp异常(没写)](#tcp异常没写)
  - [http的理解](#http的理解)
  - [http优缺点](#http优缺点)
  - [HTTP状态码](#http状态码)
  - [HTTP与HTTPS有哪些区别](#http与https有哪些区别)
  - [https过程(有两篇文章还没看)](#https过程有两篇文章还没看)
  - [怎么保证证书有效](#怎么保证证书有效)
        - [明文数据和数字签名组成证书，传递给客户端。](#明文数据和数字签名组成证书传递给客户端)
  - [Http格式](#http格式)
  - [HTTP中Get与Post的区别](#http中get与post的区别)
  - [HTTP1.0,HTTP1.1,HTTP2.0,HTTP3.0的区别与联系](#http10http11http20http30的区别与联系)
    - [HTTP/1.1](#http11)
    - [HTTP/2](#http2)
  - [http劫持(还没看)](#http劫持还没看)
  - [HTTP缓存机制及原理](#http缓存机制及原理)
  - [HTTP响应代码](#http响应代码)
  - [MTU最大传输单元](#mtu最大传输单元)
  - [正向代理和反向代理的区别](#正向代理和反向代理的区别)
  - [负载均衡算法](#负载均衡算法)
  - [ping工作原理](#ping工作原理)
  - [请求转发和重定向的区别](#请求转发和重定向的区别)
  - [NAT](#nat)
  - [线程同步机制](#线程同步机制)
- [Java](#java)
  - [JRE和JDK的区别](#jre和jdk的区别)
  - [基本数据类型](#基本数据类型)
  - [Math.round(11.5) 等于多少?Math.round(-11.5)等于多少](#mathround115-等于多少mathround-115等于多少)
  - [访问修饰符](#访问修饰符)
  - [final finally finalize区别](#final-finally-finalize区别)
  - [面向对象的三大特性](#面向对象的三大特性)
  - [面向对象的五大基本原则](#面向对象的五大基本原则)
  - [多态的必要条件](#多态的必要条件)
  - [方法多态的实现](#方法多态的实现)
  - [重载与重写的区别](#重载与重写的区别)
  - [类的实例化顺序](#类的实例化顺序)
  - [Java创建对象的5种方式](#java创建对象的5种方式)
  - [抽象类和接口的区别](#抽象类和接口的区别)
  - [内部类](#内部类)
  - [值传递与引用传递](#值传递与引用传递)
  - [深拷贝和浅拷贝的区别](#深拷贝和浅拷贝的区别)
  - [==和equals的区别](#和equals的区别)
  - [hashCode（）与equals（）的相关规定](#hashcode与equals的相关规定)
  - [Integer a= 127 与 Integer b = 127相等吗](#integer-a-127-与-integer-b--127相等吗)
  - [关于包装类](#关于包装类)
  - [Object类方法](#object类方法)
  - [String有关](#string有关)
    - [结构演变](#结构演变)
    - [创建方式](#创建方式)
    - [不可变性](#不可变性)
    - [拼接字符串的优化](#拼接字符串的优化)
    - [常用方法](#常用方法)
    - [JDK6和JDK7中的substring()方法的区别](#jdk6和jdk7中的substring方法的区别)
    - [String.valueOf和Integer.toString的区别](#stringvalueof和integertostring的区别)
    - [intern()方法](#intern方法)
    - [字符串常量池](#字符串常量池)
  - [Class常量池](#class常量池)
  - [运行时常量池](#运行时常量池)
    - [运行时常量池,Class常量池,字符串常量池的区别和联系](#运行时常量池class常量池字符串常量池的区别和联系)
  - [关键字](#关键字)
  - [异常](#异常)
    - [try-catch-finally-return执行顺序](#try-catch-finally-return执行顺序)
  - [反射](#反射)
  - [动态代理（没看懂）](#动态代理没看懂)
  - [CGLIB和JDK](#cglib和jdk)
  - [BIO,NIO,AIO有什么区别？](#bionioaio有什么区别)
  - [Java8新特性](#java8新特性)
    - [接口内允许添加默认实现的方法](#接口内允许添加默认实现的方法)
    - [Lambda表达式](#lambda表达式)
    - [内置函数式接口](#内置函数式接口)
    - [Optional](#optional)
    - [Stream流](#stream流)
  - [集合](#集合)
    - [集合框架底层数据结构](#集合框架底层数据结构)
    - [fail-fast机制](#fail-fast机制)
    - [comparable 和 comparator 的区别？](#comparable-和-comparator-的区别)
    - [SynchronizedList和Vector的区别](#synchronizedlist和vector的区别)
    - [List和Set的区别](#list和set的区别)
    - [ArrayList的优缺点](#arraylist的优缺点)
    - [Arrays.asList为什么不能增加或修改](#arraysaslist为什么不能增加或修改)
    - [ArrayList和LinkedList的区别](#arraylist和linkedlist的区别)
    - [ArrayList和Vector的区别](#arraylist和vector的区别)
    - [为什么ArrayList的elementData要加上transient修饰](#为什么arraylist的elementdata要加上transient修饰)
    - [HashSet的实现原理](#hashset的实现原理)
    - [Set如何检查重复](#set如何检查重复)
    - [hashmap1.7和1.8的区别](#hashmap17和18的区别)
    - [为什么扩容的时候一定必须是2的多少次幂](#为什么扩容的时候一定必须是2的多少次幂)
    - [为什么JDK1.7的时候是先进行扩容后进行插入，而JDK1.8的时候是先插入后扩容](#为什么jdk17的时候是先进行扩容后进行插入而jdk18的时候是先插入后扩容)
    - [为什么在JDK1.8中进行hashmap优化时，把链表转化为红黑树的阈值是8，而不是7或20呢？](#为什么在jdk18中进行hashmap优化时把链表转化为红黑树的阈值是8而不是7或20呢)
    - [哈希表如何解决Hash冲突](#哈希表如何解决hash冲突)
    - [为什么hashmap具备下述特点：键-值(key-value)都允许为空，线程不安全，不保证有序，存储位置随时间变化](#为什么hashmap具备下述特点键-值key-value都允许为空线程不安全不保证有序存储位置随时间变化)
    - [为什么HashMap中String,Integer这样的包装类适合作为key键](#为什么hashmap中stringinteger这样的包装类适合作为key键)
    - [HashMap中的key若Object类型，则需实现哪些方法?](#hashmap中的key若object类型则需实现哪些方法)
    - [Hashmap1.7和1.8扩容机制对比](#hashmap17和18扩容机制对比)
    - [hashmap put方法流程](#hashmap-put方法流程)
    - [为什么头插法会产生死循环](#为什么头插法会产生死循环)
    - [HashMap与HashTable的区别](#hashmap与hashtable的区别)
    - [TreeMap](#treemap)
    - [如何决定使用 HashMap 还是 TreeMap？](#如何决定使用-hashmap-还是-treemap)
    - [HashMap 和 ConcurrentHashMap 的区别](#hashmap-和-concurrenthashmap-的区别)
    - [ConcurrentHashMap 基本结构](#concurrenthashmap-基本结构)
    - [ConcurrentHashMap put方法流程](#concurrenthashmap-put方法流程)
    - [ConcurrentHashMap 扩容流程（还没写）](#concurrenthashmap-扩容流程还没写)
    - [ConcurrentHashMap为什么不能存值为null的value（主要学习作者的学习方式）](#concurrenthashmap为什么不能存值为null的value主要学习作者的学习方式)
  - [阻塞队列(BlockingQueue）](#阻塞队列blockingqueue)
    - [LinkedBlockingQueue和ArrayBlockingQueue（没写完）](#linkedblockingqueue和arrayblockingqueue没写完)
  - [多线程](#多线程)
    - [生产者消费者模式的实现（还没写）](#生产者消费者模式的实现还没写)
    - [线程和进程的区别](#线程和进程的区别)
    - [创建线程的四种方式](#创建线程的四种方式)
    - [上下文切换](#上下文切换)
    - [线程状态转换关系](#线程状态转换关系)
    - [sleep()和wait()的区别](#sleep和wait的区别)
    - [sleep()和yield()的区别](#sleep和yield的区别)
    - [形成死锁的四个条件](#形成死锁的四个条件)
    - [如何避免线程死锁](#如何避免线程死锁)
    - [Java中用到的线程调度算法](#java中用到的线程调度算法)
    - [终止线程运行的情况](#终止线程运行的情况)
    - [重排序实际执行的指令步骤](#重排序实际执行的指令步骤)
    - [as-if-serial和happens-before规则的区别](#as-if-serial和happens-before规则的区别)
    - [Java内存模型（JMM）](#java内存模型jmm)
    - [volatile](#volatile)
      - [为什么其他线程能感知到变量更新?（原理）](#为什么其他线程能感知到变量更新原理)
      - [volatile如何实现禁止指令重排](#volatile如何实现禁止指令重排)
    - [多线程8锁](#多线程8锁)
      - [公平锁/非公平锁](#公平锁非公平锁)
      - [可重入锁](#可重入锁)
      - [独享锁/共享锁](#独享锁共享锁)
      - [互斥锁/读写锁](#互斥锁读写锁)
      - [乐观锁/悲观锁](#乐观锁悲观锁)
      - [分段锁](#分段锁)
      - [偏向锁/轻量级锁/重量级锁](#偏向锁轻量级锁重量级锁)
      - [自旋锁](#自旋锁)
    - [锁机制（b站那个视频没总结完）](#锁机制b站那个视频没总结完)
    - [synchronized和Lock的区别](#synchronized和lock的区别)
    - [synchronized和ReentrantLock的区别](#synchronized和reentrantlock的区别)
    - [synchronized和volatile的区别](#synchronized和volatile的区别)
    - [为什么synchronized无法禁止指令重排，却能保证有序性？](#为什么synchronized无法禁止指令重排却能保证有序性)
    - [CAS](#cas)
    - [CAS产生的问题](#cas产生的问题)
    - [线程池](#线程池)
      - [参数](#参数)
      - [四种拒绝策略](#四种拒绝策略)
      - [线程池触发拒绝策略的时机](#线程池触发拒绝策略的时机)
      - [四类不同的线程池](#四类不同的线程池)
      - [工作流程](#工作流程)
      - [如何实现线程复用](#如何实现线程复用)
    - [CountDownLatch,CyclicBarrier,Semaphore](#countdownlatchcyclicbarriersemaphore)
    - [AQS（没写完）](#aqs没写完)
      - [获取锁](#获取锁)
    - [JDBC流程](#jdbc流程)
- [JVM](#jvm)
  - [四种引用(没写完)](#四种引用没写完)
    - [虚引用](#虚引用)
    - [软引用](#软引用)
    - [弱引用](#弱引用)
    - [强引用](#强引用)
  - [finalize()方法什么时候被调用？](#finalize方法什么时候被调用)
  - [JVM的结构](#jvm的结构)
  - [运行时数据区](#运行时数据区)
    - [虚拟机栈](#虚拟机栈)
    - [程序计数器](#程序计数器)
  - [JVM如何执行方法调用](#jvm如何执行方法调用)
  - [TLAB分配](#tlab分配)
  - [PLAB](#plab)
  - [为什么用元空间](#为什么用元空间)
  - [类加载过程](#类加载过程)
  - [判断对象是否可以被回收](#判断对象是否可以被回收)
  - [可以作为GC Roots的对象](#可以作为gc-roots的对象)
  - [对象从年轻代进入老年代的时机](#对象从年轻代进入老年代的时机)
  - [触发Full GC的时机](#触发full-gc的时机)
  - [Minor GC的触发条件](#minor-gc的触发条件)
  - [“无用的类”的判断条件](#无用的类的判断条件)
  - [如何判断一个常量是废弃常量](#如何判断一个常量是废弃常量)
  - [垃圾回收算法](#垃圾回收算法)
    - [标记清除算法](#标记清除算法)
    - [复制算法](#复制算法)
    - [标记整理算法](#标记整理算法)
  - [垃圾收集器（还没写）](#垃圾收集器还没写)
  - [双亲委派机制](#双亲委派机制)
  - [全盘负责](#全盘负责)
  - [并发标记](#并发标记)
  - [CMS回收器的回收流程](#cms回收器的回收流程)
  - [G1回收器的回收流程](#g1回收器的回收流程)
  - [G1收集器原理](#g1收集器原理)
  - [常量池](#常量池)
  - [保守和非保守GC](#保守和非保守gc)
- [Spring](#spring)
  - [过滤器和拦截器的区别（这个算是做的笔记）](#过滤器和拦截器的区别这个算是做的笔记)
  - [IOC容器的组成部分](#ioc容器的组成部分)
  - [IOC容器的初始化流程(需要通俗语言)](#ioc容器的初始化流程需要通俗语言)
  - [IOC容器的刷新流程](#ioc容器的刷新流程)
  - [Spring读取自定义xml文件解析](#spring读取自定义xml文件解析)
    - [refresh()方法](#refresh方法)
- [MySQL](#mysql)
  - [储存格式](#储存格式)
  - [MySQL的查询流程](#mysql的查询流程)
  - [MySQLr如何建立连接](#mysqlr如何建立连接)
  - [MyISAM和InnoDB](#myisam和innodb)
  - [MyISAM的应用场景](#myisam的应用场景)
  - [InnoDB的4大特性](#innodb的4大特性)
  - [二次写](#二次写)
  - [哪个存储引擎执行 select count(*) 更快，为什么?](#哪个存储引擎执行-select-count-更快为什么)
  - [char和varchar的区别](#char和varchar的区别)
  - [三范式](#三范式)
  - [百万级别或以上的数据如何删除](#百万级别或以上的数据如何删除)
  - [为什么InnoDB要有主键](#为什么innodb要有主键)
  - [count(*) 和 count(1)和count(列名)区别](#count-和-count1和count列名区别)
  - [MySQL中in和exists的区别](#mysql中in和exists的区别)
  - [UNION和UNION ALL的区别](#union和union-all的区别)
  - [SQL执行顺序](#sql执行顺序)
  - [关于索引的sql语句](#关于索引的sql语句)
  - [索引分类](#索引分类)
  - [索引为什么选择B+树](#索引为什么选择b树)
  - [B-Tree的性质](#b-tree的性质)
  - [B+Tree的性质](#btree的性质)
  - [B+Tree索引和Hash索引区别](#btree索引和hash索引区别)
  - [为什么不建议使用订单号作为主键?](#为什么不建议使用订单号作为主键)
  - [一棵B+树可以存放多少行数据](#一棵b树可以存放多少行数据)
  - [聚集索引与非聚集索引的区别](#聚集索引与非聚集索引的区别)
  - [MyISAM主键索引和辅助索引的结构](#myisam主键索引和辅助索引的结构)
  - [InnoDB如何实现聚集（聚簇）索引](#innodb如何实现聚集聚簇索引)
  - [回表查询](#回表查询)
  - [full-text全文索引](#full-text全文索引)
  - [与索引有关的SQL语句](#与索引有关的sql语句)
  - [哪些情况需要创建索引](#哪些情况需要创建索引)
  - [哪些情况不要创建索引](#哪些情况不要创建索引)
  - [索引覆盖](#索引覆盖)
  - [索引不生效 前缀索引](#索引不生效-前缀索引)
  - [索引设计准则:三星索引](#索引设计准则三星索引)
  - [事务的基本要素](#事务的基本要素)
  - [并发事务处理带来的问题](#并发事务处理带来的问题)
  - [事务隔离级别](#事务隔离级别)
  - [mvcc实现原理](#mvcc实现原理)
  - [REPEATABLE READ（可重读）隔离级别下MVCC如何工作](#repeatable-read可重读隔离级别下mvcc如何工作)
  - [MVCC中的ReadView(可读视图)](#mvcc中的readview可读视图)
  - [MVCC和next-key lock为什么不能完全解决幻读](#mvcc和next-key-lock为什么不能完全解决幻读)
  - [MySQL中有哪几种锁](#mysql中有哪几种锁)
  - [为什么没有意向锁的话，表锁和行锁不能共存？](#为什么没有意向锁的话表锁和行锁不能共存)
  - [意向锁是如何让表锁和行锁共存的？](#意向锁是如何让表锁和行锁共存的)
  - [意向锁是表锁还是行锁](#意向锁是表锁还是行锁)
  - [MySQL中InnoDB引擎的行锁是怎么实现的](#mysql中innodb引擎的行锁是怎么实现的)
  - [select for update的含义](#select-for-update的含义)
  - [获取InnoDB行锁争用情况](#获取innodb行锁争用情况)
  - [InnoDB存储引擎中不同SQL在不同隔离级别下锁的比较](#innodb存储引擎中不同sql在不同隔离级别下锁的比较)
  - [数据库死锁怎么处理](#数据库死锁怎么处理)
  - [如何避免死锁](#如何避免死锁)
  - [数据恢复策略](#数据恢复策略)
  - [日志](#日志)
    - [bin log和redo log的区别](#bin-log和redo-log的区别)
    - [bin log](#bin-log)
    - [undo log](#undo-log)
      - [undo log的写入时机](#undo-log的写入时机)
      - [undo log的存储位置](#undo-log的存储位置)
    - [redo log 重做日志](#redo-log-重做日志)
      - [什么时候写入?](#什么时候写入)
      - [整体流程](#整体流程)
    - [binlog和redo log写入的细节](#binlog和redo-log写入的细节)
    - [为什么有了redo log还需要bin log](#为什么有了redo-log还需要bin-log)
  - [排序](#排序)
  - [MySQL中有一条SQL比较慢](#mysql中有一条sql比较慢)
  - [explain详解（没写）](#explain详解没写)
  - [主从复制的基本原理](#主从复制的基本原理)
  - [MySQL分区分库分表](#mysql分区分库分表)
  - [分布式数据库数据一致性原理说明与实现（没写）](#分布式数据库数据一致性原理说明与实现没写)
  - [Join算法原理（没写）](#join算法原理没写)
  - [SQL truncate,delete与drop区别(没写)](#sql-truncatedelete与drop区别没写)
  - [预编译语句](#预编译语句)
- [Netty(学习笔记)](#netty学习笔记)
  - [零拷贝](#零拷贝)
    - [传统IO模型](#传统io模型)
    - [减少内核空间到用户空间的拷贝次数](#减少内核空间到用户空间的拷贝次数)
      - [mmap系统调用](#mmap系统调用)
      - [sendfile系统调用](#sendfile系统调用)
      - [splice系统调用](#splice系统调用)
    - [优化Linux页缓存和用户进程的缓存区之间的传输过程](#优化linux页缓存和用户进程的缓存区之间的传输过程)
  - [Reactor模式](#reactor模式)
    - [单Reactor单线程](#单reactor单线程)
    - [单Reactor多线程](#单reactor多线程)
    - [多Reactor多进程/线程](#多reactor多进程线程)
    - [Netty中的零拷贝](#netty中的零拷贝)
  - [组件](#组件)
  - [主要流程](#主要流程)
  - [WebSocket](#websocket)
  - [RPC框架](#rpc框架)
- [Dubbo](#dubbo)
- [设计模式](#设计模式)
  - [单例模式](#单例模式)
- [操作系统(Linux)](#操作系统linux)
  - [cpu负载和cpu利用率的区别](#cpu负载和cpu利用率的区别)
- [ElasticSearch](#elasticsearch)
  - [全文搜索](#全文搜索)
  - [倒排索引](#倒排索引)
  - [核心概念](#核心概念)
    - [Index](#index)
    - [Document&field](#documentfield)
    - [elasticsearch核心概念vs数据库核心概念](#elasticsearch核心概念vs数据库核心概念)
- [算法题](#算法题)
  - [只出现一次的数字(136)](#只出现一次的数字136)
  - [阶乘后的零(172)](#阶乘后的零172)
- [还没看完的文章](#还没看完的文章)
  - [MySQL](#mysql-1)

# 计算机网络

## 7层结构

自底向上分别是:

- 物理层：负责透明传输比特流
- 数据链路层：负责将网络层传下来的IP数据报组装成帧，检测和校正物理层传输介质上产生的传输差错，具体的有PPP，STP
- 网络层：负责为不同主机提供通信服务，网络层的分组数据从源端传到目的端，具体协议有IP,ARP,RARP,ICMP,IGMP等
- 传输层：负责为不同主机中的进程提供通信服务，具体协议有TCP，UDP
- 会话层：允许不同主机上各进程之间的会话
- 表示层：处理在两个通信系统中交换信息的表示方式
- 应用层：为特殊类型的网络应用提供OSI环境手段

## 输入网址后发生了什么

1.解析URL，确定Web服务器和文件名

2.查询服务器域名对应的IP地址：首先查找浏览器上缓存，没有再查找.host文件的缓存，如果没有会发送一个DNS请求给本地DNS域名服务器，本地域名服务器收到请求后如果缓存中的表格能找到则直接返回IP地址，如果没有，则去问根域名服务器。根DNS收到本地DNS的请求后，发现后置是.com。根域名服务器返回本地域名服务器.com顶级域名服务器的地址，本地DNS再去问顶级域名服务器，顶级域名服务器地址告诉本地DNS权威DNS服务器地址，本地DNS再去问就拿到IP地址了。

3.协议栈进行TCP三次握手。TCP模块在执行各阶段操作时，都需要委托IP模块将数据封装成网络包发送给通信对象，接下来网络包在IP头部的前面加上MAC头部（网卡驱动从IP模块获取到包后，将其复制到网卡内的缓存区中，并加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列），网卡将数字信号转换为电信号进行传输，接下来包通过交换机原样转发到目的地，之后到达路由器，并在此被转发到下一个路由器或目标设备。

4.数据包抵达服务器之后，服务器会先查看数据包的MAC头部，查看是否和服务器自己的MAC地址符合，接着继续查看数据包的IP头，发现IP地址符合，根据IP头中的协议项，知道自己上层是TCP协议，接下来查看TCP头部中的序列号，如果是想要的，就放入缓存中然后返回一个ACK，如果不是就丢弃。服务器再根据TCP头部中的端口号，将包发给HTTP进程，最后浏览器获得数据后进行渲染。

## 为什么DNS用udp

https://www.zhihu.com/question/310145373

采用TCP传输，则域名解析时间为：

DNS域名解析时间 = TCP连接时间 + DNS交易时间

采用UDP传输，则域名解析时间为：

DNS域名解析时间 = DNS交易时间

很显然，采用UDP传输，DNS域名解析时间更小。

在很多时候，用户在访问一些冷门网站时，由于DNS服务器没有冷门网站的解析缓存，需要到域名根服务器、一级域名服务器、二级域名服务器迭代查询，直到查询到冷门网站的权威服务器，这中间可能涉及到多次的查询。

如果使用TCP传输，多几次查询，就多几次TCP连接时间，这多出来的时间不容小觑

## 网络协议为什么分层

(1)各层之间是独立的。上一层的工作如何进行并不影响下一层的工作，这样我们在进行每一层的工作[设计](https://www.applysquare.com/fos-cn/design/)时只要保证接口不变可以随意调整层内的工作方式。

(2)灵活性好。当任何一层发生变化时，只要层间接口关系保持不变，则在这层以上或以下各层均不受影响。当某一层出现技术革新或者某一层在工作中出现问题时不会连累到其他层的工作，排除问题时也只需要考虑这一层单独的问题即可。

(3)结构上可分割开。各层都可以采用最合适的技术来实现。技术的发展往往是不对称的，层次化的划分有效避免了木桶效应，不会因为某一方面技术的不完善而影响整体的工作效率。

(4)易于实现和维护。这种结构使得实现和调试一个庞大又复杂的系统变得易于处理，因为整个的系统已被分解为若干个相对独立的子系统。进行调试和维护时，可以对每一层进行单独的调试，避免了出现找不到问题、解决错问题的情况。

(5)能促进标准化工作。因为每一层的功能及其所提供的服务都已有了精确的说明。标准化的好处就是可以随意替换其中的某几层，对于使用和科研来说十分方便。

## 什么是TCP/IP协议

TCP/IP协议是指一个由[FTP](https://baike.baidu.com/item/FTP/13839)、[SMTP](https://baike.baidu.com/item/SMTP/175887)、TCP、[UDP](https://baike.baidu.com/item/UDP/571511)、IP等协议构成的协议簇。只是因为在TCP/IP协议中TCP协议和IP协议最具代表性，所以被称为TCP/IP协议。TCP/IP传输协议，即传输控制/网络协议，也叫作网络通讯协议。TCP/IP传输协议是严格来说是一个四层的体系结构，应用层、传输层、网络层和数据链路层都包含其中。

## TCP的定义

TCP协议是面向连接的、可靠的、基于字节流的传输层通信协议。

面向连接：使用TCP传输数据前，必须先建立TCP连接；传输完成后再释放连接。

全双工通信:建立TCP连接后，通信双方都能发送数据

可靠：通过TCP连接传送的数据，不丢失，无差错，不重复&&按序到达

面向字节流：数据以流的形式进行传输，TCP一次传输的报文长度有限制，若太大则需分块，分次传输，但由于TCP连接的可靠性，接收方可按顺序接收数据块&重新组成分块之前的数据流，所以TCP看起来就像直接互相传输字节流一样。

## TCP头部格式

主要使用的几个选项：

SYN(synchronous)： 发送/同步标志，用来建立连接，和下面的第二个标志位ACK搭配使用。连接开始时，SYN=1，ACK=0，代表连接开始但是未获得响应。当连接被响应的时候，标志位会发生变化，其中ACK会置为1，代表确认收到连接请求，此时的标志位变成了 SYN=1，ACK=1。

ACK(acknowledgement)：确认标志，表示确认收到请求。

PSH(push) ：表示推送操作，就是指数据包到达接收端以后，不对其进行队列处理，而是尽可能的将数据交给应用程序处理；

FIN(finish)：结束标志，用于结束一个TCP会话；

RST(reset)：重置复位标志，用于复位对应的TCP连接。

URG(urgent)：紧急标志，用于保证TCP连接不被中断，并且督促中间层设备尽快处理。

## UDP头部格式

- 16位源端口号
- 16位目标端口号
- 16位包长度
- 16位校验和
- 数据

## TCP粘包（没写完）

TCP 是一个面向字节流的协议，它是性质是流式的，所以它并没有分段。就像水流一样，你没法知道什么时候开始，什么时候结束。

![](https://user-gold-cdn.xitu.io/2018/8/6/1650c8b818748287?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

接收到的是一个报文，它是由发送的两个报文组成的，这样称为粘包。

解决方式：

- 在报文末尾增加换行符表明一条完整的消息，这样在接收端可以根据这个换行符来判断消息是否完整。
- 将消息分为消息头、消息体。可以在消息头中声明消息的长度，根据这个长度来获取报文（比如 808 协议）。
- 规定好报文长度，不足的空位补齐，取的时候按照长度截取即可。

## TCP三次握手

建立TCP连接前：TCP客户端，服务端都处于关闭状态（CLOSED），直到客户端主动打开连接，服务端才被动打开连接（处于监听状态LISTEN）,等待接收客户端的请求。

第一次握手时，客户端向服务器发送1个连接请求的报文段，此报文段同步标志位SYN=1，随机选择一个起始序号seq=x，不携带数据，客户端进入同步已发送状态（SYN_SEND），等待服务器确认。

第二次握手时，服务器收到请求连接的报文段后，若同意建立连接，则向客户端发送连接确认的报文段，该报文段的同步标志位SYN=1，确认标记位ACK=1，随机选择一个起始序号seq=y，确认号字段ack=x+1，不携带数据，服务器进入同步已接收状态（SYN_RCVD）

第三次握手，客户端收到确认报文段后，向服务器再次发出连接确认报文段，该报文段的确认标记位ACK=1，序号seq=x+1，确认号字段ack=y+1，可以携带数据，客户端和服务器端都进入已创建状态(ESTABLISHED)

## 三次握手报文丢失问题

第一次握手丢失：

每次超时时间RTO是指数(翻倍)上涨的，当超过最大重传次数后，客户端不再发送SYN包。在Linux中，第一次握手的SYN超时重传次数，是如下内核参数指定的:

`cat /proc/sys/net/ipv4/tcp_syn_retries`,默认值为5，也就是SYN最大重传次数是5次。

第二次握手丢失：

当第二次握手的SYN，ACK丢包时，客户端会超时重发SYN包，服务端也会超时重传SYN，ACK包。

第三次握手：

在建立TCP连接时，如果第三次握手的ACK，服务端无法收到，则服务端就会短暂处于`SYN_RECV`状态，而客户端会处于`ESTABLISHED	`状态.

由于服务端一直收不到TCP第三次握手的ACK，则会一直重传SYN,ACK包，直到重传次数超过`tcp_synack_retries`值（默认值5次）后,服务端就会断开TCP连接。

而客户端则会有两种情况:

- 如果客户端没发送数据包,一直处于`ESTABLISHED`状态，然后经过2小时11分15秒才可以发现一个死亡连接，于是客户端连接就会断开连接。
- 如果客户端发送了数据包，一直没有收到服务端对该数据包的确认报文，则会一直重传该数据包，直到重传次数超过`tcp_retries2`值（默认值15次）后，客户端就会断开TCP连接

## 三次握手初始序列号

大约每4微秒增加1，为了防止序列号猜测攻击

### TCP序列号预测攻击原理（没写）

## TCP为什么是三次握手

主要有三方面的原因：
1.避免历史连接：

客户端连续发送多次SYN建立连接的报文，在网络拥堵等情况下：一个旧SYN报文比最新的SYN报文早到达了客户端,此时服务端就会回一个`SYN+ACK`报文给客户端，客户端收到后可以根据自身的上下文，判断这是否是一个历史连接（序列号过期或超时）。如果是历史连接，则第三次握手发送的报文是RST报文，以此中止历史连接，如果不是历史连接，则第三次发送的报文是`ACK`报文，通信双方就会成功建立连接。如果是两次握手连接，就不能判断当前连接是否是历史连接。

2.同步双方初始序列号：

当客户端发送携带「初始序列号」的 `SYN` 报文的时候，需要服务端回一个 `ACK` 应答报文，表示客户端的 SYN 报文已被服务端成功接收，那当服务端发送「初始序列号」给客户端的时候，依然也要得到客户端的应答回应，**这样一来一回，才能确保双方的初始序列号能被可靠的同步。**

3.避免资源浪费：

如果客户端的 `SYN` 阻塞了，重复发送多次 `SYN` 报文，那么服务器在收到请求后就会**建立多个冗余的无效链接，造成不必要的资源浪费。**

「四次握手」：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。

## 四次挥手过程

释放TCP连接前，TCP客户端和服务器都处于已创建状态(ESTABLISHED)直到客户端主动关闭TCP连接。

第一次挥手时，客户端向服务器发送1个连接释放的报文段，该报文段终止控制位FIN=1，报文段序号为前面传送数据最后1个字节的序号加1，可以携带数据，客户端进入终止等待1状态（FIN-WAIT-1），等待服务器确认。

第二次挥手时，服务器收到连接释放报文段后，则向客户端发回连接释放确认的报文段，该报文段确认标记位ACK=1，报文段序号seq为前面传送数据最后一个字节的序号加1：seq=v，确认号字段设为ack=u+1，此时服务器进入关闭等待状态（CLOSE-WAIT），客户端收到服务器的确认后，进入终止等待2状态(FIN-WAIT-2),等待服务器发出释放连接请求，至此，客户端到服务器的TCP连接已断开，即TCP连接处于半关闭状态，即客户端到服务器的连接断开，服务器到客户端的连接未断开。

第三次挥手时，若服务器已无数据要向客户端发送，则发出释放连接的报文段，该报文段终止控制位FIN=1，确认标记位ACK=1，报文段序号seq=w，重复上次已发送的确认号字段ack=u+1，可以携带数据，服务端进入最后确认状态（LAST-ACK）

第四次挥手时，客户端收到连接释放报文段后，则向服务器发回连接释放确认的报文段，该报文段确认标记位ACK=1，报文段序号seq=u+1，确认号字段ack=w+1，可以携带数据（？），客户端进入时间等待状态（TIME_WAIT），服务器进入关闭状态（CLOSED），此时TCP连接还未释放，须经过时间等待计时器设置的时间2MSL后，客户端才进入连接关闭状态(CLOSED)

[关于三次握手和四次挥手，面试官想听到怎样的回答？ - 车小胖的回答 - 知乎](https://www.zhihu.com/question/271701044/answer/398114686)

## 为什么客户端关闭连接前要等待2MSL时间？

原因1：为了保证客户端发送的最后1个连接释放确认报文能到达服务器，从而使得服务器能正常释放连接。

原因2：防止上文提到的早已失效的连接请求报文出现在本连接中，客户端发送了最后1个连接释放请求确认报文后，再经过2MSL时间，则可使本连接持续时间内所产生的所有报文段都从网络中消失，即在下一个新的连接中就不会出现早已失效的连接请求报文。

## 为什么挥手需要四次

- 关闭连接时，客户端向服务端发送 `FIN` 时，仅仅表示客户端不再发送数据了但是还能接收数据。
- 服务器收到客户端的`FIN`报文时，先回一个`ACK`应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送`FIN`报文给客户端来表示同意现在关闭连接。

从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的`ACK`和`FIN`一般都会分开发送，从而比三次握手导致多了一次。

## 挥手一定需要四次吗？

假设client已经没有数据发送给server了，所以它发送FIN给server表明自己数据发完了，不再发了，如果这时候server还是有数据要发送给client,那么它就是先回复ack，然后继续发送数据。

等server数据发送完了之后再向client发送FIN表明它也发完了，然后等client的ACK这种情况下就会有四次挥手。

那么假设client发送FIN给server的时候server也没数据给client,那么server就可以将ACK和它的FIN一起发给client,然后等待client的ACK，这样不就三次挥手了?

## TIME_WAIT状态（没写）

## SYN Cookies

是用来防范SYN Flood攻击的一种手段。

SYN Flood攻击是指攻击者在短时间内发送大量的TCP SYN包给受害者。受害者(服务器)为每个TCP SYN包分配一个特定的数据区，只要这些SYN包具有不同的源地址(攻击者很容易伪造)。这将给TCP服务器造成很大的系统负担，最终导致系统不能正常工作。

SYN Cookie的原理是在TCP服务器接收到TCP SYN包并返回TCP SYN+ACK包时，不分配一个专门的数据区，而是根据这个SYN包计算出一个cookie值。这个cookie作为将要返回的SYN ACK包的初始序列号。当客户端返回一个ACK包时，根据包头信息计算cookie，与返回的确认序列号（初始序列号+1）进行对比，如果相同，则是一个正常连接，然后分配资源，建立连接。

cookie的计算:服务器收到一个SYN包,计算一个消息摘要mac.

## SYN Flood

SYN Flood（半开放攻击）是一种拒绝服务（DDoS）攻击，其目的是通过消耗所有可用的服务器资源使服务器不可用于合法流量。通过重复发送初始连接请求（SYN）数据包，攻击者能够压倒目标服务器机器上的所有可用端口，导致目标设备根本不响应合法流量。

**工作原理**:

攻击者向目标服务器发送大量SYN数据包，通常会使用欺骗性的IP地址.然后,服务器响应每个连接请求，并留下开放端口准备好接收响应。

当服务器等待从未到达的最终ACK数据包时，攻击者继续发送更多的SYN数据包。每个新的SYN数据包的到达导致服务器暂时维持新的开放端口连接一段时间，一旦所有可用端口被使用，服务器就无法正常工作。

**解决办法**:

- 在服务器上降低等待syn后续ack的timeout时间,避免消耗资源进行无用的等待.
- 服务器上可以开启syn cookie或类似的特性,在收到syn之后并不立即分配半开连接资源而是等到收到正确的cookie ack之后再分配资源
- 在服务器前端的四层设备上启用类似syn proxy的功能，等到确认tcp正常建链后再转给服务器处理

[如何改进TCP，甚至重新设计TCP/IP，才可以完全杜绝SYN Flood等安全问题？ - 小麦1212的回答 - 知乎](https://www.zhihu.com/question/40909733/answer/137556963)

## 应对DDoS攻击的方式

**高防服务器**:

高防服务器主要是指能独立硬防御 50Gbps 以上的服务器，能够帮助网站拒绝服务攻击，定期扫描网络主节点等

**黑名单**:

设置ip黑名单

**DDoS清洗**:

DDoS清洗会对用户请求数据进行实时监控，及时发现DOS攻击等异常流量，在不影响正常业务开展的情况下清洗掉这些异常流量。

**CDN加速**：

CDN服务将网站访问流量分配到了各个节点中，这样一方面隐藏网站的真实 IP，另一方面即使遭遇DDoS攻击，也可以将流量分散到各个节点中，防止源站崩溃。

## 服务器主动中断

当服务器进程被终止时，会关闭其打开的所有文件描述符，此时就会向客户端发送一个`FIN`的报文，客户端则响应一个`ACK`报文，但是这样只完成了四次挥手的前两次挥手，也就是说这样只实现了半关闭，客户端仍然可以向服务器写入数据。

但是当客户端向服务器写入数据时，由于服务器端的套接字进程已经终止，此时连接的状态已经异常了，所以服务端进程不会向客户端发送ACK报文，而是发送了一个RST报文请求将处于异常状态的连接复位， **如果客户端此时还要向服务端发送数据，将诱发服务端TCP向服务端发送SIGPIPE信号，因为向接收到RST的套接口写数据都会收到此信号.** 所以说，这就是为什么我们主动关闭服务端后，用客户端向服务端写数据，还必须是写两次后连接才会关闭的原因。

## 为什么还需要快速重传机制

超时重传是按时间来驱动的，如果是网络状况真的不好的情况，超时重传没问题，但是如果网络状况好的时候，只是恰巧丢包了，那等这么长时间就没必要。

于是又引入了数据驱动的重传叫快速重传，发送方如果连续三次收到对方相同的确认号，那么马上重传数据。

因为连续收到三次相同 ACK 证明当前网络状况是 ok 的，那么确认是丢包了，于是立马重发，没必要等这么久。

## 拥塞控制

**过程解析**:

阶段1:因cwnd<ssthresh，使用慢开始算法

阶段2：因cwnd>ssthresh,故停止使用慢开始算法而改用拥塞避免算法

阶段3：出现网络拥塞，把慢开始门限（ssthresh）设置为出现拥塞时的发送方窗口值的一半，把拥塞窗口（cwnd）重新设置为1

阶段4：因cwnd<ssthresh，故使用慢开始算法

阶段5：因cwnd>ssthresh，故停止使用慢开始算法而改用拥塞避免算法

注：

a.乘法减小：出现网络拥塞时慢开始门限设置为出现拥塞时的发送方窗口值的一半

b.加法增大：拥塞避免时的缓慢增大

c.二者合并叫为AIMD算法（即加法增大，乘法减少）

目的是为了防止过多的数据注入到网络中。

## tcp慢开始，为什么指数级别还叫慢开始

虽然窗口是指数增加，但是相比于一开始就选择大窗口，仍然较慢

## 流量控制（没写）

## TCP快速建立连接

![](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZctmf3ObkESj41ayTbgy9q4ThRjO0ukiaIPYKAsY8XThOp0f1R4Id6L9icUxj7GUvLica7hmfB9DibG9g/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

- 在第一次建立连接的时候，服务端在第二次握手产生一个cookie(已加密)并通过SYN、ACK包一起发给客户端，于是客户端就会缓存这个cookie，所以第一次发起HTTP Get请求的时候，还是需要2个RTT的时延
- 在下次请求的时候，客户端在SYN包带上cookie发给服务端，就提前可以跳过三次握手的过程，因为Cookie中维护了一些信息，服务端可以从Cookie获取TCP相关的信息，这时发起的HTTP GET请求就只需要1个RTT的时延

## TCP和UDP的区别

- TCP是面向连接的，UDP是面向报文的
- TCP传输可靠，UDP传输不可靠
- TCP的传输形式是字节流，UDP的传输形式是数据报文段
- TCP传输效率较慢，UDP传输效率快
- TCP需要的资源多，UDP所需资源少
- TCP主要应用于要求通信数据可靠的场景，UDP主要应用于要求通信速度高的场景

- TCP首部字节为20-60个字节，UDP首部字节为8个字节
- UDP不存在发送缓存

[^什么是short write]: 对于一个非阻塞的TCP套接口，如果其发送缓冲区中根本没有空间，输出函数调用将立即返回一个EWOULDBLOCK错误。如果其发送缓冲区中有一些空间，返回值将是内核能够拷贝到该缓冲区中的字节数。这个字节数也称为不足计数(应该就是short write的意思)

## TCP确保传输可靠性的方式

TCP协议保证数据传输可靠性的方式主要有:

- 校验和
- 序列号**用来解决网络包乱序问题**

接收方可以去除重复的数据；

接收方可以根据数据包的序列号按序接收；

可以标识发送出去的数据包中，哪些是已经被对方收到的：

- 确认应答**用来解决不丢包的问题**
- 超时重传
- 连接管理
- 流量控制
- 拥塞控制

## 有一个 IP 的服务器监听了一个端口，它的 TCP 的最大连接数是多少？

理论值计算公式如下：最大TCP连接数=客户端的IP数X客户端的端口数

对IPv4，客户端的IP数最多为2的32次方，客户端的端口数最多为2的16次方，也就是服务端单机最大TCP连接数，约为2的48次方。

当然，服务端最大并发 TCP 连接数远不能达到理论上限。

- 首先主要是**文件描述符限制**，Socket 都是文件，所以首先要通过 `ulimit` 配置文件描述符的数目；
- 另一个是**内存限制**，每个 TCP 连接都要占用一定内存，操作系统是有限的。

## TCP半连接和全连接队列（这个没弄懂）

![img](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost/计算机网络/TCP-半连接和全连接/3.jpg)

- 0 ：如果全连接队列满了，那么 server 扔掉 client 发过来的 ack ；
- 1 ：如果全连接队列满了，server 发送一个 `reset` 包给 client，表示废掉这个握手过程和这个连接；

只要服务器没有为请求回复 ACK，请求就会被多次**重发**。如果服务器上的进程只是**短暂的繁忙造成 accept 队列满，那么当 TCP 全连接队列有空位时，再次接收到的请求报文由于含有 ACK，仍然会触发服务器端成功建立连接。**

## TCP Socket编程

- 服务端和客户端初始化 `socket`，得到文件描述符；
- 服务端调用 `bind`，将绑定在 IP 地址和端口;
- 服务端调用 `listen`，进行监听；
- 服务端调用 `accept`，等待客户端连接；
- 客户端调用 `connect`，向服务器端的地址和端口发起连接请求；
- 服务端 `accept` 返回用于传输的 `socket` 的文件描述符；
- 客户端调用 `write` 写入数据；服务端调用 `read` 读取数据；
- 客户端断开连接时，会调用 `close`，那么服务端 `read` 读取数据的时候，就会读取到了 `EOF`，待处理完数据后，服务端调用 `close`，表示连接关闭。

![img](https://gitee.com/xurunxuan/picgo/raw/master/img/0_1314694589UeXT.gif)

下面的图可能更好理解:

![](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9f3cb90c32e9484c893436a556be00a0~tplv-k3u1fbpfcp-watermark.image)

## TCP，UDP数据包大小的限制

![](https://yueqilai-images.oss-cn-beijing.aliyuncs.com/image-20200813111620210.png)

我们从下到上分析一下： 　　
1.在链路层，由以太网的物理特性决定了数据帧的长度为(46＋18)－(1500＋18)，其中的18是数据帧的头和尾，也就是说数据帧的内容最大为1500(不包括帧头和帧尾)，即MTU(Maximum Transmission Unit)为1500； 　
2.在网络层，因为IP包的首部要占用20字节，所以这的MTU为1500－20＝1480；　
3.在传输层，对于UDP包的首部要占用8字节，所以这的MTU为1480－8＝1472； 　　
所以，在应用层，你的Data最大长度为1472。当我们的UDP包中的数据多于MTU(1472)时，发送方的IP层需要分片fragmentation进行传输，而在接收方IP层则需要进行数据报重组，由于UDP是不可靠的传输协议，如果分片丢失导致重组失败，将导致UDP数据包被丢弃。 　　
从上面的分析来看，在普通的局域网环境下，UDP的数据最大为1472字节最好(避免分片重组)。

UDP 包的大小就应该是 1500 - IP头(20) - UDP头(8) = 1472(Bytes)
TCP 包的大小就应该是 1500 - IP头(20) - TCP头(20) = 1460 (Bytes)

## BBR（这个还需要了解）

BBR算法是个主动的闭环反馈系统，通俗来说就是根据带宽和RTT延时来不断动态探索寻找合适的发送速率和发送量。

## 快速重传解决的问题

快速重传解决了超时重发的时间等待（每一次遇到超时重传时，都会将下一次超时时间间隔设为先前值的两倍）。

但是仍然面临**重传的时候，是重传之前的一个，还是重传所有的问题。**

于是又引入了：`SACK`选择性确认

这种方式需要在 TCP 头部「选项」字段里加一个 `SACK` 的东西，它**可以将缓存的地图发送给发送方**，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以**只重传丢失的数据**。

Duplicate SACK 又称 `D-SACK`，其主要**使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。**

`	D-SACK` 有这么几个好处：

1. 可以让「发送方」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了;
2. 可以知道是不是「发送方」的数据包被网络延迟了;
3. 可以知道网络中是不是把「发送方」的数据包给复制了;

## 糊涂窗口综合症

**如果接收方腾出几个字节并告诉发送方现在有几个字节的窗口，而发送方会义无反顾地发送这几个字节，这就是糊涂窗口综合症**。

要解决糊涂窗口综合症，

- 让接收方不通告小窗口给发送方
- 让发送方避免发送小数据

## tcp异常(没写)

## http的理解

[待补充](https://mp.weixin.qq.com/s/amOya0M00LwpL5kCS96Y6w)

## http优缺点

**优点**:

- 简单:HTTP基本的报文格式就是 `header + body`，头部信息也是 `key-value` 简单文本的形式
- 灵活和易于扩展:HTTP协议里的各类请求方法、URI/URL、状态码、头字段等每个组成要求都没有被固定死。它下层也可以随意变化
- 应用广泛和跨平台

**缺点**:

- 无状态:好处是不需要额外的资源来记录状态信息,减轻服务器的负担;坏处是在完成有关联性的操作时会非常麻烦。
- 通信使用明文传输，内容可能会被窃听
- 不验证通信方的身份
- 无法证明报文的完整性

## HTTP状态码

- 1xx：属于提示信息，是协议处理中的一种中间状态，实际用到的比较少。
- 2xx：成功,报文已经收到并被正确处理
  200 ok:是最常见的成功状态码，表示一切正常。
  204 No Content:响应头没有body数据
  206 Partial Content:应用于Http分块下载或断点续传,表示响应返回的body数据并不是资源的全部,而是其中的一部分,也是服务器处理成功的状态.
- 3xx：重定向，资源位置发生变动，需要客户端重新发送请求
  301 Moved Permanently:表示永久重定向,说明请求的资源已经不存在了,需改用新的URL再次访问.
- 4xx：客户端错误，请求报文有误，服务器无法处理
- 5xx：服务器错误，服务器在处理请求时内部发生了错误

## HTTP与HTTPS有哪些区别

- HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输
- HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输
- HTTP 的端口号是 80，HTTPS 的端口号是 443
- HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的

## https过程(有两篇文章还没看)

[待补充1](https://mp.weixin.qq.com/s/amOya0M00LwpL5kCS96Y6w)

[待补充2](https://mp.weixin.qq.com/s/21JaXwdfSjItj5SgOwhapg)

![img](https://mmbiz.qpic.cn/sz_mmbiz_png/VMORHafhQIMVgicZXOeicEJscQFXU3y2ibpuVYnibFtWRHyE2TXYlsS8oZiaQbK6cia4ic310qicVxlpPXgj3TP0q2mxpA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

1. 用户在浏览器发起HTTPS请求（如 https://www.mogu.com/），默认使用服务端的443端口进行连接；
2. HTTPS需要使用一套**CA数字证书**，证书内会附带一个**公钥Pub**，而与之对应的**私钥Private**保留在服务端不公开；
3. 服务端收到请求，返回配置好的包含**公钥Pub**的证书给客户端；
4. 客户端收到**证书**，校验合法性，主要包括是否在有效期内、证书的域名与请求的域名是否匹配，上一级证书是否有效（递归判断，直到判断到系统内置或浏览器配置好的根证书），如果不通过，则显示HTTPS警告信息，如果通过则继续；
5. 客户端生成一个用于对称加密的**随机Key**，并用证书内的**公钥Pub**进行加密，发送给服务端；
6. 服务端收到**随机Key**的密文，使用与**公钥Pub**配对的**私钥Private**进行解密，得到客户端真正想发送的**随机Key**；
7. 服务端使用客户端发送过来的**随机Key**对要传输的HTTP数据进行对称加密，将密文返回客户端；
8. 客户端使用**随机Key**对称解密密文，得到HTTP数据明文；
9. 后续HTTPS请求使用之前交换好的**随机Key**进行对称加解密。

## 怎么保证证书有效

私钥除了解密外的真正用途其实还有一个，就是**数字签名**，其实就是一种防伪技术，只要有人篡改了证书，那么数字签名必然校验失败。具体过程如下

1. CA机构拥有自己的一对公钥和私钥
2. CA机构在颁发证书时对证书明文信息进行哈希
3. 将哈希值用私钥进行**加签**，得到数字签名

##### 明文数据和数字签名组成证书，传递给客户端。

1. 客户端得到证书，分解成明文部分Text和数字签名Sig1
2. 用CA机构的公钥进行**解签**，得到Sig2（由于CA机构是一种公信身份，因此在系统或浏览器中会内置CA机构的证书和公钥信息）
3. 用证书里声明的哈希算法对明文Text部分进行哈希得到H
4. 当自己计算得到的哈希值T与**解签**后的Sig2**相等**，表示证书可信，**没有被篡改**

**验证过程**:

(有些没看懂)

## Http格式

请求报文:

![](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4aae68cc0c814586847cf213ee120a2c~tplv-k3u1fbpfcp-watermark.image)

响应报文:

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/761dc4539f244e32a014211ee05338e7~tplv-k3u1fbpfcp-watermark.image)

## HTTP中Get与Post的区别

- GET用于信息获取，而且应该是安全的和幂等的
- POST表示可能修改服务器上的资源的请求

## HTTP1.0,HTTP1.1,HTTP2.0,HTTP3.0的区别与联系

### HTTP/1.1

HTTP/1.1 相比 HTTP/1.0 性能上的改进：

- 使用 TCP 长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。
- 支持 管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。

最主要的改进就是引入了持久连接(在一个TCP连接上可以传送多个HTTP请求和响应)

但 HTTP/1.1 还是有性能瓶颈：

- 请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 `Body` 的部分；
- 发送冗长的首部。每次互相发送相同的首部造成的浪费较多；
- 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队头阻塞；
- 没有请求优先级控制；
- 请求只能从客户端开始，服务器只能被动响应。

### HTTP/2

HTTP/2 相比 HTTP/1.1 性能上的改进:

1. 头部压缩
   
HTTP/2 会**压缩头**（Header）如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你**消除重复的分**。

这就是所谓的 `HPACK` 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就**提高速度**了。

2. 二进制格式

HTTP2中头信息和数据体都是二进制,并且统称为帧:头信息帧和数据帧

3. 数据流

HTTP2中每个请求或回应的所有数据包,称为一个数据流.

4. 多路复用

HTTP2中可以在一个连接中并发多个请求或回应,而不用按照顺序一一对应.

5. 服务器推送

HTTP2中服务不再是被动的响应，也可以主动向客户端发送消息.

因为HTTP/2底层是采用TCP协议实现的，虽然解决了HTTP队头阻塞的问题，但是对于TCP队头阻塞的问题却无能为力。

TCP传输过程中会把数据拆分为一个个按照顺序排列的数据包，这些数据包通过网络传输到了接收端，接收端再按照顺序将这些数据包组合成原始数据，这样就完成了数据传输。

但是如果其中的某一个数据包没有按照顺序到达，接收端会一直保持连接等待数据包返回，这时候就会阻塞后续请求。这就发生了TCP队头阻塞。


## http劫持(还没看)

[http劫持](https://juejin.im/post/6844903991764058126#comment)

## HTTP缓存机制及原理

1、对于强制缓存，服务器通知浏览器一个缓存时间，在缓存时间内，下次请求，直接用缓存，不在时间内，执行比较缓存策略。

2、对于比较缓存，将缓存信息中的Etag和Last-Modified通过请求发送给服务器，由服务器校验，返回304状态码时，浏览器直接使用缓存。

![img](https://user-gold-cdn.xitu.io/2019/3/22/169a12255df4532a?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

验证是否能使用缓存（`协商缓存策略`）主要有两种方式：

1、`Last-Modified` ：最后一次修改时间

2、`Etag`: 数据签名

配合`If-Match`或者`If-Non-Match`使用 对比资源的签名判断是否使用缓存 `ETag`也是首次请求的时候

## HTTP响应代码

[http响应代码](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status)

## MTU最大传输单元

其实一个标准的以太网数据帧大小是：`1518`，头信息有14字节，尾部校验和FCS占了4字节，所以真正留给上层协议传输数据的大小就是：1518 - 14 - 4 = 1500

太大会一直占用发送端口，导致其他数据不能及时发送

又因为最小的64字节，数据链路层占用18字节，所以Ip层是64-1500字节

## 正向代理和反向代理的区别

HTTP请求的访问域名，是不是指向代理服务器。指向代理服务器时，就是反向代理，否则就是正向代理。

## 负载均衡算法

**权重法**:

给集群中的每台机器设置权重值weight，按照请求访问的时间顺序，指定一台机器访问。当某台机器宕机，自动剔除，不再给其分配请求，避免用户访问受到影响。weight越大，被分配的概率越高。

缺点是:容易导致热点不均衡

**IP Hash法**:

根据请求IP的Hash值分配机器

缺点同权重法，无法智能感知每台机器的负载情况

优点也很明显：解决动态网页存在的session连接问题.

**fair**:

第三方工具，相比于前两者，考虑响应时间、页面大小智能做负载均衡。

**url hash**:

按照请求url的hash值分配机器，可有效利用缓存。

## ping工作原理

1. 假设有两个主机，主机A（192.168.0.1）和主机B（192.168.0.2），现在我们要监测主机A和主机B之间网络是否可达，那么我们在主机A上输入命令：ping 192.168.0.2
2. 此时，ping命令会在主机A上构建一个ICMP的请求数据包，然后ICMP协议会将这个数据包以及目标IP（192.168.0.2）等信息一同交给IP层协议
3. IP层协议得到这些信息后，将源地址（即本机IP）、目标地址（即目标IP：192.168.0.2）、再加上一些其它的控制信息，构建成一个IP数据包
4. IP数据包构建完成后，还不够，还需要加上MAC地址，因此，还需要通过ARP映射表找出目标IP所对应的MAC地址。当拿到了目标主机的MAC地址和本机MAC后，一并交给数据链路层，组装成一个数据帧，依据以太网的介质访问规则，将它们传送出出去；
5. 当主机B收到这个数据帧之后，会首先检查它的目标MAC地址是不是本机，如果是就接收下来处理，接收之后会检查这个数据帧，将数据帧中的IP数据包取出来，交给本机的IP层协议，然后IP层协议检查完之后，再将ICMP数据包取出来交给ICMP协议处理，当这一步也处理完成之后，就会构建一个ICMP应答数据包，回发给主机A；
6. 在一定的时间内，如果主机A收到了应答包，则说明它与主机B之间网络可达，如果没有收到，则说明网络不可达。

## 请求转发和重定向的区别

forward(转发):

是服务器请求资源,服务器直接访问目标地址的URL,把那个URL的响应内容读取过来,然后把这些内容再发给浏览器.

浏览器根本不知道服务器发送的内容从哪里来的,因为这个跳转过程实在服务器实现的，并不是在客户端实现的所以客户端并不知道这个跳转动作，所以它的地址栏还是原来的地址.

redirect(重定向):

是服务端根据逻辑,发送一个状态码,告诉浏览器重新去请求那个地址.所以地址栏显示的是新的URL.

转发是服务器行为,重定向是客户端行为.

**区别**:

- 从地址栏显示来说:forward显示原来的地址,redirect显示的是新的地址
- 从数据共享来说:forward是转发页面和转发到的页面可以共享request里面的数据,redirect不能共享数据
- 从效率来说:forward高,redirect低

**本质区别**:

转发过程：客户浏览器发送http请求----》web服务器接受此请求--》调用内部的一个方法在容器内部完成请求处理和转发动作----》将目标资源发送给客户;在这里，转发的路径必须是同一个web容器下的url，其不能转向到其他的web路径上去，中间传递的是自己的容器内的request。

在客户浏览器路径栏显示的仍然是其第一次访问的路径，也就是说客户是感觉不到服务器做了转发的。转发行为是浏览器只做了一次访问请求。

重定向过程:客户浏览器发送http请求----》web服务器接受后发送302状态码响应及对应新的location给客户浏览器--》客户浏览器发现是302响应，则自动再发送一个新的http请求，请求url是新的location地址----》服务器根据此请求寻找资源并发送给客户。

在这里location可以重定向到任意URL，既然是浏览器重新发出了请求，则就没有什么request传递的概念了。在客户浏览器路径栏显示的是其重定向的路径，客户可以观察到地址的变化的。重定向行为是浏览器做了至少两次的访问请求的。

[请求转发（Forward）和重定向（Redirect）的区别](https://www.cnblogs.com/Qian123/p/5345527.html)

## NAT

NAT有三种类型：静态NAT(Static NAT)、动态地址NAT(Pooled NAT)、网络地址端口转换NAPT（Port-Level NAT）。

其中，网络地址端口转换NAPT（Network Address Port Translation）则是把内部地址映射到外部网络的一个IP地址的不同端口上。

它将内部连接映射到外部网络中的一个单独的IP地址上，同时在该地址上加上一个由NAT设备选定的端口号。

NAPT是使用最普遍的一种转换方式，它又包含两种转换方式：SNAT和DNAT。

(1)源NAT（Source NAT，SNAT）：修改数据包的源地址。源NAT改变第一个数据包的来源地址，它永远会在数据包发送到网络之前完成，数据包伪装就是一具SNAT的例子。

(2)目的NAT（Destination NAT，DNAT）：修改数据包的目的地址。Destination NAT刚好与SNAT相反，它是改变第一个数据懈的目的地地址，如平衡负载、端口转发和透明代理就是属于DNAT。

**主要功能**:

数据伪装: 可以将内网数据包中的地址信息更改成统一的对外地址信息，不让内网主机直接暴露在因特网上，保证内网主机的安全。同时，该功能也常用来实现共享上网。

端口转发: 当内网主机对外提供服务时，由于使用的是内部私有IP地址，外网无法直接访问。因此，需要在网关上进行端口转发，将特定服务的数据包转发给内网主机。

负载平衡: 目的地址转换NAT可以重定向一些服务器的连接到其他随机选定的服务器。（不是很明白）

失效终结: 目的地址转换NAT可以用来提供高可靠性的服务。如果一个系统有一台通过路由器访问的关键服务器，一旦路由器检测到该服务器当机，它可以使用目的地址转换NAT透明的把连接转移到一个备份服务器上。（如何转移的?）

透明代理: NAT可以把连接到因特网的HTTP连接重定向到一个指定的HTTP代理服务器以缓存数据和过滤请求。一些因特网服务提供商就使用这种技术来减少带宽的使用而不用让他们的客户配置他们的浏览器支持代理连接。（如何重定向的?）

[看不太懂](https://blog.csdn.net/hzhsan/article/details/45038265)

## 线程同步机制

![](https://yueqilai-images.oss-cn-beijing.aliyuncs.com/image-20200803203736671.png)



# Java

## JRE和JDK的区别

JRE： Java Runtime Environment，java运行时环境，**包含了java虚拟机，java基础类库**。是使用java语言编写的程序运行所需要的软件环境，是提供给想运行java程序的用户使用的。

JDK：Java Development Kit，java开发工具包，是程序员使用java语言编写java程序所需的开发工具包，是提供给程序员使用的。JDK包含了JRE，同时还包含了编译java源码的编译器。

## 基本数据类型

![](https://user-gold-cdn.xitu.io/2020/4/14/171744c434465b69?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

## Math.round(11.5) 等于多少?Math.round(-11.5)等于多少

Math.round(11.5)的返回值是 12，Math.round(-11.5)的返回值是-11。四舍五入的原理是在参数上加 0.5 然后进行下取整。

## 访问修饰符

- private : 在同一类内可见。使用对象：变量、方法。 注意：不能修饰类（外部类）

- default (即缺省，什么也不写，不使用任何关键字）: 在同一包内可见，不使用任何修饰符。使用对象：类、接口、变量、方法。

- protected : 对同一包内的类和所有子类可见。使用对象：变量、方法。 注意：不能修饰类（外部类）。

- public : 对所有类可见。使用对象：类、接口、变量、方法

![](https://user-gold-cdn.xitu.io/2020/4/14/171744c433bcfd38?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

## final finally finalize区别

- final可以修饰类、变量、方法，修饰类表示该类不能被继承、修饰方法表示该方法不能被重写、修饰变量表 示该变量是一个常量不能被重新赋值。
- finally一般作用在try-catch代码块中，在处理异常的时候，通常我们将一定要执行的代码方法finally代码块中，表示不管是否出现异常，该代码块都会执行，一般用来存放一些关闭资源的代码。
- finalize是一个方法，属于Object类的一个方法，而Object类是所有类的父类，该方法一般由垃圾回收器来调用，当我们调用`System.gc()`方法的时候���由垃圾回收器调用`finalize()`，回收垃圾，一个对象是否可回收的 最后判断。

## 面向对象的三大特性

- 封装：把一个对象的属性私有化，同时提供一些可以被外界访问的属性的方法
- 继承：使用已存在的类的定义作为基础建立新类
- 多态：父类或接口定义的引用变量可以指向子类或具体实现类的实例对象。

## 面向对象的五大基本原则

- 单一职责原则:一个类，最好只做一件事，只有一个引起它的变化。
- 开放封闭原则:软件实体应该是可扩展的，而不可修改的
- Liskov替换原则:子类必须能够替换其基类。
- 依赖倒置原则:依赖于抽象。高层模块不依赖于底层模块，二者都同依赖于抽象；抽象不依赖于具体，具体依赖于抽象
- 接口隔离原则:使用多个小的专门的接口，而不要使用一个大的总接口。

## 多态的必要条件

- 有类继承或者接口实现
- 子类要重写父类的方法
- 父类的引用指向子类的对象

## 方法多态的实现

多态中方法多态的实现是靠动态分派。

![](https://yueqilai-images.oss-cn-beijing.aliyuncs.com/image-20200801164355442.png)

虚方法表中存放着各个方法的实际入口地址。如果某个方法在子类中没有被重写，那子类的虚方法表中的地址入口和父类相同方法的地址入口是一致的，都指向父类的实现入口。如果子类中重写了这个方法，子类虚方法表中的地址也会被替换为指向子类实现版本的入口地址。

## 重载与重写的区别

- 方法的重载和重写都是实现多态的方式，区别在于前者实现的是编译时的多态性，而后者实现的是运行时的多态性。

- 重载：发生在同一个类中，方法名相同参数列表不同（参数类型不同、个数不同、顺序不同），与方法返回值和访问修饰符无关，即重载的方法不能根据返回类型进行区分

- 重写：发生在父子类中，方法名、参数列表必须相同，返回值小于等于父类，抛出的异常小于等于父类，访问修饰符大于等于父类（里氏代换原则）；如果父类方法访问修饰符为private则子类中就不是重写。

多态应该是一种运行期特性，Java中的重写是多态的体现。

## 类的实例化顺序

父类静态代码块/静态域->子类静态代码块/静态域 -> 父类非静态代码块 -> 父类构造器 -> 子类非静态代码块 -> 子类构造器

## Java创建对象的5种方式

- 用new语句创建对象。

- 使用反射，使用`Class.newInstance()`创建对象/调用类对象的**构造方法**——Constructor

- 调用对象的`clone()`方法。

- 运用反序列化手段，调用`java.io.ObjectInputStream`对象的`readObject()`方法.

- 使用Unsafe

## 抽象类和接口的区别

- 定义上，抽象类是包含抽象方法的类，接口是抽象方法和全局变量的集合
- 组成上，抽象类由构造方法、抽象方法、普通方法、常量和变量构成，接口由常量、抽象方法构成，在JDK1.8之后，接口里可以有静态方法和方法体
- 使用上，子类继承抽象类，子类实现接口
- 关系上，抽象类可以实现多个接口，接口不能继承抽象类，但是允许继承多个接口
- 局限上，抽象类有单继承的局限，接口没有单继承的限制
- 声明上，抽象类使用abstract声明，接口使用interface声明

## 内部类

- 静态内部类：定义在类内部的静态类

  静态内部类可以访问外部类所有的静态变量，而不可访问外部类的非静态变量；静态内部类的创建方式，`new 外部类.静态内部类()`

- 成员内部类：定义在类内部，成员位置上的非静态类

  成员内部类可以访问外部类所有的变量和方法，包括静态和非静态，私有和公有。成员内部类依赖于外部类的实例，它的创建方式`外部类实例.new 内部类()`

- 局部内部类：定义在方法中的内部类

  定义在实例方法中的局部类可以访问外部类的所有变量和方法，定义在静态方法中的局部类只能访问外部类的静态变量和方法。局部内部类的创建方式，在对应方法内，`new 内部类()`

- 匿名内部类：没有名字的内部类

  - 匿名内部类必须继承一个抽象类或者实现一个接口。
  - 匿名内部类不能定义任何静态成员和静态方法。
  - 当所在的方法的形参需要被匿名内部类使用时，必须声明为 final。
  - 匿名内部类不能是抽象的，它必须要实现继承的类或者实现的接口的所有抽象方法。

## 值传递与引用传递

值传递（pass by value）是指在调用函数时将实际参数复制一份传递到函数中，这样在函数中如果对参数进行修改，将不会影响到实际参数。

引用传递（pass by reference）是指在调用函数时将实际参数的地址直接传递到函数中，那么在函数中对参数所进行的修改，将影响到实际参数。

Java中只有值传递，只不过传递的内容是对象的引用

## 深拷贝和浅拷贝的区别

**浅拷贝**:

复制了对象的引用地址，两个对象指向同一个内存地址，所以修改其中任意的值，另一个值都会随之变化。

![](https://user-gold-cdn.xitu.io/2020/2/1/16ffca9fd5f38501?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

**深拷贝**:

将对象及值复制过来，两个对象修改其中任意的值另一个值不会改变

![](https://user-gold-cdn.xitu.io/2020/2/1/16ffcab48469215e?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

## ==和equals的区别

**==** : 它的作用是判断两个对象的地址是不是相等。即，判断两个对象是不是同一个对象。(基本数据类型 == 比较的是值，引用数据类型 == 比较的是内存地址)

**equals()** : 它的作用也是判断两个对象是否相等。但它一般有两种使用情况：

- 情况1：类没有覆盖 equals() 方法。则通过 equals() 比较该类的两个对象时，等价于通过“==”比较这两个对象。
- 情况2：类覆盖了 equals() 方法。一般，我们都覆盖 equals() 方法来两个对象的内容相等；若它们的内容相等，则返回 true (即，认为这两个对象相等)。

## hashCode（）与equals（）的相关规定

- 如果两个对象相等，则hashcode一定也是相同的
- 两个对象相等，对两个对象分别调用equals方法都返回true
- 两个对象有相同的hashcode值，它们也不一定是相等的
- equals方法被覆盖过，则hashCode方法也必须被覆盖
- hashCode()的默认行为是对堆上的对象产生独特值。如果没有重写hashCode()，则该class的两个对象无论如何都不会相等（即使这两个对象指向相同的数据）

## Integer a= 127 与 Integer b = 127相等吗

- 对于对象引用类型：==比较的是对象的内存地址。
- 对于基本数据类型：==比较的是值。
- 如果整型字面量的值在-128到127之间，那么自动装箱时不会new新的Integer对象，而是直接引用常量池中的Integer对象，超过范围 a1==b1的结果是false

可以通过-XX:AutoBoxCacheMax=size修改缓存最大值

## 关于包装类

[《阿里巴巴Java开发手册-泰山版》提到的三目运算符的空指针问题到底是个怎么回事？](https://www.hollischuang.com/archives/4749)

三目运算符的语法规范:当第二，第三位操作数分别为基本类型和对象时，其中的对象就会拆箱为基本类型进行操作。

## Object类方法

- `Object()`
- `clone()`
- `equals(Object)`
- `finalize()`
- `getClass()`
- `hashCode()`
- `notify()`
- `notifyAll()`
- `toString()`
- `wait()`
- `wait(long)`
- `wait(long, int)`

## String有关

### 结构演变

![](https://user-gold-cdn.xitu.io/2019/9/23/16d5eac18d375060?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

**Java6及之前：**

是对 char 数组进行了封装实现的对象，主要有四个成员变量： char 数组、偏移量 offset、字符数量 count、哈希值 hash。通过 offset 和 count 两个属性来定位 char[] 数组，获取字符串。但这种方式很有可能会导致内存泄漏。

**Java7-8**：

占用的内存稍微少了点，同时解决了内存泄漏的问题。

**Java9:**

将char数组改为了byte数组，节约了空间。

在 Java9 维护了一个新的属性 coder，它是编码格式的标识，在计算字符串长度或者调用 indexOf() 函数时，需要根据这个字段，判断如何计算字符串长度。coder 属性默认有 0 和 1 两个值， 0 代表Latin-1（单字节编码），1 代表 UTF-16 编码。如果 `String`判断字符串只包含了 Latin-1，则 coder 属性值为 0 ，反之则为 1。

### 创建方式

- 通过字符串常量的方式：`String str = "alone"`的形式，使用这种形式创建字符串时，JVM会**在字符串常量池中先检查**是否存在该对象，如果存在，返回该对象的引用地址，如果不存在，则在字符串常量池中创建该字符串对象并且返回引用。
- 通过构造函数的方式：`String str = new String("pingtouge")`的形式，这种方式要分成两个阶段，首先在编译时，字符串`pingtouge`会被加入到常量结构中，类加载时候就会在常量池中创建该字符串。然后就是在调用new()时，JVM 将会调用`String`的构造函数，同时引用常量池中的`pingtouge`字符串， 在堆内存中创建一个`String`对象并且返回堆中的引用地址。

### 不可变性

- 因为String类用了final修饰符，所以String类不可被继承
- 用来存储字符串的`char value[]`数组被`private`和`final`修饰，不可修改`char[]`指向的地址，但是数组内的值是可以改的

### 拼接字符串的优化

1. String s = "a" + "b"，编译器会进行常量折叠(因为两个都是编译期常量，编译期可知)，即变成 String s = "ab"

2. 对于能够进行优化的(String s = "a" + 变量 等)用 StringBuilder 的 append() 方法替代，最后调用 toString() 方法 (底层就是一个 new String())

```java
String str = "pingtouge";

for(int i=0; i<1000; i++) {
      str = str + i;
}
```

编译器会帮我们优化成:

```
String str = "pingtouge";

for(int i=0; i<1000; i++) {
        	  str = (new StringBuilder(String.valueOf(str))).append(i).toString();
}
```

阿里巴巴Java开发手册中推荐：循环体内,字符串的连接方式,使用StringBuilder的append方法进行扩展.

五种方式的效率(从短到长)对比:

StringBuilder < StringBuffer < concat < + < StringUtils.join

### 常用方法

- `indexOf()`：返回指定字符的索引。

- `charAt()`：返回指定索引处的字符。

- `replace()`：字符串替换。

- `trim()`：去除字符串两端空白。

- `split()`：分割字符串，返回一个分割后的字符串数组。

- `getBytes()`：返回字符串的 byte 类型数组。

- `length()`：返回字符串长度。

- `toLowerCase()`：将字符串转成小写字母。

- `toUpperCase()`：将字符串转成大写字符。

- `substring()`：截取字符串。

- `equals()`：字符串比较。

### JDK6和JDK7中的substring()方法的区别

JDK6：当调用substring方法的时候，会创建一个新的string对象，但是这个string的值仍然指向堆中的同一个字符数组。这两个对象中只有count和offset 的值是不同的。

![](http://www.programcreek.com/wp-content/uploads/2013/09/string-substring-jdk6-650x389.jpeg)

JDK7:会在堆内存中创建一个新的数组

![](http://www.programcreek.com/wp-content/uploads/2013/09/string-substring-jdk71-650x389.jpeg)

### String.valueOf和Integer.toString的区别

```
1.int i = 5;
2.String i1 = "" + i;
3.String i2 = String.valueOf(i);
4.String i3 = Integer.toString(i);
```

第三行和第四行没有任何区别，因为`String.valueOf(i)`也是调用`Integer.toString(i)`来实现的。

第二行代码其实是`String i1 = (new StringBuilder()).append(i).toString();`，首先创建一个StringBuilder对象，然后再调用append方法，再调用toString方法。

### intern()方法

intern()方法的功能是可以在运行期将字符串内容放置到字符串常量池.

在每次赋值的时候使用 String 的 intern 方法，如果常量池中有相同值，就会重复使用该对象，返回对象引用。

### 字符串常量池

当代码中出现双引号形式（字面量）创建字符串对象时，JVM 会先对这个字符串进行检查，如果字符串常量池中存在相同内容的字符串对象的引用，则将这个引用返回；否则，创建新的字符串对象，然后将这个引用放入字符串常量池，并返回该引用。

在JDK 7以前的版本中，字符串常量池是放在永久代中的.

JDK 7中，将字符串常量池先从永久代中移出，暂时放到了堆内存中。

在JDK 8中，彻底移除了永久代，使用元空间替代了永久代，于是字符串常量池再次从堆内存移动到永久代中

## Class常量池

在版本号的后面,用于存放编译器生成的各种字面量(Literal)和符号引用(Symbolic References)。

在Class文件的常量池入口处会设置两个字节的常量池容量计数器，记录了常量池中常量的个数。

**常量池的内容**:

常量池中主要存放两大类常量：字面量（literal）和符号引用（symbolic references）。

字面量是用于表达源代码中一个固定值的表示法。说简单点，字面量就是指由字母、数字等构成的字符串或者数值。

符号引用主要包括了以下三类常量： 

- 类和接口的全限定名 
- 字段的名称和描述符 
- 方法的名称和描述符

Class是用来保存常量的一个媒介场所，并且是一个中间场所。在JVM真的运行时，需要把常量池中的常量加载到内存中。

## 运行时常量池

运行时常量池（ Runtime Constant Pool）是每一个类或接口的常量池（ Constant_Pool）的运行时表示形式。它包括了若干种不同的常量：编译期可知的字面量和符号引用（来自Class常量池） 运行期解析后可获得的常量（如String的intern方法）

运行时常量池中的内容包含：Class常量池中的常量、字符串常量池中的内容

**在各个版本中的实现**:

在JDK 1.7之前，方法区位于堆内存的永久代中，运行时常量池作为方法区的一部分，也处于永久代中。

在1.7中，将原本位于永久代中的运行时常量池移动到堆内存中。（永久代在JDK 1.7并没有完全移除，只是原来方法区中的运行时常量池、类的静态变量等移动到了堆内存中。）

在JDK 1.8中，彻底移除了永久代，方法区通过元空间的方式实现。随之，运行时常量池也在元空间中实现。

### 运行时常量池,Class常量池,字符串常量池的区别和联系

虚拟机启动过程中，会将各个Class文件中的常量池载入到运行时常量池中。

所以,Class常量池只是一个媒介场所。在JVM真的运行时，需要把常量池中的常量加载到内存中，进入到运行时常量池。

字符串常量池可以理解为运行时常量池分出来的部分。加载时，对于class的静态常量池，如果字符串会被装到字符串常量池中。

## 关键字

`transient`: 简单点说，就是被transient修饰的成员变量，在序列化的时候其值会被忽略，在被反序列化后， transient 变量的值被设为初始值， 如 int 型的是 0，对象型的是 null。

`instanceof`: 作用是测试它左边的对象是否是它右边的类的实例，返回 boolean 的数据类型。

## 异常

![](https://yueqilai-images.oss-cn-beijing.aliyuncs.com/2019101117003396.png)

### try-catch-finally-return执行顺序

- 如果不发生异常，不会执行catch部分。

- 不管有没有发生异常，finally都会执行到。

- 即使try和catch中有return时，finally仍然会执行

- finally是在return后面的表达式运算完后再执行的。（此时并没有返回运算后的值，而是先把要返回的值保存起来，若finally中无return，则不管finally中的代码怎么样，返回的值都不会改变，仍然是之前保存的值），该情况下函数返回值是在finally执行前确定的)

- finally部分就不要return了，要不然，就回不去try或者catch的return了。

## 反射

**定义**：

动态获取的信息以及动态调用对象的方法的功能

**实现**：

jdk是通过UNSAFE类对堆内存中对象的属性进行直接的读取和写入，要读取和写入首先需要确定属性所在的位置，也就是相对对象起始位置的偏移量。

**功能**：

①、在运行时判断任意一个对象所属的类
②、在运行时构造任意一个类的对象
③、在运行时判断任意一个类所具有的成员变量和方法（通过反射设置可以调用 private）
④、在运行时调用人一个对象的方法

**缺点**

- 性能较低，JVM无法对这些代码进行优化
- 必须在没有安全限制的环境中运行
- 可移植性差

**应用场景：**

- 使用JDBC连接数据库时使用Class.forName()通过反射加载数据库的驱动程序
- Spring通过XML配置模式装载Bean：
  - 将程序内所有 XML 或 Properties 配置文件加载入内存中
  - Java类里面解析xml或properties里面的内容，得到对应实体类的字节码字符串以及相关的属性信息;
  - 使用反射机制，根据这个字符串获得某个类的Class实例;
  - 动态配置实例的属性

**获取反射的三种方法：**

- 通过new对象实现反射机制

  ```java
  //方式一(通过建立对象)
  Student stu = new Student();
  Class classobj1 = stu.getClass();
  System.out.println(classobj1.getName());
  ```

- 通过路径实现反射机制

  ```java
  //方式二（所在通过路径-相对路径）
  Class classobj2 = Class.forName("fanshe.Student");
  System.out.println(classobj2.getName());
  ```

- 通过类名实现反射机制

  ```java
  //方式三（通过类名）
  Class classobj3 = Student.class;
  System.out.println(classobj3.getName());
  ```

## 动态代理（没看懂）

https://www.zhihu.com/question/20794107

![img](https://gitee.com/xurunxuan/picgo/raw/master/img/v2-6aacbe1e9df4fe982a68fe142401952e_720w.jpg)

从编译期是否能确定最终的执行方法可以把代理模式分为静态代理和动态代理.

新创建一个用户实现类 （UserDaoImpl），它不执行用户操作。然后再创建一个用户代理（UserProxy），执行用户代理的用户保存（saveUser），其内部会调用用户实现类的保存用户（saveUser）方法，因为 JVM 可以在编译期确定最终的执行方法，所以上面的这种代理模式又叫做静态代理。

JDK动态代理的调用处理程序必须事先继承 InvocationHandler 接口，使用 Proxy 类中的 newProxyInstance 方法动态的创建代理类

## CGLIB和JDK

CGLib创建的动态代理对象性能比JDK创建的动态代理对象的性能高不少，但是CGLib在创建代理对象时所花费的时间却比JDK多得多，所以对于单例的对象，因为无需频繁创建对象，用CGLib合适，反之，使用JDK方式要更为合适一些。同时，由于CGLib由于是采用动态创建子类的方法，对于final方法，无法进行代理。

JDK动态代理在调用方法时，使用了反射技术来调用被拦截的方法，效率低下，CGLib底层采用ASM字节码生成框架，使用字节码技术生成代理类，比使用Java反射效率要高。并且CGLIB采用`fastclass`机制来进行调用，对一个类的方法建立索引，通过索引来直接调用相应的方法。唯一需要注意的是，CGLib不能对声明为final的方法进行代理。

 CGLIB 动态代理是**针对类实现代理，主要是对指定的类生成一个子类，覆盖其中的方法**,采用类继承->方法重写的方式进行。

 ![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c3ae429e42684e9ab838b1b61c2c150e~tplv-k3u1fbpfcp-zoom-1.image)

## BIO,NIO,AIO有什么区别？

BIO：Block IO 同步阻塞式 IO，就是我们平常使用的传统 IO，它的特点是模式简单使用方便，并发处理能力低。

![](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9934ef7c03d94cc9b07bcc5aac48b4a1~tplv-k3u1fbpfcp-watermark.image)

NIO：Non IO 同步非阻塞 IO，是传统 IO 的升级，客户端和服务器端通过 Channel（通道）通讯，实现了多路复用。

![](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ed3e5528b1fa48778f2c2dcce87604a7~tplv-k3u1fbpfcp-watermark.image)

AIO：Asynchronous IO 是 NIO 的升级，也叫 NIO2，实现了异步非堵塞 IO ，异步 IO 的操作基于事件和回调机制。

![](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/cac7fc5e378746ef9ab8ce981b371d28~tplv-k3u1fbpfcp-watermark.image)

## Java8新特性

### 接口内允许添加默认实现的方法

Java8允许通过`default`关键字对接口中定义的抽象方法提供一个默认的实现。

```
// 定义一个公式接口
interface Formula {
    // 计算
    double calculate(int a);

    // 求平方根
    default double sqrt(int a) {
        return Math.sqrt(a);
    }
}
```

匿名对象实现`Formula`接口：

```
Formula formula = new Formula() {
    @Override
    public double calculate(int a) {
        return sqrt(a * 100);
    }
};

formula.calculate(100);     // 100.0
formula.sqrt(16);           // 4.0

```

### Lambda表达式

老版本的对一个含有字符串的集合进行排序：

```
List<String> names = Arrays.asList("peter", "anna", "mike", "xenia");

Collections.sort(names, new Comparator<String>() {
    @Override
    public int compare(String a, String b) {
        return b.compareTo(a);
    }
});

```

Java8中推荐：

```
Collections.sort(names, (String a, String b) -> {
    return b.compareTo(a);
});
```

函数式接口：**只包含一个抽象方法**的声明，针对该接口类型的所有Lambda表达式都会与这个抽象方法匹配。

Java8中接口的default默认方法不算抽象方法。

Java8允许通过`::`关键字来引用类的方法或构造器。

在Lambda表达式中，可以访问外部的final变量（可为隐式final类型），对成员变量和静态变量拥有读写权限。

带有默认实现的接口方法，可以在匿名内部类中访问，不可使用Lambda表达式访问。

### 内置函数式接口

`Predicate` 是一个可以指定入参类型，并返回 boolean 值的函数式接口。它内部提供了一些带有默认实现的方法，可以 被用来组合一个复杂的逻辑判断（`and`, `or`, `negate`）：

```
Predicate<String> predicate = (s) -> s.length() > 0;

predicate.test("foo");              // true
predicate.negate().test("foo");     // false

Predicate<Boolean> nonNull = Objects::nonNull;
Predicate<Boolean> isNull = Objects::isNull;

Predicate<String> isEmpty = String::isEmpty;
Predicate<String> isNotEmpty = isEmpty.negate();
```

`Function` 函数式接口的作用是，我们可以为其提供一个原料，他给生产一个最终的产品。通过它提供的默认方法，组合,链行处理(`compose`, `andThen`):

```
Function<String, Integer> toInteger = Integer::valueOf;
Function<String, String> backToString = toInteger.andThen(String::valueOf);

backToString.apply("123");     // "123"

```

`Supplier` 与 `Function` 不同，它不接受入参，直接为我们生产一个指定的结果，有点像生产者模式:

```
Supplier<Person> personSupplier = Person::new;
personSupplier.get();   // new Person
```

对于 `Consumer`，我们需要提供入参，用来被消费，如下面这段示例代码：

```
Consumer<Person> greeter = (p) -> System.out.println("Hello, " + p.firstName);
greeter.accept(new Person("Luke", "Skywalker"));
```

`Comparator` 在 Java 8 之前是使用比较普遍的。Java 8 中除了将其升级成了函数式接口，还为它拓展了一些默认方法：

```
Comparator<Person> comparator = (p1, p2) -> p1.firstName.compareTo(p2.firstName);

Person p1 = new Person("John", "Doe");
Person p2 = new Person("Alice", "Wonderland");

comparator.compare(p1, p2);             // > 0
comparator.reversed().compare(p1, p2);  // < 0
```

### Optional

设计它的目的是为了防止空指针异常(NullPointerException).

Optional 类是一个可以为null的容器对象。如果值存在则isPresent()方法会返回true，调用get()方法会返回该对象。

```
Optional<String> optional = Optional.of("bam");

optional.isPresent();           // true
optional.get();                 // "bam"
optional.orElse("fallback");    // "bam"

optional.ifPresent((s) -> System.out.println(s.charAt(0)));     // "b"

```

### Stream流

可以使用`java.util.Stream`对一个包含一个或多个元素的集合做各种操作（中间操作或终端操作）。

只能对实现了`java.util.Collection`接口的类做流的操作。

eg：

```
package com.alone.test.java8;  
  
import org.junit.Test;  
  
import java.util.ArrayList;  
import java.util.List;  
import java.util.Optional;  
import java.util.UUID;  
import java.util.concurrent.TimeUnit;  
import java.util.stream.Collectors;  
  
/**  
 * @BelongsProject: JavaSourceNotes  
 * @BelongsPackage: com.alone.test.java8  
 * @Author: Alone  
 * @CreateTime: 2020-10-04 20:26  
 * @Description: Stream流的使用  
  */  
public class StreamTest {  
  
    /**  
 * filter 过滤  
  */  
  @Test  
  public void test1(){  
        List<String> list = new ArrayList<>();  
        list.add("ddd2");  
        list.add("aaa2");  
        list.add("bbb1");  
        list.add("aaa3");  
        list.add("ccc");  
        list.add("bbb2");  
        list.add("ddd1");  
  
        //filter的入参是一个Predicate,返参同样是一个Stream流,forEach是一个终端操作，打印被筛选的元素  
  list.stream()  
                .filter((s) -> s.startsWith("a"))  
                .forEach(System.out::println);  
    }  
  
    @Test  
  public void test2() {  
        List<String> list = new ArrayList<>();  
        list.add("ddd2");  
        list.add("aaa2");  
        list.add("bbb1");  
        list.add("aaa3");  
        list.add("ccc");  
        list.add("bbb2");  
        list.add("ddd1");  
  
        list.stream()  
                .sorted()  
                .filter((s) -> s.startsWith("a"))  
                .forEach(System.out::println);  
  
        //sorted不会对list做出任何改变,list还是原有的那些元素,且顺序不变  
  System.out.println(list);  
  
        List<String> sortedList = list.stream()  
                .sorted()  
                .filter((s) -> s.startsWith("a"))  
                .collect(Collectors.toList());//将流转换为list  
  System.out.println(sortedList);  
    }  
  
    @Test  
  public void test3() {  
        List<String> list = new ArrayList<>();  
        list.add("ddd2");  
        list.add("aaa2");  
        list.add("bbb1");  
        list.add("aaa3");  
        list.add("ccc");  
        list.add("bbb2");  
        list.add("ddd1");  
  
        //将每一个元素做功能处理  
  list.stream()  
                .map(String::toUpperCase)  
                .sorted((a, b) -> b.compareTo(a))  
                .forEach(System.out::println);  
    }  
  
    /**  
 * match用来做匹配操作  
  * 返回值是一个boolean类型  
  * 可以方便验证一个list中是否存在某个类型的元素  
  */  
  @Test  
  public void test4() {  
        List<String> list = new ArrayList<>();  
        list.add("ddd2");  
        list.add("aaa2");  
        list.add("bbb1");  
        list.add("aaa3");  
        list.add("ccc");  
        list.add("bbb2");  
        list.add("ddd1");  
  
        //验证list中string是否有以a开头的,匹配到第一个,即返回true  
  boolean anyStartsWithA = list.stream()  
                .anyMatch((s) -> s.startsWith("a"));  
        System.out.println(anyStartsWithA);  
  
        //验证list中string是否都是以a开头的  
  boolean allStartsWithA = list.stream()  
                .allMatch((s) -> s.startsWith("a"));  
        System.out.println(allStartsWithA);  
  
        //验证list中string是否都不是以z开头的  
  boolean noneStartsWithZ = list.stream()  
                .noneMatch((s) -> s.startsWith("z"));  
        System.out.println(noneStartsWithZ);  
    }  
  
    /**  
 * count是一个终端操作  
  * 用于统计stream流中的元素总数  
  */  
  @Test  
  public void test5() {  
        List<String> list = new ArrayList<>();  
        list.add("ddd2");  
        list.add("aaa2");  
        list.add("bbb1");  
        list.add("aaa3");  
        list.add("ccc");  
        list.add("bbb2");  
        list.add("ddd1");  
  
        long startsWithB = list.stream()  
                .filter((s) -> s.startsWith("b"))  
                .count();  
        System.out.println(startsWithB);  
    }  
  
    /**  
 * 通过入参的function将list归约成一个值,返回类型为Optional类型  
  */  
  @Test  
  public void test6() {  
        List<String> list = new ArrayList<>();  
        list.add("ddd2");  
        list.add("aaa2");  
        list.add("bbb1");  
        list.add("aaa3");  
        list.add("ccc");  
        list.add("bbb2");  
        list.add("ddd1");  
  
        Optional<String> reduced = list.stream()  
                .sorted()  
                .reduce((s1, s2) -> s1 + "#" + s2);  
        reduced.ifPresent(System.out::println);  
    }  
  
    /**  
 * 顺序流排序和并行流排序  
  * 并行流比顺序流快一倍  
  */  
  @Test  
  public void test7() {  
        int max = 1000000;  
        List<String> values = new ArrayList<>(max);  
        for (int i = 0; i < max; i++) {  
            UUID uuid = UUID.randomUUID();  
            values.add(uuid.toString());  
        }  
  
        long t0 = System.nanoTime();//纳秒  
  long count = values.stream().sorted().count();  
        System.out.println(count);  
  
        long t1 = System.nanoTime();  
        //纳秒转微秒  
  long millis = TimeUnit.NANOSECONDS.toMillis(t1 - t0);  
        System.out.println(String.format("顺序流排序耗时: %d ms", millis));  
  
        // 纳秒  
  long t2 = System.nanoTime();  
  
        long count1 = values.parallelStream().sorted().count();  
        System.out.println(count);  
  
        long t3 = System.nanoTime();  
  
        // 纳秒转微秒  
  long millis1 = TimeUnit.NANOSECONDS.toMillis(t3 - t2);  
        System.out.println(String.format("并行流排序耗时: %d ms", millis1));  
  
    }  
}
```

## 集合

![](https://yueqilai-images.oss-cn-beijing.aliyuncs.com/20171110225615382.png)

### 集合框架底层数据结构

- Collection

  1. List
     - Arraylist： Object数组
     - Vector： Object数组
     - LinkedList： 双向循环链表

  2. Set
     - HashSet（无序，唯一）：基于 HashMap 实现的，底层采用 HashMap 来保存元素
     - LinkedHashSet： LinkedHashSet 继承与 HashSet，并且其内部是通过 LinkedHashMap 来实现的。有点类似于我们之前说的LinkedHashMap 其内部是基于 Hashmap 实现一样，不过还是有一点点区别的。
     - TreeSet（有序，唯一）： 红黑树(自平衡的排序二叉树。)

- Map
  - HashMap： JDK1.8之前HashMap由数组+链表组成的，数组是HashMap的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）.JDK1.8以后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8）时，将链表转化为红黑树，以减少搜索时间
  - LinkedHashMap：LinkedHashMap 继承自 HashMap，所以它的底层仍然是基于拉链式散列结构即由数组和链表或红黑树组成。另外，LinkedHashMap 在上面结构的基础上，增加了一条双向链表，使得上面的结构可以保持键值对的插入顺序。同时通过对链表进行相应的操作，实现了访问顺序相关逻辑。
  - HashTable： 数组+链表组成的，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的
  - TreeMap： 红黑树（自平衡的排序二叉树）

### fail-fast机制

多个线程对同一集合进行结构上的改变的操作时抛出ConcurrentModificationException 异常。

**原因：**

  迭代器在遍历时直接访问集合中的内容，并且在遍历过程中使用一个 modCount 变量。集合在被遍历期间如果内容发生变化，就会改变modCount的值。每当迭代器使用hashNext()/next()遍历下一个元素之前，都会检测modCount变量是否为expectedmodCount值，是的话就返回遍历；否则抛出异常，终止遍历。

**解决方法：**

1. 在遍历过程中，所有涉及到改变modCount值得地方全部加上synchronized。
2. 使用CopyOnWriteArrayList来替换ArrayList

### comparable 和 comparator 的区别？

comparable接口实际上是出自`java.lang`包，可以看做java语言的基础接口,它有一个`compareTo(Object obj)`方法用来排序，comparator接口实际上是出自`java.util`包，表示他是一个工具类，它有一个`compare(Object obj1, Object obj2)`方法用来排序

comparable表示对可排序的集合进行自然排序，comparator表示对可排序的集合进行自定义排序。在排序过程中，首先会去检查Comparator是否存在，如果不存在则会使用默认的natural ordering。还有一个区别就是Comparator允许对null参数的比较，而Comparable是不允许的，否则会爬出NullPointerException。

### SynchronizedList和Vector的区别

- SynchronizedList有很好的扩展和兼容功能。他可以将所有的List的子类转成线程安全的类
- 使用SynchronizedList的时候，进行遍历时要手动进行同步处理。
- SynchronizedList可以指定锁定的对象。

### List和Set的区别

- List是有序容器，Set是无序容器
- List中元素可以重复，Set中不可以存储重复元素
- List查找元素效率较高，插入删除元素效率低，Set插入和删除效率高，查找效率低
- List支持for循环遍历，Set只能用迭代器遍历

### ArrayList的优缺点

- ArrayList的优点如下：
  - ArrayList 底层以数组实现，是一种随机访问模式。ArrayList 实现了 RandomAccess 接口，因此查找的时候非常快。
  - ArrayList 在顺序添加一个元素的时候非常方便。

- ArrayList 的缺点如下：
  - 删除元素的时候，需要做一次元素复制操作。如果要复制的元素很多，那么就会比较耗费性能。
  - 插入元素的时候，也需要做一次元素复制操作，缺点同上。

- ArrayList 比较适合顺序添加、随机访问的场景。

### Arrays.asList为什么不能增加或修改

1.返回的是**内部类**，而内部类对元素的定义是final

```
private final E[] a;
```

2.Arrays继承了AbstractList<E>，而在AbstractList中U对add方法天然就会抛出异常`throw new UnsupportedOperationException();`，平时我们使用的都是ArrayList的add方法，它是进行了重写；

### ArrayList和LinkedList的区别

- 实现上，ArrayList是动态数组的实现，LinkedList是双向链表的实现
- 随机访问效率上，ArrayList比LinkedList效率高，非首尾的增加和删除效率上LinkedList比ArrayList效率高
- 内存空间占用上，LinkedList比ArrayList更占内存

### ArrayList和Vector的区别

- Vector是线程安全的，ArrayList是线程不安全的
- ArrayList在性能方面要优于Vector
- ArrayList每次扩容时容量增加50%，Vector每次增加1倍

### 为什么ArrayList的elementData要加上transient修饰

transient是说不希望elementData数组被序列化，ArrayList中重写了writeObject实现：每次序列化时，先调用`defaultWriteObject()`方法序列化ArrayList中的非transient元素，然后遍历elementData，只序列化已存入的元素，这样既加快了序列化的速度，又减小了序列化之后文件的大小。

### HashSet的实现原理

HashSet 是基于 HashMap 实现的，HashSet的值存放于HashMap的key上，HashMap的value统一为present。

### Set如何检查重复

**HashSet**:

- 添加元素时，判断元素是否存在的依据不仅要比较hash值，还要结合equals方法
- HashSet中的add()方法会使用HashMap的put方法
- HashMap 的 key 是唯一的，由源码可以看出 HashSet 添加进去的值就是作为HashMap 的key，并且在HashMap中如果K/V相同时，会用新的V覆盖掉旧的V，然后返回旧的V。所以不会重复

**TreeSet**:

TreeSet的底层是TreeMap的keySet()，而TreeMap是基于红黑树实现的，红黑树是一种平衡二叉查找树，它能保证任何一个节点的左右子树的高度差不会超过较矮的那棵的一倍。

TreeMap是按key排序的，元素在插入TreeSet时compareTo()方法要被调用，所以TreeSet中的元素要实现Comparable接口。TreeSet作为一种Set，它不允许出现重复元素。TreeSet是用compareTo()来判断重复元素的。

### hashmap1.7和1.8的区别

不同点：

- JDK1.7用的是头插法，JDK1.8及之后使用的都是尾插法，因为JDK1.7是用单链表进行的纵向延伸，当采用头插法时会容易出现逆序且环形链表死循环问题。在JDK1.8之后是因为加入了红黑树使用尾插法，能够避免出现逆序且链表死循环的问题。

- 扩容后数据存储位置的计算方式也不一样： 

  在JDK1.7的时候是直接用hash值和需要扩容的二进制数进行&，而在JDK1.8的时候直接用了JDK1.7的时候计算的规律，也就是扩容前的原始位置+扩容的大小值，这种方式就相当于只需要判断Hash值的新增参与运算的位是0还是1即可。

- JDK1.7使用数组+单链表的数据结构，JDK1.8及之后时使用数组+链表+红黑树的数据结构

### 为什么扩容的时候一定必须是2的多少次幂

如果只有2的n次幂的情况时最后一位二进制数才一定是1，这样能最大程度减少hash碰撞

### 为什么JDK1.7的时候是先进行扩容后进行插入，而JDK1.8的时候是先插入后扩容

在JDK1.7中是先进行扩容后进行插入的，当你发现你插入的桶为空时，说明存在值发生了hash冲突，那么就必须扩容。但是如果不发生hash冲突的话，说明当前桶是空的（后面并没有挂有链表），那就等到下一次发生Hash冲突的时候再进行扩容，但是如果以后都没有发生hash冲突，那么就不会进行扩容了，减少了一次无用扩容。

### 为什么在JDK1.8中进行hashmap优化时，把链表转化为红黑树的阈值是8，而不是7或20呢？

如果选择6和8，中间有个差值7，可以有效防止链表和树频繁转换。

由于treenodes的大小大约是常规节点的两倍，因此我们仅在容器包含足够的节点以保证使用时才使用它们，当它们变得太小（由于移除或调整大小）时，它们会被转换回普通的node节点，容器中节点分布在hash桶中的频率遵循泊松分布，桶的长度超过8的概率非常非常小。所以作者应该是根据概率统计而选择了8作为阀值

### 哈希表如何解决Hash冲突

![](https://img-blog.csdn.net/20180905105313470?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2NTIwMjM1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

### 为什么hashmap具备下述特点：键-值(key-value)都允许为空，线程不安全，不保证有序，存储位置随时间变化

![](https://img-blog.csdn.net/20180905105402336?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2NTIwMjM1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

### 为什么HashMap中String,Integer这样的包装类适合作为key键

![](https://img-blog.csdn.net/20180905105453712?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2NTIwMjM1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

### HashMap中的key若Object类型，则需实现哪些方法?

![](https://img-blog.csdn.net/20180905105527545?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2NTIwMjM1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

### Hashmap1.7和1.8扩容机制对比

![](https://img-blog.csdn.net/20180905105129591?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2NTIwMjM1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

https://blog.csdn.net/qq_36520235/article/details/82417949

### hashmap put方法流程

**JDK1.7：**

- 判断当前数组是否需要初始化。
- 如果 key 为空，则 put 一个空值进去。
- 根据 key 计算出 hashcode。
- 根据计算出的 hashcode 定位出所在桶。
- 如果桶是一个链表则需要遍历判断里面的 hashcode、key 是否和传入 key 相等，如果相等则进行覆盖，并返回原来的值。
- 如果桶是空的，说明当前位置没有数据存入；新增一个 Entry 对象写入当前位置。

**JDK1.8：**

1. 判断当前桶是否为空，空的就需要初始化（resize 中会判断是否进行初始化）。
2. 根据当前 key 的 hashcode 定位到具体的桶中并判断是否为空，为空表明没有 Hash 冲突就直接在当前位置创建一个新桶即可。
3. 如果当前桶有值（ Hash 冲突），那么就要比较当前桶中的 `key、key 的 hashcode` 与写入的 key 是否相等，相等就赋值给 `e`,在第 8 步的时候会统一进行赋值及返回。
4. 如果当前桶为红黑树，那就要按照红黑树的方式写入数据。
5. 如果是个链表，就需要将当前的 key、value 封装成一个新节点写入到当前桶的后面（形成链表）。
6. 接着判断当前链表的大小是否大于预设的阈值，大于时就要转换为红黑树。
7. 如果在遍历过程中找到 key 相同时直接退出遍历。
8. 如果 `e != null` 就相当于存在相同的 key,那就需要将值覆盖。
9. 最后判断是否需要进行扩容。

https://crossoverjie.top/2018/07/23/java-senior/ConcurrentHashMap/

### 为什么头插法会产生死循环

https://blog.csdn.net/littlehaes/article/details/105241194

### HashMap与HashTable的区别

- HashMap是非线程安全的，HashTable是线程安全的，HashMap比HashTable效率高一些
- HashMap中可以用null作为键，HashTable中put进的键值只要有一个null，直接抛NullPointerException
- 创建时如果不指定容量初始值，Hashtable默认的初始大小为11，之后每次扩充为原来的2n+1.HashMap默认的初始化大小为16，之后每次扩充，容量变为原来的2倍。创建时如果给定了容量初始值，那么Hashtable会直接使用你给定的大小，而HashMap会将其扩充为2的幂次方的大小。

### TreeMap

是一个有序的线程不同步的key-value集合，基于红黑树实现，该映射根据**其键的自然顺序进行排序**，或者根据**创建映射时提供的 Comparator 进行排序**（具体取决于使用的构造方法。）

### 如何决定使用 HashMap 还是 TreeMap？

对于在Map中插入、删除和定位元素这类操作，HashMap是最好的选择。然而，假如你需要对一个有序的key集合进行遍历，TreeMap是更好的选择。

### HashMap 和 ConcurrentHashMap 的区别

1. ConcurrentHashMap对整个桶数组进行了分割分段(Segment)，然后在每一个分段上都用lock锁进行保护，相对于HashTable的synchronized锁的粒度更精细了一些，并发性能更好，而HashMap没有锁机制，不是线程安全的。（JDK1.8之后ConcurrentHashMap启用了一种全新的方式实现,利用CAS算法。）
2. HashMap的键值对允许有null，但是ConCurrentHashMap都不允许。

### ConcurrentHashMap 基本结构

首先将数据分为一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据时，其他段的数据也能被其他线程访问。

**JDK1.7**：

ConcurrentHashMap采用Segment + HashEntry的方式进行实现，结构如下：

一个 ConcurrentHashMap 里包含一个 Segment 数组。Segment 的结构和HashMap类似，是一种数组和链表结构，一个 Segment 包含一个 HashEntry 数组，每个 HashEntry 是一个链表结构的元素，每个 Segment 守护着一个HashEntry数组里的元素，当对 HashEntry 数组的数据进行修改时，必须首先获得对应的 Segment的锁。

![](https://user-gold-cdn.xitu.io/2020/4/13/171735524c5089b8?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

1.该类包含两个静态内部类 HashEntry 和 Segment ；前者用来封装映射表的键值对，后者用来充当锁的角色；

2.Segment 是一种可重入的锁 ReentrantLock，每个 Segment 守护一个HashEntry 数组里得元素，当对 HashEntry 数组的数据进行修改时，必须首先获得对应的 Segment 锁。

**JDK1.8**:

**放弃了Segment臃肿的设计，取而代之的是采用Node + CAS + Synchronized来保证并发安全进行实现**，synchronized只锁定当前链表或红黑二叉树的首节点，这样只要hash不冲突，就不会产生并发，效率又提升N倍。

![](https://user-gold-cdn.xitu.io/2020/4/13/17173552564c22be?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

### ConcurrentHashMap put方法流程

**JDK1.8：**

- 根据 key 计算出 hashcode 。
- 判断是否需要进行初始化。
- `f` 即为当前 key 定位出的 Node，如果为空表示当前位置可以写入数据，利用 CAS 尝试写入，失败则自旋保证成功。
- 如果当前位置的 `hashcode == MOVED == -1`,则需要进行扩容。
- 如果都不满足，则利用 synchronized 锁写入数据。
- 如果数量大于 `TREEIFY_THRESHOLD` 则要转换为红黑树。

### ConcurrentHashMap 扩容流程（还没写）

https://www.jianshu.com/p/487d00afe6ca

1.线程执行put操作，发现容量已经达到扩容阈值，需要进行扩容操作，此时transferindex=tab.length=32

2.扩容线程A 以cas的方式修改transferindex=31-16=16 ,然后按照降序迁移table[31]--table[16]这个区间的hash桶

3.迁移hash桶时，会将桶内的链表或者红黑树，按照一定算法，拆分成2份，将其插入nextTable[i]和nextTable[i+n]（n是table数组的长度）。 迁移完毕的hash桶,会被设置成ForwardingNode节点，以此告知访问此桶的其他线程，此节点已经迁移完毕。

4.此时线程2访问到了ForwardingNode节点，如果线程2执行的put或remove等写操作，那么就会先帮其扩容。如果线程2执行的是get等读方法，则会调用ForwardingNode的find方法，去nextTable里面查找相关元素。

### ConcurrentHashMap为什么不能存值为null的value（主要学习作者的学习方式）

https://mp.weixin.qq.com/s?__biz=MzIxNTQ4MzE1NA==&mid=2247484354&idx=1&sn=80c92881b47a586eba9c633eb78d36f6&chksm=9796d5bfa0e15ca9713ff9dc6e100593e0ef06ed7ea2f60cb984e492c4ed438d2405fbb2c4ff&scene=21#wechat_redirect

## 阻塞队列(BlockingQueue）

实现原理：https://blog.csdn.net/chenchaofuck1/article/details/51660119

阻塞队列与我们平常接触的普通队列(LinkedList或ArrayList等)的最大不同点，在于阻塞队列支出阻塞添加和阻塞删除方法。

- 阻塞添加
  所谓的阻塞添加是指当阻塞队列元素已满时，队列会阻塞加入元素的线程，直队列元素不满时才重新唤醒线程执行元素加入操作。
- 阻塞删除
  阻塞删除是指在队列元素为空时，删除队列元素的线程将被阻塞，直到队列不为空再执行删除操作(一般都会返回被删除的元素)

实现类：

- **ArrayBlockingQueue**：ArrayBlockingQueue 是一个有界的阻塞队列，其内部实现是将对象放到一个数组里。
- **DelayQueue**：DelayQueue 对元素进行持有直到一个特定的延迟到期。注入其中的元素必须实现 java.util.concurrent.Delayed 接口。
- **LinkedBlockingQueue**：LinkedBlockingQueue 内部以一个链式结构(链接节点)对其元素进行存储。如果需要的话，这一链式结构可以选择一个上限。如果没有定义上限，将使用 Integer.MAX_VALUE 作为上限。
- **PriorityBlockingQueue**：PriorityBlockingQueue 是一个无界的并发队列。它使用了和类 java.util.PriorityQueue 一样的排序规则。你无法向这个队列中插入 null 值。所有插入到 PriorityBlockingQueue 的元素必须实现 java.lang.Comparable 接口。因此该队列中元素的排序就取决于你自己的 Comparable 实现。
- **SynchronousQueue**：SynchronousQueue 是一个特殊的队列，它的内部同时只能够容纳单个元素。如果该队列已有一元素的话，试图向队列中插入一个新元素的线程将会阻塞，直到另一个线程将该元素从队列中抽走。同样，如果该队列为空，试图向队列中抽取一个元素的线程将会阻塞，直到另一个线程向队列中插入了一条新的元素。据此，把这个类称作一个队列显然是夸大其词了。它更多像是一个汇合点。

### LinkedBlockingQueue和ArrayBlockingQueue（没写完）

ArrayBlockingQueue内部的阻塞队列是通过重入锁ReenterLock和Condition条件队列实现的，所以ArrayBlockingQueue中的元素存在公平访问与非公平访问的区别，对于公平访问队列，被阻塞的线程可以按照阻塞的先后顺序访问队列，即先阻塞的线程先访问队列。而非公平队列，当队列可用时，阻塞的线程将进入争夺访问资源的竞争中，也就是说谁先抢到谁就执行，没有固定的先后顺序。

https://blog.csdn.net/javazejian/article/details/77410889

## 多线程

### 生产者消费者模式的实现（还没写）


### 线程和进程的区别

- 进程是操作系统资源分配的基本单位，而线程是处理器任务调度和执行的基本单位
- 每个进程都有独立的代码和数据空间（程序上下文），程序之间的切换会有较大的开销；同一类线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器（PC），线程之间切换的开销小。
- 同一进程的线程共享本进程的地址空间和资源，而进程与进程之间的地址空间和资源是相互独立的
- 一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃有可能导致整个进程都死掉。
- 每个独立的进程有程序运行的入口、顺序执行序列和程序出口。但是线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制，两者均可并发执行

### 创建线程的四种方式

- 采用实现Runnable创建多线程
- 使用继承Thread类的方式创建多线程
- 采用实现Callable接口的方式创建多线程
- 通过创建线程池来创建线程

### 上下文切换

当前任务在执行完 CPU 时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。任务从保存到再加载的过程就是一次上下文切换。

### 线程状态转换关系

![](https://user-gold-cdn.xitu.io/2018/4/30/163159b8a740b329?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

阻塞的情况分三种：

- (一). 等待阻塞：运行状态中的线程执行 wait()方法，JVM会把该线程放入等待队列(waitting queue)中，使本线程进入到等待阻塞状态；
- (二). 同步阻塞：线程在获取 synchronized 同步锁失败(因为锁被其它线程所占用)，，则JVM会把该线程放入锁池(lock pool)中，线程会进入同步阻塞状态；
- (三). 其他阻塞: 通过调用线程的 sleep()或 join()或发出了 I/O 请求时，线程会进入到阻塞状态。当 sleep()状态超时、join()等待线程终止或者超时、或者 I/O 处理完毕时，线程重新转入就绪状态。


### sleep()和wait()的区别

![](https://yueqilai-images.oss-cn-beijing.aliyuncs.com/20180723171041981.png)

### sleep()和yield()的区别

- sleep()方法给其他线程运行机会时不考虑线程的优先级，yield()方法只会给相同优先级或更高优先级的线程以运行的机会
- 线程执行sleep()方法后转入阻塞(blocked)状态，而执行yield()方法后转入就绪(ready)状态
- sleep()方法声明抛出InterruptedException,而yield()方法没有声明任何异常
- sleep()方法比yield()方法具有更好的移植性，不建议使用yield()方法来控制并发线程的执行

### 形成死锁的四个条件

- 互斥条件：在一段时间内某资源只由一个进程占用
- 占有且等待条件：指进程已经保持至少一个资源，但又提出了新的资源请求，而该资源已被其它进程占有，此时请求进程阻塞，但又对自己已获得的其它资源保持不放。
- 不可抢占条件：别人已经占有了某项资源，你不能因为自己也需要该资源，就去把别人的资源抢过来。
- 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。

### 如何避免线程死锁

- 避免一个线程同时获得多个锁
- 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源
- 尝试使用定时锁，使用`lock.tryLock(timeout)`来替代使用内部锁机制

### Java中用到的线程调度算法

- 分时调度模型：让所有的线程轮流获得cpu的使用权，并且平均分配每个线程占用的CPU的时间片
- 抢占式调度模型：是指优先让可运行池中优先级高的线程占用CPU，如果可运行池中的线程优先级相同，那么就随机选择一个线程，使其占用CPU。处于运行状态的线程会一直运行，直至它不得不放弃 CPU。

### 终止线程运行的情况

- 线程体中调用了 yield 方法让出了对 cpu 的占用权利
- 线程体中调用了 sleep 方法使线程进入睡眠状态
- 线程由于 IO 操作受到阻塞
- 另外一个更高优先级线程出现
- 在支持时间片的系统中，该线程的时间片用完

### 重排序实际执行的指令步骤

- 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。
- 指令级并行的重排序。现代处理器采用了指令级并行技术（ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。
- 内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。

### as-if-serial和happens-before规则的区别

- as-if-serial语义保证单线程内程序的执行结果不被改变，happens-before关系保证正确同步的多线程程序的执行结果不被改变
- as-if-serial语义给编写单线程程序的程序员创造了一个幻境：单线程程序是按程序的顺序来执行的。happens-before关系给编写正确同步的多线程程序的程序员创造了一个幻境：正确同步的多线程程序是按happens-before指定的顺序来执行的。

### Java内存模型（JMM）

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/89b87f6e8db04a8dbe99416f9ff05ac2~tplv-k3u1fbpfcp-zoom-1.image)

JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存中，每个线程都有一个私有的本地内存，本地内存中存储了该线程以读/写共享变量的副本。

线程A与线程B之间如果要通信的话，必须要经历下面两个步骤：

- 线程A把本地内存A中更新过的共享变量刷新到主内存中去
- 线程B到主内存中去读取线程A之前已更新过的共享变量

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6ebd1754a928408b9228db964bac49a8~tplv-k3u1fbpfcp-zoom-1.image)

几个规范:

- 所有变量存储在主内存
- 主内存是虚拟机内存的一部分
- 每条线程有自己的工作内存
- 线程的工作内存保存变量的主内存副本
- 线程对变量的操作必须在工作内存中进行
- 不同线程之间无法直接访问对方工作内存中的变量
- 线程间变量值的传递均需要通过主内存来完成

### volatile

[好文](https://juejin.cn/post/6861885337568804871#heading-24)

**三大特性**：

- 保证可见性
- 不保证原子性
- 禁止指令重排

#### 为什么其他线程能感知到变量更新?（原理）

缓存一致性:

当多个CPU持有的缓存都来自同一个主内存的拷贝，当有其他CPU偷偷改了这个主内存数据后，其他CPU并不知道，那拷贝的内存将会和主内存不一致，这就是缓存不一致。

通过MESI协议来保证缓存一致性:

当CPU写数据时，如果发现操作的变量是共享变量，即在其它CPU中也存在该变量的副本，系统会发出信号通知其它CPU将该内存变量的缓存行设置为无效。当其它CPU读取这个变量的时，发现自己缓存该变量的缓存行是无效的，那么它就会从内存中重新读取。

使用总线嗅探技术使其他CPU知道要将缓存更新为失效：

每个CPU不断嗅探总线上传播的数据来检查自己缓存值是否过期了，如果处理器发现自己的缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置为无效状态，当处理器对这个数据进行修改操作的时候，会重新从内存中把数据读取到处理器缓存中。

缺点在于需要不断对主线进行内存嗅探，大量的交互会导致总线带宽达到峰值。

再概述一遍：

当对volatile变量进行写操作的时候，JVM会向处理器发送一条lock前缀的指令，将这个缓存中的变量回写到系统主存中。此时为了保证各个处理器的缓存是一致的，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器要对这个数据进行修改操作的时候，会强制重新从系统内存里把数据读到处理器缓存里。

**指令重排**:

方式:

1.编译器优化重排：编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。


2.指令级的并行重排：现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。


3.内存系统的重排：由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/60ea5804fd9e43aa8a1205e1988645b4~tplv-k3u1fbpfcp-zoom-1.image)

#### volatile如何实现禁止指令重排

原理：在volatile生成的指令序列前后插入内存屏障（Memory Barries）来禁止处理器重排序。

有四种内存屏障:

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c9eb55cfc2514d5b967005c9591ea433~tplv-k3u1fbpfcp-zoom-1.image)

volatile写的场景如何插入内存屏障:

- 在每个volatile写操作的前面插入一个StoreStore屏障（写-写 屏障）。
- 在每个volatile写操作的后面插入一个StoreLoad屏障（写-读 屏障）。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2d4909f2b35745839b92ddee883774a3~tplv-k3u1fbpfcp-zoom-1.image)

volatile读场景如何插入内存屏障：

- 在每个volatile读操作的后面插入一个LoadLoad屏障（读-读 屏障）。
- 在每个volatile读操作的后面插入一个LoadStore屏障（读-写 屏障）。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/abe11d4910354a019053d9cab3440818~tplv-k3u1fbpfcp-zoom-1.image)

### 多线程8锁

#### 公平锁/非公平锁

1. 公平锁是指多个线程按照申请锁的顺序来获取锁。（先到先得，非常公平）
2. 非公平锁是指多个线程获取锁的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁。有可能，会造成优先级反转或者饥饿现象。

#### 可重入锁

可重入锁又名递归锁，是指在同一个线程在外层方法获取锁的时候，在进入内层方法会自动获取锁。

#### 独享锁/共享锁

1. 独享锁是指该锁一次只能被一个线程所持有。
2. 共享锁是指该锁可被多个线程所持有。

#### 互斥锁/读写锁

上面讲的独享锁/共享锁就是一种广义的说法，互斥锁/读写锁就是具体的实现。
互斥锁在Java中的具体实现就是ReentrantLock
读写锁在Java中的具体实现就是ReadWriteLock

#### 乐观锁/悲观锁

乐观锁与悲观锁不是指具体的什么类型的锁，而是指看待并发同步的角度。

1. 悲观锁认为对于同一个数据的并发操作，一定是会发生修改的，哪怕没有修改，也会认为修改。因此对于同一个数据的并发操作，悲观锁采取加锁的形式。悲观的认为，不加锁的并发操作一定会出问题。
2. 乐观锁则认为对于同一个数据的并发操作，是不会发生修改的。在更新数据的时候，会采用尝试更新，不断重新的方式更新数据。乐观的认为，不加锁的并发操作是没有事情的。

实现：

1. 悲观锁在Java中的使用，就是利用各种锁。
2. 乐观锁在Java中的使用，是无锁编程，常常采用的是CAS算法，典型的例子就是原子类，通过CAS自旋实现原子操作的更新。

#### 分段锁

​	分段锁其实是一种锁的设计，并不是具体的一种锁，对于ConcurrentHashMap而言，其并发的实现就是通过分段锁的形式来实现高效的并发操作。ConcurrentHashMap内部就是用了分段锁。
​    分段锁的设计目的是细化锁的粒度，当操作不需要更新整个数组的时候，就仅仅针对数组中的一项进行加锁操作。

#### 偏向锁/轻量级锁/重量级锁

1. 偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁。降低获取锁的代价。
2. 轻量级锁是指当锁是偏向锁的时候，被另一个线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，提高性能。
3. 重量级锁是指当锁为轻量级锁的时候，另一个线程虽然是自旋，但自旋不会一直持续下去，当自旋一定次数的时候，还没有获取到锁，就会进入阻塞，该锁膨胀为重量级锁。重量级锁会让其他申请的线程进入阻塞，性能降低。

**从偏向锁->轻量级锁->重量级锁 是锁升级过程，该过程不可逆**

#### 自旋锁

在Java中，自旋锁是指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁，这样的好处是减少线程上下文切换的消耗，缺点是循环会消耗CPU。

### 锁机制（b站那个视频没总结完）

在Java中每个对象都有一把锁，存放于对象头中，锁中记录当前对象是被哪个线程所占用。

对象的结构又分为对象头，实例数据和对齐填充，对齐填充是为了满足Java对象的大小必须是8字节的倍数而设计。实例数据是在初始化时设定的属性和状态的内容。

对象头存放对象本身的运行时信息，包含两部分Mark word和class pointer。class pointer就是一个指针，指向当前对象类型所在方法区中的类型数据。mark word存储了很多和当前对象运行时状态有关的数据。(那个表格)mark word最后两位为锁标志位。
synchronized编译后生成monitorenter和monitorexit两个字节码指令来进行线程同步。monitor的原理是首先entryset中聚集了一些想要进入monitor的线程，他们正处于waiting状态，假设线程a成功进入monitor，它就变为active状态，此时若线程执行途中遇到了一个判断条件需要暂时让出执行权，它将进入wait set，状态变为waiting，此时entry set中的线程可以进入monitor。当monitor中的线程执行完毕后可以唤醒其他线程继续执行。synchronized可能会有性能问题，因为monitor是依赖操作系统的mutex lock来实现的。JAVA线程实际是对操作系统线程的映射，所以每当挂起或唤醒一个线程都要切换操作系统内核态。
1.6开始，对synchronized进行了优化，锁总共有四种状态。(后面有点长)

### synchronized和Lock的区别

- synchronized是Java内置关键字,Lock是Java类
- synchronized可以给类，方法，代码块加锁，而lock只能给代码块加锁
- synchronized不需要手动获取锁和释放锁，使用简单，发生异常会自动释放锁，不会造成死锁；而lock需要自己加锁和释放锁，如果使用不当没有unLock()去释放锁就会造成死锁
- 通过Lock可以知道有没有成功获取锁，而synchronized却无法办到.

### synchronized和ReentrantLock的区别

- ReentrantLock使用起来比较灵活，但是必须有释放锁的配合动作
- ReentrantLock必须手动获取与释放锁，而synchronized不需要手动释放和开启锁
- ReentrantLock只适用于代码块锁,而synchronized可以修饰类，方法，变量等。
- ReentrantLock底层调用的是Unsafe的park方法加锁，synchronized操作的应该是对象头中的mark word

### synchronized和volatile的区别

- volatile是变量修饰符,synchronized可以修饰类，方法，变量
- volatile仅能实现变量的修改可见性，不能保证原子性;而synchronized则可以保证变量的修改可见性和原子性
- volatile不会造成线程的阻塞,synchronized可能会造成线程的阻塞
- volatile标记的变量不会被编译器优化,synchronized标记的变量可以被编译器优化

### 为什么synchronized无法禁止指令重排，却能保证有序性？

synchronized通过排他锁的方式就保证了同一时间内，被synchronized修饰的代码是单线程执行的。

### CAS

CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。如果内存地址里面的值和 A 的值是一样的，那么就将内存里面的值更新成 B。

### CAS产生的问题

- ABA问题:
  一个线程 one 从内存位置 V 中取出 A，这时候另一个线程 two 也从内存中取出 A，并且 two 进行了一些操作变成了 B，然后 two 又将 V 位置的数据变成 A，这时候线程 one 进行 CAS 操作发现内存中仍然是 A，然后 one 操作成功。
- 循环时间长开销大:
  对于资源竞争严重（线程冲突严重）的情况，CAS 自旋的概率会比较大，从而浪费更多的 CPU 资源，效率低于 synchronized
- 只能保证一个共享变量的原子操作

### 线程池

#### 参数

```java
ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue<Runnable> workQueue,
                              ThreadFactory threadFactory,
                              RejectedExecutionHandler handler) 
```

- corePoolSize：核心线程数量

  如果线程池收到任务，且线程池内部线程数量没有达到corePoolSize，线程池会直接给此任务创建一个新线程来处理此任务。具体是创建一个Work对象，此Work持有此任务Runnable、此线程Thread的引用。最后将此Work放入一个名叫workers的Set集合中。0 =< workers.size <=maximumPoolSize。

- maximumPoolSize: 最大允许线程数量

  线程池内部线程数量已经达到核心线程数量，即corePoolSize，并且任务队列已满，此时如果继续有任务被提交，将判断线程池内部线程总数是否达到maximumPoolSize，如果小于maximumPoolSize，将继续使用线程工厂创建新线程。如果线程池内线程数量等于maximumPoolSize，就不会继续创建线程，将触发拒绝策略RejectedExecutionHandler。新创建的同样是一个Work对象，并最终放入workers集合中。

- keepAliveTime, unit:超出线程的存活时间

  当线程池内部的线程数量大于corePoolSize，则多出来的线程会在keepAliveTime时间之后销毁。

- workQueue:任务队列

  线程池需要执行的任务的队列，通常有固定数量的ArrayBlockingQueue,无限制的LinkedBlockingQueue.

- threadFactory:线程工厂，用于创建线程

- handler���任务拒绝策略

  当任务队列已满，又有新的任务进来时，会回调此接口。

#### 四种拒绝策略

`ThreadPoolExecutor.AbortPolicy`:丢弃任务并抛出RejectedExecutionException异常。
`ThreadPoolExecutor.DiscardPolicy`：丢弃任务，但是不抛出异常。
`ThreadPoolExecutor.DiscardOldestPolicy`：丢弃队列最前面的任务，然后重新提交被拒绝的任务
`ThreadPoolExecutor.CallerRunsPolicy`：由调用线程（提交任务的线程）处理该任务,一般在不允许失败的、对性能要求不高、并发量较小的场景下使用

#### 线程池触发拒绝策略的时机

当提交的任务数大于corePoolSize时,会优先放到队列缓冲区,只有填满了缓冲区后,才会判断当前运行的任务是否大于maxPoolSize,小于时会新建线程处理,大于时就触发了拒绝策略.

#### 四类不同的线程池

- newCachedThreadPool:创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程
- newFixedThreadPool:创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待
- newScheduledThreadPool:创建一个定长线程池，支持定时及周期性任务执行
- newSingleThreadExecutor:创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行

#### 工作流程

![](https://upload-images.jianshu.io/upload_images/4134622-fbbdbcb6bcc00178.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

#### 如何实现线程复用

1、当Thread的run方法执行完一个任务之后，会循环地从阻塞队列中取任务来执行，这样执行完一个任务之后就不会立即销毁了；

2、当工作线程数小于核心线程数，那些空闲的核心线程再去队列取任务的时候，如果队列中的Runnable数量为0，就会阻塞当前线程，这样线程就不会回收了

https://www.jianshu.com/p/5e952ab2c41b

### CountDownLatch,CyclicBarrier,Semaphore

CountDownLatch:

​	允许一个或多个线程一直等待，直到一组在其他线程执行的操作全部完成

​	当一个线程调用await方法时，就会阻塞当前线程。每当有线程调用一次countDown方法时，计数就会减1。当count的值等于0的时候，被阻塞的线程才会继续运行。

CyclicBarrier:

让所有线程都等待完成后才会继续下一步行动

CyclicBarrier初始化时规定一个数目，然后计算调用了CyclicBarrier.await()进入等待的线程数。当线程数达到了这个数目时，所有进入等待状态的线程被唤醒并继续。

Semaphore:

Semaphore是一种基于计数的信号量。它可以设定一个阈值，基于此，多个线程竞争获取许可信号，做自己的申请后归还，超过阈值后，线程申请许可信号将会被阻塞。

### AQS（没写完）

AQS 全称是 AbstractQueuedSynchronizer，是一个用来构建**锁**和**同步器**的框架，它维护了一个共享资源 state 和一个 FIFO 的等待队列，底层利用了 CAS 机制来保证操作的原子性。

**AQS锁的实现原理：**

![img](https://mmbiz.qpic.cn/mmbiz_jpg/OyweysCSeLUw3oEcJTUMphCBvlHmY65EaNibqm2VepgYQCicnCf3ibjdLUNjxNg3Z7YmWPMYC16ZqmwvT72DQ0FqA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



以实现独占锁为例（即当前资源只能被一个线程占有），其实现原理如下：state 初始化 0，在多线程条件下，线程要执行临界区的代码，必须首先获取 state，某个线程获取成功之后， state 加 1，其他线程再获取的话由于共享资源已被占用，所以会到 FIFO 等待队列去等待，等占有 state 的线程执行完临界区的代码释放资源( state 减 1)后，会唤醒 FIFO 中的下一个等待线程（head 中的下一个结点）去获取 state。

state 由于是多线程共享变量，所以必须定义成 volatile，以保证 state 的可见性, 同时虽然 volatile 能保证可见性，但不能保证原子性，所以 AQS 提供了对 state 的原子操作方法，保证了线程安全。

另外 AQS 中实现的 FIFO 队列（CLH 队列）其实是双向链表实现的，由 head, tail 节点表示，head 结点代表当前占用的线程，其他节点由于暂时获取不到锁所以依次排队等待锁释放。

#### 获取锁

### JDBC流程

第一步：加载Driver类，注册数据库驱动；
第二步：通过DriverManager,使用url，用户名和密码建立连接(Connection)；
第三步：通过Connection，使用sql语句打开Statement对象；
第四步：执行语句，将结果返回resultSet；
第五步：对结果resultSet进行处理；
第六步：倒叙释放资源resultSet-》preparedStatement-》connection。

# JVM

## 四种引用(没写完)

### 虚引用

主要用来**跟踪对象**被垃圾回收器**回收**的活动。 

**虚引用**与**软引用**和**弱引用**的一个区别在于：虚引用必须和引用队列(ReferenceQueue)联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。

简单的说是，虚引用是用来判断对象是否被即将回收，然后程序再采取相应的措施

```java
    String str = new String("abc");
    ReferenceQueue queue = new ReferenceQueue();
    // 创建虚引用，要求必须与一个引用队列关联
    PhantomReference pr = new PhantomReference(str, queue);
复制代码
```

### 软引用

有用但不是必须的对象，在发生内存溢出之前会被回收

### 弱引用

有用但不是必须的对象，在下一次GC时会被回收

### 强引用

发生gc的时候不会被回收

## finalize()方法什么时候被调用？

垃圾回收器准备释放对象占用的内存时，将首先调用该对象的finalize()方法，并且下一次垃圾回收动作发生时，才真正回收对象占用的内存空间。

## JVM的结构

![](https://user-gold-cdn.xitu.io/2020/4/13/171729fc868d44b7?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

首先通过编译器把 Java 代码转换成字节码，类加载器（ClassLoader）再把字节码加载到内存中，将其放在运行时数据区（Runtime data area）的方法区内，而字节码文件只是 JVM 的一套指令集规范，并不能直接交给底层操作系统去执行，因此需要特定的命令解析器执行引擎（Execution Engine），将字节码翻译成底层系统指令，再交由 CPU 去执行，而这个过程中需要调用其他语言的本地库接口（Native Interface）来实现整个程序的功能。

## 运行时数据区

- 程序计数器（Program Counter Register）：当前线程所执行的字节码的行号指示器，分支、循环、跳转、异常处理、线程恢复等基础功能，都需要依赖这个计数器来完成
- Java 虚拟机栈（Java Virtual Machine Stacks）：每个方法在执行的同时都会在Java 虚拟机栈中创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息
- 本地方法栈（Native Method Stack）：与虚拟机栈的作用是一样的，只不过虚拟机栈是服务 Java 方法的，而本地方法栈是为虚拟机调用 Native 方法服务的；
- Java 堆（Java Heap）：Java 虚拟机中内存最大的一块，是被所有线程共享的，几乎所有的对象实例都在这里分配内存
- 方法区（Methed Area）：用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译后的代码等数据

### 虚拟机栈

虚拟机栈描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息

**解析栈帧**

局部变量表：是用来存储我们临时8个基本数据类型、对象引用地址、returnAddress类型。（returnAddress中保存的是return后要执行的字节码的指令地址。）由于它是线程的私有数据,因此不存在数据安全问题.

局部变量表所需要的容量大小是编译期确定下来的.其中的变量只在当前方法调用中有效.

最基本的存储单元是Slot(变量槽),32位以内的类型(包括returnAddress类型)只占用一个Slot,64位的类型(long和double)占用两个连续的Slot.JVM 会为局部变量表中的每一个 Slot 都分配一个访问索引，通过这个索引即可成功访问到局部变量表中指定的局部变量值.

局部变量表中的变量也是重要的垃圾回收根节点，只要被局部变量表中直接或间接引用的对象都不会被回收

操作数栈：操作数栈主要用于保存计算过程的中间结果，同时作为计算过程中变量临时的存储空间,如果被调用的方法带有返回值的话，其返回值将会被压入当前栈帧的操作数栈中

将栈顶元素全部缓存在物理 CPU 的寄存器中，以此降低对内存的读/写次数，提升执行引擎的执行效率

动态链接：每一个栈帧内部都包含一个指向运行时常量池中该栈帧所属方法的引用,在 Java 源文件被编译到字节码文件中时，所有的变量和方法引用都作为符号引用（Symbolic Reference）保存在 Class 文件的常量池中,动态链接的作用就是为了将符号引用转换为调用方法的直接引用

![](https://user-gold-cdn.xitu.io/2020/7/20/17369d17ff0af244?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

方法返回地址：出口正常的话就是return，不正常的话就是抛出异常。

![](https://user-gold-cdn.xitu.io/2020/7/20/17369d17dfe1593d?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

### 程序计数器

用来存储指向下一条指令的地址(Java方法->JVM 字节码指令地址),如果是执行native方法,则是undefined.

## JVM如何执行方法调用

方法调用阶段的唯一任务就是确定被调用方法的版本.一切方法调用在 Class文件里面存储的都是符号引用，而不是方法在实际运行时内存布局中的入口地址（直接引用）。需要在类加载阶段，甚至到运行期才能确定目标方法的直接引用。

如果方法在编译器就确定了具体的调用版本，这个版本在运行时是不可变的。这样的方法称为非虚方法,其他方法称为虚方法.

JVM 采用在类的方法区建立一个虚方法表，表中存放着各个方法的实际入口。虚方法表会在类加载的连接阶段被创建并开始初始化，类的变量初始值准备完成之后，JVM 会把该类的方法表也初始化完毕。

## TLAB分配

每个线程在Java堆中预先分配一小块内存，然后再给对象分配内存的时候，直接在自己这块”私有”内存中分配，当这部分区域用完之后，再分配新的”私有”内存。

不过每次申请的大小不固定，会根据该线程启动到现在的历史信息来调整。

**“堆是线程共享的内存区域”这句话并不完全正确，因为TLAB是堆内存的一部分，他在读取上确实是线程共享的，但是在内存分分配上，是线程独享的。**

通过`-XX:UseTLAB`设置是否开启TLAB空间,可以通过`-XX:TLABWasteTargetPercent`设置TLAB空间所占用Eden空间的百分比大小.

TLAB会浪费空间。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4e49adbdcaa04fc68b42668b750ada98~tplv-k3u1fbpfcp-zoom-1.image)

可以看到 TLAB 内部只剩一格大小，申请的对象需要两格，这时候需要再申请一块 TLAB ，之前的那一格就浪费了。在 HotSpot 中会生成一个填充对象来填满这一块，因为堆需要线性遍历，遍历的流程是通过对象头得知对象的大小，然后跳过这个大小就能找到下一个对象，所以不能有空洞。

## PLAB

用在年轻代对象晋升到老年代时.在多线程并行执行 YGC 时，可能有很多对象需要晋升到老年代，就产生了PLAB.

先从老年代 freelist（空闲链表） 申请一块空间，然后在这一块空间中就可以通过指针加法（bump the pointer）来分配内存，这样对 freelist 竞争也少了，分配空间也快了。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/de79f919dadd4422bd2fb5ded1db10c7~tplv-k3u1fbpfcp-zoom-1.image)

## 为什么用元空间

1、字符串存在永久代中，容易出现性能问题和内存溢出。

2、类及方法的信息等比较难确定其大小，因此对于永久代的大小指定比较困难，太小容易出现永久代溢出，太大则容易导致老年代溢出。

3、永久代会为 GC 带来不必要的复杂度，并且回收效率偏低。

## 类加载过程

![](https://user-gold-cdn.xitu.io/2020/2/22/1706abac42fee7f4?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

**1.加载(Loading):**

做的事情：

1. 通过一个类的全限定名获取定义此类的二进制字节流
2. 将这个字节流所代表的的静态存储结构转化为方法区的运行时数据结构
3. **在内存中生成一个代表这个类的 `java.lang.Class` 对象**，作为方法区这个类的各种数据的访问入口

加载`.class`文件的方式：

- 从本地系统中直接加载

- 通过网络获取，典型场景：Web Applet

- 从zip压缩文件中读取，成为日后jar、war格式的基础

- 运行时计算生成，使用最多的是：动态代理技术

- 由其他文件生成，比如 JSP 应用

- 从专有数据库提取.class 文件，比较少见

- 从加密文件中获取，典型的防 Class 文件被反编译的保护措施

**2. 连接（Linking）**

- **验证（Verify）**

  目的在于确保Class文件的字节流中包含信息符合当前虚拟机要求，保证被加载类的正确性，不会危害虚拟机自身安全，主要包括四种验证：**文件格式验证，元数据验证，字节码验证，符号引用验证**

- **准备（Prepare）**

  为类变量分配内存并且设置该类变量的默认初始值，即**零值**

  注意：

  - 这里不包含用final修饰的static，因为final在编译的时候就会分配了，准备阶段会显示初始化
  - 这里**不会为实例变量分配初始化**，类变量会分配在**方法区**中，而实例变量是会随着对象一起分配到Java堆中

- **解析（Resolve）**

  将常量池内的符号引用转换为直接引用的过程，符号引用就是一组符号来描述所引用的目标。直接引用就是直接指向目标的指针，相对偏移量或一个间接定位到目标的句柄。解析动作主要针对类或接口、字段、类方法、接口方法、方法类型等。

  

**3.初始化(Initialization)**

初始化阶段就是执行**类构造器方法**<clinit>()的过程，此方法不需要定义，是javac编译器自动收集类中的所有类变量的赋值动作和静态代码块中的语句合并而来，构造器方法中指令按语句在源文件中出现的顺序执行。若该类具有父类，JVM会保证子类的`<clinit>()`执行前，父类的`<clinit>()`已经执行完毕，虚拟机必须保证一个类的`<clinit>()`方法在多线程下被同步加锁。

## 判断对象是否可以被回收

**引用计数器法**：

为每个对象创建一个引用计数，有对象引用时计数器 +1，引用被释放时计数 -1，当计数器为 0 时就可以被回收。它有一个缺点不能解决循环引用的问题

**可达性分析**：

从GC Roots开始向下搜索，搜索所走过的路径称为引用链。当一个对象到GC Roots没有任何引用链相连时，则证明此对象是可以被回收的。

## 可以作为GC Roots的对象

- 被启动类（bootstrap加载器）加载的类和创建的对象
- JavaStack中的引用的对象(栈内存中引用的对象)。
- 方法区中静态引用指向的对象。
- 方法区中常量引用指向的对象。
- Native方法中JNI引用的对象。

## 对象从年轻代进入老年代的时机

- Young GC时，To Survivor区不足以存放存活的对象，对象会直接进入到老年代。
- 经过多次Young GC后，如果存活对象的年龄达到了设定阈值(默认是15)，则会晋升到老年代中。
- 动态年龄判定规则，To Survivor区中相同年龄的对象，如果其大小之和占到了 To Survivor区一半以上的空间，那么大于此年龄的对象会直接进入老年代，而不需要达到默认的分代年龄。
- 大对象：由-XX:PretenureSizeThreshold启动参数控制，若对象大小大于此值，就会绕过新生代, 直接在老年代中分配。

## 触发Full GC的时机

- 晋升到老年代的对象大于了老年代的剩余空间
- 老年代的内存使用率达到了一定阈值（可通过参数调整）
- 空间分配担保：在Young GC之前，会先检查老年代最大可用的连续空间是否大于新生代所有对象的总空间。如果小于，说明Young GC是不安全的，则会查看参数 HandlePromotionFailure 是否被设置成了允许担保失败，如果不允许则直接触发Full GC；如果允许，那么会进一步检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果小于也会触发 Full GC。
- Metaspace（元空间）在空间不足时会进行扩容，当扩容到了`-XX:MetaspaceSize` 参数的指定值时，也会触发Full GC。
- `System.gc()` 或者`Runtime.gc()` 被显式调用时，触发Full GC。

## Minor GC的触发条件

当 Eden 区的空间耗尽，这个时候 Java虚拟机便会触发一次 **Minor GC**来收集新生代的垃圾，存活下来的对象，则会被送到 Survivor区。

Eden快满的触发因素有两个：

- 为对象分配内存不够
- 为TLAB分配内存不够

## “无用的类”的判断条件

- 该类所有的实例都已经被回收
- 加载该类的ClassLoader已经被回收
- 该类对应的`java.lang.Class`对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法

## 如何判断一个常量是废弃常量

没有任何String对象引用该字符串常量

## 垃圾回收算法

### 标记清除算法

标记无用对象，然后进行清除回收。

分为两个阶段：

- 标记阶段：标记出可以回收的对象
- 清除阶段：回收被标记的对象所占用的空间

优点：实现简单，不需要对象进行移动

缺点：效率低，产生大量不连续的内存碎片

（缺个图）

### 复制算法

将内存空间划为两个相等的区域，每次只使用其中一个区域。垃圾收集时，遍历当前使用的区域，把存活对象复制到另外一个区域中，最后将当前使用的区域的可回收的对象进行回收

优点：按顺序分配内存即可，实现简单、运行高效，不用考虑内存碎片

缺点：可用的内存大小缩小为原来的一半，对象存活率高时会频繁进行复制

（缺图）

### 标记整理算法

在标记可回收对象后将所有存活的对象压缩到内存的一端，然后对端边界以外的内存进行回收。回收后，已用和未用的内存都各自一边。

优点：没有内存碎片

缺点：效率不高

（缺图）

## 垃圾收集器（还没写）



## 双亲委派机制

**过程**：

源ClassLoader先判断该Class是否已加载，如果已加载，则返回Class对象；如果没有则委托给父类加载器。
父类加载器判断是否加载过该Class，如果已加载，则返回Class对象；如果没有则委托给祖父类加载器。
依此类推，直到始祖类加载器（引用类加载器）。
始祖类加载器判断是否加载过该Class，如果已加载，则返回Class对象；如果没有则尝试从其对应的类路径下寻找class字节码文件并载入。如果载入成功，则返回Class对象；如果载入失败，则委托给始祖类加载器的子类加载器。
始祖类加载器的子类加载器尝试从其对应的类路径下寻找class字节码文件并载入。如果载入成功，则返回Class对象；如果载入失败，则委托给始祖类加载器的孙类加载器。
依此类推，直到源ClassLoader。
源ClassLoader尝试从其对应的类路径下寻找class字节码文件并载入。如果载入成功，则返回Class对象；如果载入失败，源ClassLoader不会再委托其子类加载器，而是抛出异常。

**双亲委派模型能保证基础类仅加载一次，不会让jvm中存在重名的类。**

**自己实现ClassLoader时只需要继承ClassLoader类，然后覆盖findClass（String name）方法即可完成一个带有双亲委派模型的类加载器。**

**破坏双亲委派模型：**

1.代码热替换，在不重启服务器的情况下可以修改类的代码并使之生效。

热部署步骤：

1. 销毁自定义classloader(被该加载器加载的class也会自动卸载)；
2. 更新class
3. 使用新的ClassLoader去加载class

2.JDBC

我们知道Java核心API（比如rt.jar包）是使用Bootstrap ClassLoader类加载器加载的，而用户提供的Jar包是由AppClassLoader加载的。如果一个类由类加载器加载，那么这个类依赖的类也是由相同的类加载器加载的。

- 第一，从META-INF/services/java.sql.Driver文件中获取具体的实现类名“com.mysql.jdbc.Driver”
- 第二，加载这个类，这里肯定只能用class.forName("com.mysql.jdbc.Driver")来加载

好了，问题来了，Class.forName()加载用的是调用者的Classloader，这个调用者DriverManager是在rt.jar中的，ClassLoader是启动类加载器，而com.mysql.jdbc.Driver肯定不在/lib下，所以肯定是无法加载mysql中的这个类的。这就是双亲委派模型的局限性了，父级加载器无法加载子级类加载器路径中的类。

那么，这个问题如何解决呢？按照目前情况来分析，这个mysql的drvier只有应用类加载器能加载，那么我们只要在启动类加载器中有方法获取应用程序类加载器，然后通过它去加载就可以了。这就是所谓的线程上下文加载器。

**线程上下文类加载器让父级类加载器能通过调用子级类加载器来加载类，这打破了双亲委派模型的原则**

简单的说就是破坏了可见性

3.tomcat中的每个项目之间能加载不用的lib

## 全盘负责

“全盘负责”是指当一个ClassLoader装载一个类时，除非显示地使用另一个ClassLoader，则该类所依赖及引用的类也由这个ClassLoader载入。

## 并发标记

https://segmentfault.com/a/1190000021820577

在遍历对象图的过程中，把访问都的对象**按照"是否访问过"这个条件**标记成以下三种颜色：

**白色：表示对象尚未被垃圾回收器访问过**。显然，在可达性分析刚刚开始的阶段，所有的对象都是白色的，若在分析结束的阶段，仍然是白色的对象，即代表不可达。

**黑色：表示对象已经被垃圾回收器访问过，且这个对象的所有引用都已经扫描过**。黑色的对象代表已经扫描过，它是安全存活的，如果有其它的对象引用指向了黑色对象，无须重新扫描一遍。黑色对象不可能直接（不经过灰色对象）指向某个白色对象。

**灰色：表示对象已经被垃圾回收器访问过，但这个对象至少存在一个引用还没有被扫描过**。

![img](https://gitee.com/xurunxuan/picgo/raw/master/img/1460000021820594)

怎么解决"对象消失"问题呢？

条件一：赋值器插入了一条或者多条从黑色对象到白色对象的新引用。

条件二：赋值器删除了全部从灰色对象到该白色对象的直接或间接引用。

你在结合我们上面出现过的图捋一捋上面的这两个条件，是不是当且仅当的关系：

黑色对象5到白色对象9之间的引用是新建的，对应条件一。

黑色对象6到白色对象9之间的引用被删除了，对应条件二。

![](https://gitee.com/xurunxuan/picgo/raw/master/img/1460000021820598)

**CMS是基于增量更新来做并发标记的，G1则采用的是原始快照的方式。**

增量更新

黑色对象一旦插入了指向白色对象的引用之后，它就变回了灰色对象。

原始快照

无论引用关系删除与否，都会按照刚刚开始扫描那一刻的对象图快照开进行搜索。

[好文,但是有些看不懂,需要多看](https://juejin.cn/post/6894435290350845959#heading-10)

## CMS回收器的回收流程

1、初始标记(initial mark)，这个阶段是 STW 的，扫描根集合，标记根直接可达的对象即可。

2、并发标记(Concurrent marking)，这个阶段和应用线程并发，从上一步标记的根直接可达对象开始进行 tracing，递归扫描所有可达对象。

3、并发预清理(Concurrent precleaning)，这个阶段和应用线程并发，就是想帮重新标记阶段先做点工作，扫描一下卡表脏的区域和新晋升到老年代的对象等，因为重新标记是 STW 的，所以分担一点。

4、可中断的预清理阶段（AbortablePreclean），这个和上一个阶段基本上一致，就是为了分担重新标记标记的工作。

5、重新标记(remark)，这个阶段是 STW 的，因为并发阶段引用关系会发生变化，所以要重新遍历一遍新生代对象、Gc Roots、卡表等，来修正标记。

6、并发清理(Concurrent sweeping)，这个阶段和应用线程并发，用于清理垃圾。

7、并发重置(Concurrent reset)，这个阶段和应用线程并发，重置 cms 内部状态。

cms 的瓶颈就在于重新标记阶段，需要较长花费时间来进行重新扫描。

## G1回收器的回收流程

G1 从大局上看分为两大阶段，分别是并发标记和对象拷贝。

并发标记是基于 STAB 的，可以分为四大阶段：

1、初始标记（initial marking)，这个阶段是 STW 的，扫描根集合，标记根直接可达的对象即可。在G1中标记对象是利用外部的bitmap来记录，而不是对象头。

2、并发阶段（concurrent marking）,这个阶段和应用线程并发，从上一步标记的根直接可达对象开始进行 tracing，递归扫描所有可达对象。 STAB 也会在这个阶段记录着变更的引用。

3、最终标记（final marking), 这个阶段是 STW 的，处理 STAB 中的引用。

4、清理阶段（clenaup），这个阶段是 STW 的，根据标记的 bitmap 统计每个 region 存活对象的多少，如果有完全没存活的 region 则整体回收。

对象拷贝阶段（evacuation)，这个阶段是 STW 的。

根据标记结果选择合适的 reigon 组成收集集合（collection set 即 CSet），然后将 CSet 存活对象拷贝到新 region 中。

G1 的瓶颈在于对象拷贝阶段，需要花较多的瓶颈来转移对象。


## G1收集器原理

[G1收集器原理](https://segmentfault.com/a/1190000021878102)

![](https://gitee.com/xurunxuan/picgo/raw/master/img/1460000021878115)

h表示大对象

G1的堆内存被划分为多个大小相等的 Region ，但是 Region 的总个数在 2048 个左右，默认是 2048 。对于一个 Region 来说，是逻辑连续的一段空间，其大小的取值范围是 1MB 到 32MB 之间。

![](https://gitee.com/xurunxuan/picgo/raw/master/img/1460000021878130)

![avatar](https://gitee.com/xurunxuan/picgo/raw/master/img/1460000021878134)

## 常量池

https://mp.weixin.qq.com/s/Av2phrOe_TXnRwD0SeYPCg

![image-20201107112058414](https://gitee.com/xurunxuan/picgo/raw/master/img/image-20201107112058414.png)

class常量池

- 类和接口的全限定名
- 字段的名称和描述符
- 方法的名称和描述符

**运行时常量池就是用来存放 class 常量池中的内容的**

1. 字符串常量池本质就是一个哈希表
2. 字符串常量池中存储的是字符串实例的引用
3. 字符串常量池在被整个 JVM 共享
4. 在解析运行时常量池中的符号引用时，会去查询字符串常量池，确保运行时常量池中解析后的直接引用跟字符串常量池中的引用是一致的

## 保守和非保守GC

https://zuozuo.gitbooks.io/reading-notes-of-garbage-collection/content/chapter6_bao_shou_shi_gc.html

**保守式GC(Conservative GC)指的是: 不能识别指针和非指针的GC**

**准确式GC(Exact GC)能够正确识别出指针和非指针** 	

相信大家看下来已经知道准确意味 JVM 需要清晰的知晓对象的类型，包括在栈上的引用也能得知类型等。

能想到的可以在指针上打标记，来表明类型，或者在外部记录类型信息形成一张映射表。

HotSpot 用的就是映射表，这个表叫 OopMap。

在 HotSpot 中，对象的类型信息里会记录自己的 OopMap，记录了在该类型的对象内什么偏移量上是什么类型的数据，而在解释器中执行的方法可以通过解释器里的功能自动生成出 OopMap 出来给 GC 用。

被 JIT 编译过的方法，也会在特定的位置生成 OopMap，记录了执行到该方法的某条指令时栈上和寄存器里哪些位置是引用。

这些特定的位置主要在：

1. 循环的末尾（非 counted 循环）
2. 方法临返回前 / 调用方法的call指令后
3. 可能抛异常的位置

这些位置就叫作安全点(safepoint)。

那为什么要选择这些位置插入呢？因为如果对每条指令都记录一个 OopMap 的话空间开销就过大了，因此就选择这些个关键位置来记录即可。

所以在 HotSpot 中 GC 不是在任何位置都能进入的，只能在安全点进入。

至此我们知晓了可以在类加载时计算得到对象类型中的 OopMap，解释器生成的 OopMap 和 JIT 生成的 OopMap ，所以 GC 的时候已经有充足的条件来准确判断对象类型。

因此称为准确式 GC。

[](https://mp.weixin.qq.com/s/AZ_Xv28cF1xxloluJaniww)

# Spring

## 过滤器和拦截器的区别（这个算是做的笔记）

[过滤器和拦截器的区别](https://juejin.cn/post/6847902221212844039)

**过滤器**:

过滤器的配置比较简单，直接实现Filter 接口即可，也可以通过@WebFilter注解实现对特定URL拦截，看到Filter 接口中定义了三个方法。

- `init()` ：该方法在容器启动初始化过滤器时被调用，它在Filter的整个生命周期只会被调用一次。注意：这个方法必须执行成功，否则过滤器会不起作用。
- `doFilter()` ：容器中的每一次请求都会调用该方法,FilterChain 用来调用下一个过滤器 Filter。
- `destroy()`： 当容器销毁过滤器实例时调用该方法，一般在方法中销毁或关闭资源，在过滤器Filter的整个生命周期也只会被调用一次

**拦截器**:

拦截器是链式调用，一个应用中可以同时存在多个拦截器Interceptor， 一个请求也可以触发多个拦截器 ，而每个拦截器的调用会依据它的声明顺序依次执行。

HandlerInterceptor 接口中也定义了三个方法:

- `preHandle()` ：这个方法将在请求处理之前进行调用。注意：如果该方法的返回值为false ，将视为当前请求结束，不仅自身的拦截器会失效，还会导致其他的拦截器也不再执行。
- `postHandle()`：只有在 preHandle() 方法返回值为true 时才会执行。会在Controller 中的方法调用之后，DispatcherServlet 返回渲染视图之前被调用。 有意思的是：postHandle() 方法被调用的顺序跟 preHandle() 是相反的，先声明的拦截器 preHandle() 方法先执行，而postHandle()方法反而会后执行。
- `afterCompletion()`：只有在 preHandle() 方法返回值为true 时才会执行。在整个请求结束之后， DispatcherServlet 渲染了对应的视图之后执行。

**二者区别**：

- 实现原理不同：
  过滤器是基于函数回调的，拦截器则是基于Java的反射机制（动态代理）实现的。
- 使用范围不同：
  过滤器Filter使用要依赖于Tomcat等容器，导致它只能在web程序中使用。拦截器(Interceptor) 它是一个Spring组件，并由Spring容器管理，并不依赖Tomcat等容器，是可以单独使用的。
- 触发时机不同：
  过滤器Filter是在请求进入容器后，但在进入servlet之前进行预处理，请求结束是在servlet处理完以后。拦截器 Interceptor 是在请求进入servlet后，在进入Controller之前进行预处理的，Controller 中渲染了对应的视图之后请求结束。
  ![](https://user-gold-cdn.xitu.io/2020/7/8/1732c56185f100f5?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)
- 拦截的请求范围不同:
  过滤器几乎可以对所有进入容器的请求起作用，而拦截器只会对Controller中请求或访问static目录下的资源请求起作用。
- 注入Bean情况不同:
  过滤器中可以注入service,而拦截器因为加载的时间点在springcontext之前,所以注入时会报错。需要注册拦截器之前,先手动注册Interceptor。
- 控制执行顺序不同：
  过滤器用@Order注解控制执行顺序，通过@Order控制过滤器的级别，值越小级别越高越先执行。拦截器默认的执行顺序，就是它的注册顺序，也可以通过Order手动设置控制，值越小越先执行。

## IOC容器的组成部分

- 入口: `AnnotationConfigApplicationContext`
- 生成bean的工厂: `DefaultListableBeanFactory`
- 解析注解的配置: `AnnotatedBeanDefinitionReader` (注解在Spring中被封装到BeanDefinition中，这个对象存储了bean对象的所有特征信息)
- 对用户指定的包目录进行扫描查找bean对象的路径扫描器:`ClassPathBeanDefinitionScanner`

## IOC容器的初始化流程(需要通俗语言)

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0eba47985d174f67b74ef36797cd2ddc~tplv-k3u1fbpfcp-zoom-1.image)

## IOC容器的刷新流程

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/20bd021b8b2a4bd7aa64ca06f5738785~tplv-k3u1fbpfcp-zoom-1.image)

IOC容器的最简单功能：先扫描出要放入容器的 bean，将其包装成 BeanDefinition 对象，然后通过反射创建 bean，并完成赋值操作.

如果用户想在扫描完 bean 之后做一些自定义的操作：假设容器中包含了 a 和 b，那么就动态向容器中注入 c，不满足就注入 d，这种骚操作 Spring 也是支持的，得益于它提供的 `BeanFactoryPostProcessor` 后置处理器

如果想在 bean 的初始化前后做一些操作,使用`BeanPostProcessor`后置处理器

如果想监听容器启动、刷新等事件，根据这些事件做一些自定义的操作,使用`registerListeners`

## Spring读取自定义xml文件解析

1. ApplicationContext将解析配置文件的工作委托给BeanDefinitionReader，然后BeanDefinitionReader将配置文件读取为xml的Document文档之后，又委托给BeanDefinitionDocumentReader
2. BeanDefinitionDocumentReader这个组件是根据xml元素的命名空间和元素名，起到一个路由的作用，实际的解析工作，是委托给BeanDefinitionParserDelegate来完成的
3. BeanDefinitionParserDelegate的解析工作完成以后，会返回BeanDefinitionHolder给BeanDefinitionDocumentReader，在这里，会委托给DefaultListableBeanFactory完成bean的注册
4. XmlBeanDefinitionReader（计数、解析XML文档），BeanDefinitionDocumentReader（依赖xml文档，进行解析和注册），BeanDefinitionParserDelegate（实际的解析工作）。可以看出，在解析bean的过程中，这3个组件的分工是比较清晰的，各司其职


![](https://note.youdao.com/yws/api/personal/file/219238FD61C146C99E137E303D52EA66?method=download&shareKey=d5e5aaa1e9fa782eeb056b89119c3565)

### refresh()方法

![](https://note.youdao.com/yws/api/personal/file/76AE8FEDAFF54B6881C336B056AC5B0A?method=download&shareKey=430f5263180efd8467df6e6434456f3d)

# MySQL

## 储存格式

![](https://yueqilai-images.oss-cn-beijing.aliyuncs.com/image-20200719105252395.png)

## MySQL的查询流程

客户端请求 ---> 连接器（验证用户身份，给予权限）  ---> 查询缓存（存在缓存则直接返回，不存在则执行后续操作） ---> 分析器（对SQL进行词法分析和语法分析操作）  ---> 优化器（主要对执行的sql优化选择最优的执行方案方法）  ---> 执行器（执行时会先看用户是否有执行权限，有才去使用这个引擎提供的接口） ---> 去引擎层获取数据返回（如果开启查询缓存则会缓存查询结果）

![](https://user-gold-cdn.xitu.io/2020/7/14/1734bff309fc730f?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

## MySQLr如何建立连接

![handshake](https://gitee.com/xurunxuan/picgo/raw/master/img/07205636_YA23.png)

Step1:客户端向DB发起TCP握手。
Step2:三次握手成功。与通常流程不同的是，由DB发送HandShake信息。这个Packet里面包含了MySql的能力、加密seed等信息。
Step3:客户端根据HandShake包里面的加密seed对MySql登录密码进行摘要后，构造Auth认证包发送给DB。
Step4:DB接收到客户端发过来的Auth包后会对密码摘要进行比对，从而确认是否能够登录。如果能，则发送Okay包返回。
Step5:客户端与DB的连接至此完毕。

## MyISAM和InnoDB

- InnoDB支持事务，MyISAM不支持事务
- InnoDB支持外键，而MyISAM不支持.
- InnoDB是聚簇索引,MyISAM是非聚簇索引
- InnoDB不保存表的具体行数，执行select count(*) from table 时需要全表扫描。而MyISAM用一个变量保存了整个表的行数.
- InnoDB最小的锁粒度是行锁，MyISAM最小的锁粒度是表锁。

## MyISAM的应用场景

MyISAM适合：(1)做很多count 的计算；(2)插入不频繁，查询非常频繁；(3)没有事务。

## InnoDB的4大特性

- 插入缓冲(insert buffer)
- 二次写(double write)
- 自适应哈希索引(ahi)
- 预读(read ahead)

## 二次写

**解决的问题**：

一个数据页的大小是16K，假设在把内存中的脏页写到数据库的时候，写了2K突然掉电，也就是说前2K数据是新的，后14K是旧的，那么磁盘数据库这个数据页就是不完整的，是一个坏掉的数据页。redo只能加上旧、校检完整的数据页恢复一个脏块，不能修复坏掉的数据页，所以这个数据就丢失了，可能会造成数据不一致，所以需要double write。

**使用场景**:

当数据库正在从内存想磁盘写一个数据页是，数据库宕机，从而导致这个页只写了部分数据，这就是部分写失效，它会导致数据丢失.

**工作流程**：

![img](https://gitee.com/xurunxuan/picgo/raw/master/img/13526929-95f2acde88e284f4.png)

doublewrite由两部分组成，一部分为内存中的doublewrite buffer，其大小为2MB，另一部分是磁盘上共享表空间(ibdata x)中连续的128个页，即2个区(extent)，大小也是2M。

1、当一系列机制触发数据缓冲池中的脏页刷新时，并不直接写入磁盘数据文件中，而是先拷贝至内存中的doublewrite buffer中；

2、接着从两次写缓冲区分两次写入磁盘共享表空间中(连续存储，顺序写，性能很高)，每次写1MB；

3、待第二步完成后，再将doublewrite buffer中的脏页数据写入实际的各个表空间文件(离散写)；(脏页数据固化后，即进行标记对应doublewrite数据可覆盖)

## 哪个存储引擎执行 select count(*) 更快，为什么?

MyISAM更快。

在MyISAM存储引擎中，把表的总行数存储在磁盘上，当执行`select count(*) from t`时，直接返回总数据。

在InnoDB存储引擎中，跟MyISAM不一样，没有将总行数存储在磁盘上，当执行`select count(*) from t`时，会先把数据读出来，一行一行的累加，最后返回总数量。

## char和varchar的区别

char是固定长度，varchar长度可变。

- char不论实际存储的字符数都会占用n个字符的空间，而varchar只会占用实际字符应该占用的字节空间加1
- 能存储的最大空间限制不一样：char的存储上限为255字节
- char在存储时会截断尾部的空格，而varchar不会

## 三范式

- 第一范式（1NF）：数据库表中的字段都是单一属性的，不可再分。这个单一属性由基本类型构成，包括整型、实数、字符型、逻辑型、日期型等。
- 第二范式（2NF）：数据库表中不存在非关键字段对任一候选关键字段的部分函数依赖（部分函数依赖指的是存在组合关键字中的某些字段决定非关键字段的情况），也即所有非关键字段都完全依赖于任意一组候选关键字。
- 第三范式（3NF）：在第二范式的基础上，数据表中如果不存在非关键字段对任一候选关键字段的传递函数依赖则符合第三范式。所谓传递函数依赖，指的是如 果存在"A → B → C"的决定关系，则C传递函数依赖于A。因此，满足第三范式的数据库表应该不存在如下依赖关系： 关键字段 → 非关键字段 x → 非关键字段y

## 百万级别或以上的数据如何删除

- 先删除索引
- 删除其中无用数据
- 重新创建索引

## 为什么InnoDB要有主键

innodb是用聚集索引，所以非聚集索引最后怎么定位到数据就需要靠主键

myisam是非聚集索引，不需要主键定位数据

## count(*) 和 count(1)和count(列名)区别

- 执行效果上：

count(*)包括了所有的列，相当于行数，在统计结果的时候，不会忽略列值为NULL
count(1)包括了所有列，用1代表代码行，在统计结果的时候，不会忽略列值为NULL
count(列名)只包括列名那一列，在统计结果的时候，会忽略列值为空（这里的空不是只空字符串或者0，而是表示null）的计数，即某个字段值为NULL时，不统计。

- 执行效率上：

列名为主键，count(列名)会比count(1)快
列名不为主键，count(1)会比count(列名)快
如果表多个列并且没有主键，则 count(1) 的执行效率优于 count(*)
如果有主键，则 select count（主键）的执行效率是最优的
如果表只有一个字段，则 select count(*) 最优。

## MySQL中in和exists的区别

- exists：exists对外表用loop逐条查询，每次查询都会查看exists的条件语句，当exists里的条件语句能够返回记录行时（无论记录行是的多少，只要能返回），条件就为真，返回当前loop到的这条记录；反之，如果exists里的条件语句不能返回记录行，则当前loop到的这条记录被丢弃，exists的条件就像一个bool条件，当能返回结果集则为true，不能返回结果集则为false
- in：in查询相当于多个or条件的叠加

如果查询的两个表大小相当，那么用in和exists差别不大。

如果两个表中一个较小，一个是大表，则子查询表大的用exists，子查询表小的用in.

## UNION和UNION ALL的区别

UNION和UNION ALL都是将两个结果集合并为一个，两个要联合的SQL语句 字段个数必须一样，而且字段类型要“相容”（一致）；


- UNION在进行表连接后会筛选掉重复的数据记录（效率较低），而UNION ALL则不会去掉重复的数据记录；

- UNION会按照字段的顺序进行排序，而UNION ALL只是简单的将两个结果合并就返回；

## SQL执行顺序

- 手写

```
SELECT DISTINCT <select_list>
FROM  <left_table> <join_type>
JOIN  <right_table> ON <join_condition>
WHERE  <where_condition>
GROUP BY  <group_by_list>
HAVING <having_condition>
ORDER BY <order_by_condition>
LIMIT <limit_number>
```

- 机读

```
FROM  <left_table>
ON <join_condition>
<join_type> JOIN  <right_table> 
WHERE  <where_condition>
GROUP BY  <group_by_list>
HAVING <having_condition>
SELECT
DISTINCT <select_list>
ORDER BY <order_by_condition>
LIMIT <limit_number>
```

- 总结

![](https://user-gold-cdn.xitu.io/2020/7/14/1734bff368752ece?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

## 关于索引的sql语句

- 创建索引:`CREATE [UNIQUE] INDEX indexName ON mytable(username(length))`
- 删除索引：`DROP INDEX [indexName] ON mytable`
- 查看:`SHOW INDEX FROM table_name\G`
- 使用ALERT命令：
  - `ALTER TABLE tbl_name ADD PRIMARY KEY (column_list)`: 该语句添加一个主键，这意味着索引值必须是唯一的，且不能为NULL。
  - `ALTER TABLE tbl_name ADD UNIQUE index_name (column_list)`:这条语句创建索引的值必须是唯一的（除了NULL外，NULL可能会出现多次）。
  - `ALTER TABLE tbl_name ADD INDEX index_name (column_list)`:添加普通索引，索引值可出现多次。
  - `ALTER TABLE tbl_name ADD FULLTEXT index_name (column_list)`:该语句指定了索引为 FULLTEXT ，用于全文索引。

## 索引分类

**数据结构角度**：

- B+树索引
- Hash索引
- Full-Text全文索引
- R-Tree索引

**从物理存储角度**：

- 聚集索引
- 非聚集索引

**从逻辑角度**：

- 主键索引：主键索引是一种特殊的唯一索引，不允许有空值
- 普通索引或者单列索引：每个索引只包含单个列，一个表可以有多个单列索引
- 多列索引（复合索引、联合索引）：复合索引指多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。使用复合索引时遵循最左前缀集合
- 唯一索引或者非唯一索引
- 空间索引：空间索引是对空间数据类型的字段建立的索引，MYSQL中的空间数据类型有4种，分别是GEOMETRY、POINT、LINESTRING、POLYGON。
MYSQL使用SPATIAL关键字进行扩展，使得能够用于创建正规索引类型的语法创建空间索引。创建空间索引的列，必须将其声明为NOT NULL，空间索引只能在存储引擎为MYISAM的表中创建

## 索引为什么选择B+树

- **更少的IO次数**:B+树的非叶节点只包含键，而不包含真实数据，因此每个节点存储的记录个数比B数多很多（即阶m更大），因此B+树的高度更低，访问时所需要的IO次数更少。此外，由于每个节点存储的记录数更多，所以对访问局部性原理的利用更好，缓存命中率更高。
- **更适于范围查询**:在B树中进行范围查询时，首先找到要查找的下限，然后对B树进行中序遍历，直到找到查找的上限；而B+树的范围查询，只需要对链表进行遍历即可。
- **更稳定的查询效率**:B树的查询时间复杂度在1到树高之间(分别对应记录在根节点和叶节点)，而B+树的查询复杂度则稳定为树高，因为所有数据都在叶节点。

B+树也存在劣势：由于键会重复出现，因此会占用更多的空间。但是与带来的性能优势相比，空间劣势往往可以接受，因此B+树的在数据库中的使用比B树更加广泛。

## B-Tree的性质

一棵m阶的B-Tree有如下特性：

1. 每个节点最多有m个孩子
2. 除了根节点和叶子节点外，其它每个节点至少有Ceil(m/2)个孩子。
3. 若根节点不是叶子节点，则至少有2个孩子
4. 所有叶子节点都在同一层，且不包含其它关键字信息
5. 每个非终端节点包含n个关键字信息（P0,P1,…Pn, k1,…kn）
6. 关键字的个数n满足：ceil(m/2)-1 <= n <= m-1
7. ki(i=1,…n)为关键字，且关键字升序排序
8. Pi(i=1,…n)为指向子树根节点的指针。P(i-1)指向的子树的所有节点关键字均小于ki，但都大于k(i-1)

![](https://user-gold-cdn.xitu.io/2020/7/14/1734bff356b40f0d?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

## B+Tree的性质

在B+Tree中，所有数据记录节点都是按照键值大小顺序存放在同一层的叶子节点上，而非叶子节点上只存储key值信息.

B+树和B树类似，但多了几条规则

- 非叶子结点的子树指针个数与关键字（节点中的元素个数）个数相同
- 非叶子结点的子树指针P[i]，指向关键字值属于[K[i], K[i+1])的子树（B-树是开区间）
- 所有叶子结点有一个链指针
- 所有关键字都在叶子结点出现
- 只有叶子节点有Data域

特点：

1、是多叉而不是二叉了，使用多叉的目的是降低树的高度;
2、每个节点不再只是存储一个key了，可以存储多个key；
3、非叶子节点存储key，叶子节点存储key和数据。
4、叶子节点两两相连，为顺序查询提供了帮助

![](https://user-gold-cdn.xitu.io/2020/7/14/1734bff3498c6715?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

## B+Tree索引和Hash索引区别

哈希索引适合等值查询，但是不无法进行范围查询 哈希索引没办法利用索引完成排序 哈希索引不支持多列联合索引的最左匹配规则 如果有大量重复键值得情况下，哈希索引的效率会很低，因为存在哈希碰撞问题

## 为什么不建议使用订单号作为主键?

如果主键是一个很长的字符串并且建了很多普通索引，将造成普通索引占有很大的物理空间，这也是为什么建议使用自增ID来替代订单号作为主键，另一个原因是 自增ID 在插入的时候可以保证相邻的两条记录可能在同一个数据块，而订单号的连续性在设计上可能没有自增ID好，导致连续插入可能在多个数据块，增加了磁盘读写次数。

## 一棵B+树可以存放多少行数据

InnoDB的一个页可以为索引页，也可以为数据页。

首先，InnoDB底层的数据页大小默认为16KB，一般来说，生产环境一行数据为1KB左右，那么一个数据页可以存放16条数据。剩下的只要计算有多少个数据页就行了。

对于索引页，里面数据是怎么存放的呢？

索引页存放的是主键和指针（6 Byte），若建表时没有指定主键，mysql会自动创建一个6Byte的主键。一般数据库中我们使用bigint的自增id作为主键（8Byte），那么一个<主键，指针>对大小为14Byte。一个16KB的索引页可以存放16*1024/14=1170个单元。
 一般树高为3层，那么对应的数据页有1170*1170个，数据行数为1170*1170*16=2000W行。

## 聚集索引与非聚集索引的区别

聚簇索引的叶子节点存放的是主键值和数据行，**支持覆盖索引**；二级索引的叶子节点存放的是主键值或指向数据行的指针。

由于节子节点(数据页)只能按照一颗B+树排序，故**一张表只能有一个聚簇索引**。辅助索引的存在不影响聚簇索引中数据的组织，所以一张表可以有多个辅助索引

## MyISAM主键索引和辅助索引的结构

MyISAM引擎索引结构的叶子节点的数据域，存放的并不是实际的数据记录，而是数据记录的地址。

![](https://img2018.cnblogs.com/i-beta/1464190/201911/1464190-20191106145143172-1760681728.png)

## InnoDB如何实现聚集（聚簇）索引

MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。

聚集索引就是按照每张表的主键构造一棵B+树，同时叶子节点中存放的即为整张表的行记录数据，也将聚集索引的叶子节点称为数据页。

在Innodb中一张表中聚簇索引建立的过程：

1) 有主键时，根据主键创建聚簇索引
2)  没有主键时，会用一个唯一且不允许为空的索引列做为主键，成为此表的聚簇索引
3) 如果表中没有主键或者一个合适的的唯一索引，InnoDB内部会以一个包含行ID值的合成列生成一个隐藏的聚簇索引。表中的行是按照InnoDB分配的ID排序的。行ID是一个6字节的字段，随着一个新行的插入单调增加。因此，行ID顺序物理上是插入顺序。

## 回表查询

1. 在辅助索引上检索列值，到达其叶子节点获取对应的主键
2. 使用主键在主索引上再进行对应的检索操作

## full-text全文索引

- 全文索引也是MyISAM的一种特殊索引类型，主要用于全文索引，InnoDB从MYSQL5.6版本提供对全文索引的支持。

- 它用于替代效率较低的LIKE模糊匹配操作，而且可以通过多字段组合的全文索引一次性全模糊匹配多个字段。

- 同样使用B-Tree存放索引数据，但使用的是特定的算法，将字段数据分割后再进行索引（一般每4个字节一次分割），索引文件存储的是分割前的索引字符串集合，与分割后的索引信息，对应Btree结构的节点存储的是分割后的词信息以及它在分割前的索引字符串集合中的位置。


## 与索引有关的SQL语句

- 创建:`CREATE [UNIQUE] INDEX indexName ON mytable(username(length));`
- 修改表结构(添加索引):`ALTER table tableName ADD [UNIQUE] INDEX indexName(columnName)`
- 删除:`DROP INDEX [indexName] ON mytable;`
- 查看:`SHOW INDEX FROM table_name\G`(\G格式化输出)
- 使用ALERT命令:
  - `ALTER TABLE tbl_name ADD PRIMARY KEY (column_list)`:该语句添加一个主键，这意味着索引值必须是唯一的，且不能为NULL。
  - `ALTER TABLE tbl_name ADD UNIQUE index_name (column_list)`:这条语句创建索引的值必须是唯一的（除了NULL外，NULL可能会出现多次）。
  - `ALTER TABLE tbl_name ADD INDEX index_name (column_list)`:添加普通索引，索引值可出现多次。

## 哪些情况需要创建索引

1. 主键自动建立唯一索引

2. 频繁作为查询条件的字段

3. 查询中与其他表关联的字段，外键关系建立索引

4. 单键/组合索引的选择问题，高并发下倾向创建组合索引

5. 查询中排序的字段，排序字段通过索引访问大幅提高排序速度

6. 查询中统计或分组字段

## 哪些情况不要创建索引

1. 表记录太少
2. 经常增删改的表
3. 数据重复且分布均匀的表字段，只应该为最经常查询和最经常排序的数据列建立索引（如果某个数据类包含太多的重复数据，建立索引没有太大意义）
4. 频繁更新的字段不适合创建索引（会加重IO负担）
5. where条件里用不到的字段不创建索引

## 索引覆盖

select的数据列只用从索引中就能够取得，不必读取数据行，MySQL可以利用索引返回select列表中的字段，而不必根据索引再次读取数据文件，换句话说查询列要被所建的索引覆盖。

**判断标准**：

使用explain，可以通过输出的extra列来判断，对于一个索引覆盖查询，显示为using index，MySQL查询优化器在执行查询前会决定是否有索引覆盖查询

## 索引不生效 前缀索引

[索引不生效 前缀索引](https://mp.weixin.qq.com/s/-gmAPfiKMNJgHhIZqR2C4A)

## 索引设计准则:三星索引

法则：将选择性最高的列放在索引的最前列，这种建立在某些场景可能有用，但通常不如避免随机 IO 和 排序那么重要，这里引入索引设计中非常著名的一个准则：三星索引。

如果一个查询满足三星索引中三颗星的所有索引条件，**理论上**可以认为我们设计的索引是最好的索引。什么是三星索引

1. 第一颗星：WHERE 后面参与查询的列可以组成了单列索引或联合索引
2. 第二颗星：避免排序，即如果 SQL 语句中出现 order by colulmn，那么取出的结果集就已经是按照 column 排序好的，不需要再生成临时表
3. 第三颗星：SELECT 对应的列应该尽量是索引列，即尽量避免回表查询。

## 事务的基本要素

- A (Atomicity) 原子性：整个事务中的所有操作，要么全部完成，要么全部不完成，不可能停滞在中间某个环节。
- C (Consistency) 一致性：在事务开始之前和事务结束以后，数据库的完整性约束没有被破坏
- I (Isolation)隔离性：一个事务的执行不能其它事务干扰。即一个事务内部的操作及使用的数据对其它并发事务是隔离的，并发执行的各个事务之间不能互相干扰
- D (Durability) 持久性：在事务完成以后，该事务所对数据库所作的更改便持久的保存在数据库之中，并不会被回滚

## 并发事务处理带来的问题

**更新丢失（Lost Update)**:

事务A和事务B选择同一行，然后基于最初选定的值更新该行时，由于两个事务都不知道彼此的存在，就会发生丢失更新问题

**脏读(Dirty Reads) -> 读取到了未提交的数据**:

事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据

| 事务A | 事务B |
| :-: | :-: |
| | `SET GLOBAL TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;` |
| `START TRANSACTION;` | |
|  | `select @@transaction_isolation;` |
|  | `UPDATE test.testnum SET num=num*2 WHERE num=2;` |
| `SELECT * FROM testnum;` | |
| | |

![](https://yueqilai-images.oss-cn-beijing.aliyuncs.com/脏读示例.png)



**不可重复读（Non-Repeatable Reads) -> 前后多次读取，数据内容不一致**：

事务 A 多次读取同一数据，事务B在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果不一致。

| 时间顺序 | 事务A | 事务B |
| :-: | :-: | :-: |
| 1 | 开始事务 | |
| 2 | 第一次查询，小明的年龄为20岁 | |
| 3 | | 开始事务 |
| 4 | 其他操作 | |
| 5 | | 更改小明的年龄为30岁 |
| 6 | | 提交事务 |
| 7 | 第二次查询，小明的年龄为30岁 | |
| 备注 | 按照正确逻辑，事务A前后两次读取到的数据应该一致|

**幻读（Phantom Reads) -> 前后多次读取，数据总量不一致**：

幻读与不可重复读类似。它发生在一个事务A读取了几行数据，接着另一个并发事务B插入了一些数据时。在随后的查询中，事务A就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。

| 时间顺序 | 事务A | 事务B |
| :-: | :-: | :-: |
| 1 | 开始事务 | |
| 2 | 第一次查询，数据总量为100条 | |
| 3 | | 开始事务 |
| 4 | 其他操作 | |
| 5 | | 新增100条数据 |
| 6 | | 提交事务 |
| 7 | 第二次查询，数据总量为200条 | |
| 备注 | 按照正确逻辑，事务A前后两次读取到的数据总量应该一致|

## 事务隔离级别

查看事务隔离级别:`select @@transaction_isolation;`

数据库事务的隔离级别有4种，由低到高分别为

- `READ-UNCOMMITTED(读未提交)`： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。
- `READ-COMMITTED(读已提交)`： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。
- `REPEATABLE-READ(可重复读)`： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。**MySQL默认隔离级别**
  **不可重复读对应的是修改，即UPDATE操作。但是可能还会有幻读问题。因为幻读问题对应的是插入INSERT操作，而不是UPDATE操作。**
- `SERIALIZABLE(可串行化)`： 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。

| 隔离级别 | 脏读 | 不可重复读 | 幻读 |
| :-: | :-: | :-: | :-: |
| 读未提交 | 可能 | 可能 | 可能 |
| 读提交 | 不可能 | 可能 | 可能 |
| 可重复读 | 不可能 | 不可能 | 可能 |
| 串行化 | 不可能 | 不可能 | 不可能 |

## mvcc实现原理

对于使用InnoB引擎的表来说，它的聚簇索引记录中都包含两个必要的隐藏列：

```
trx_id：每次一个事务对某条聚簇索引记录进行改动时，都会把该事务的事务id赋值给trx_id隐藏列；即记录事务ID。
roll_pointer：每次对某条聚簇索引记录进行改动时，都会把旧的版本写入到undo日志中，然后这个隐藏列就相当于一个指针，可以通过它来找到该记录修改前的信息。
```

每次对记录改动，都会记录一条undo日志，每条undo日志也都有一个roll_pointer属性（INSERT操作对应的undo日志没有该属性，因为该记录并没有更早的版本），将这条数据的undo日志组成一个链表；即为版本链。版本链的头节点就是当前记录的最新值。

## REPEATABLE READ（可重读）隔离级别下MVCC如何工作

- SELECT: 
  InnoDB会根据以下两个条件检查每行记录：
  - InnoDB只查找版本早于当前事务版本的数据行，这样可以确保事务读取的行，要么是在开始事务之前已经存在要么是事务自身插入或者修改过的
  - 行的删除版本号要么未定义，要么大于当前事务版本号，这样可以确保事务读取到的行在事务开始之前未被删除
  只有符合上述两个条件的才会被查询出来
- INSERT:
  InnoDB为新插入的每一行保存当前系统版本号作为行版本号
- DELETE:
  InnoDB为删除的每一行保存当前系统版本号作为行删除标识
- UPDATE:
  InnoDB为插入的一行新记录保存当前系统版本号作为行版本号，同时保存当前系统版本号到原来的行作为删除标识

MVCC 只在 COMMITTED READ（读提交）和REPEATABLE READ（可重复读）两种隔离级别下工作。

## MVCC中的ReadView(可读视图)

ReadView中主要就是有个列表来存储我们系统中当前活跃着的读写事务，也就是begin了还未提交的事务。通过这个列表来判断记录的某个版本是否对当前事务可见。其中最主要的与可见性相关的属性如下：

**up_limit_id**：当前已经提交的事务号 + 1，事务号 < up_limit_id ，对于当前Read View都是可见的。理解起来就是创建Read View视图的时候，之前已经提交的事务对于该事务肯定是可见的。

**low_limit_id**：当前最大的事务号 + 1，事务号 >= low_limit_id，对于当前Read View都是不可见的。理解起来就是在创建Read View视图之后创建的事务对于该事务肯定是不可见的。

**trx_ids**：为活跃事务id列表，即Read View初始化时当前未提交的事务列表。所以当进行RR读的时候，trx_ids中的事务对于本事务是不可见的（除了自身事务，自身事务对于表的修改对于自己当然是可见的）。理解起来就是创建RV时，将当前活跃事务ID记录下来，后续即使他们提交对于本事务也是不可见的。

用一张图更好的理解一下：

![img](https://gitee.com/xurunxuan/picgo/raw/master/img/v2-fef7954f5e3c7713f48b35597e7f9fb8_720w.jpg)

## MVCC和next-key lock为什么不能完全解决幻读

[MVCC和next-key lock为什么不能完全解决幻读](https://blog.csdn.net/weixin_42907817/article/details/107121470)

平常我们学习的rr确实存在幻读问题，但是在innodb下不同，它可以解决，但是解决的并不完美。
首先我们可以通过手动加锁阻塞另一个线程的insert，也就是通过innodb的next-key算法，其次我们也可以通过mvcc实现快照读，但是mvcc存在缺陷，就是一旦某个事物在事务中的修改操作覆盖到了其他事务插入的“幻行”，那么这些“幻行”在下次查询时就会再次出现，从而出现幻象问题。

## MySQL中有哪几种锁

MySQL中从对数据操作的类型分类：

- 读锁（共享锁）：针对同一份数据，多个读操作可以同时进行，不会互相影响

- 写锁（排他锁）：当前写操作没有完成前，它会阻断其他写锁和读锁

从对数据操作的粒度分类:

- 表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低
- 行级锁:开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高
- 页面锁:开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。

MyISAM的表锁有两种模式:

- 表共享读锁 （Table Read Lock）：不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求；
- 表独占写锁 （Table Write Lock）：会阻塞其他用户对同一表的读和写操作；

MyISAM 表的读操作与写操作之间，以及写操作之间是串行的。默认情况下，写锁比读锁具有更高的优先级：当一个锁释放时，这个锁会优先给写锁队列中等候的获取锁请求，然后再给读锁队列中等候的获取锁请求。

InnoDB中实现了两种类型的行锁:

- 共享锁（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。
- 排他锁（X）：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。

为了允许行锁和表锁共存，还有两种内部使用的意向锁（表锁）:

- 意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的 IS 锁。
- 意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的 IX 锁。

| | X | IX | S | IS |
| :-: | :-: | :-: | :-: | :-: |
| X | 冲突 | 冲突 | 冲突 | 冲突 |
| IX | 冲突 | 兼容 | 冲突 | 兼容 |
| S | 冲突 | 冲突 | 兼容 | 兼容 |
| IS | 冲突 | 冲突 | 兼容 | 兼容 |

索引失效会导致行锁变表锁.

MySQL的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然是访问不同行的记录，但是如果是使用相同的索引键，是会出现锁冲突的。

当表有多个索引的时候，不同的事务可以使用不同的索引锁定不同的行，另外，不论是使用主键索引、唯一索引或普通索引，InnoDB都会使用行锁来对数据加锁。

即便在条件中使用了索引字段，但是否使用索引来检索数据是由MySQL通过**判断不同执行计划的代价**来决定的，如果MySQL认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，这种情况下InnoDB将使用表锁，而不是行锁。因此，在分析锁冲突时，别忘了检查SQL的执行计划，以确认是否真正使用了索引。

## 为什么没有意向锁的话，表锁和行锁不能共存？

举个粟子（此时假设行锁和表锁能共存）： 事务A锁住表中的一行（写锁）。事务B锁住整个表（写锁）。

但你就会发现一个很明显的问题，事务A既然锁住了某一行，其他事务就不可能修改这一行。这与”事务B锁住整个表就能修改表中的任意一行“形成了冲突。所以，没有意向锁的时候，行锁与表锁共存就会存在问题！

## 意向锁是如何让表锁和行锁共存的？

有了意向锁之后，前面例子中的事务A在申请行锁（写锁）之前，数据库会自动先给事务A申请表的意向排他锁。当事务B去申请表的写锁时就会失败，因为表上有意向排他锁之后事务B申请表的写锁时会被阻塞。

所以，意向锁的作用就是：

当一个事务在需要获取资源的锁定时，如果该资源已经被排他锁占用，则数据库会自动给该事务申请一个该表的意向锁。如果自己需要一个共享锁定，就申请一个意向共享锁。如果需要的是某行（或者某些行）的排他锁定，则申请一个意向排他锁。

## 意向锁是表锁还是行锁

首先可以肯定的是，意向锁是表级别锁。意向锁是表锁是有原因的。

当我们需要给一个加表锁的时候，我们需要根据意向锁去判断表中有没有数据行被锁定，以确定是否能加成功。如果意向锁是行锁，那么我们就得遍历表中所有数据行来判断。如果意向锁是表锁，则我们直接判断一次就知道表中是否有数据行被锁定了。

## MySQL中InnoDB引擎的行锁是怎么实现的

InnoDB有三种行锁的算法:

- `记录锁(Record Locks)`:单个行记录上的锁。对索引项加锁，锁定符合条件的行。其他事务不能修改和删除加锁项；
- `间隙锁（Gap Locks）`:使用范围条件检索数据并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁。
  eg:`SELECT * FROM table WHERE id BETWEN 1 AND 10 FOR UPDATE;
`所有在(1,10)区间内的记录行都会被锁住.所有id 为 2、3、4、5、6、7、8、9 的数据行的插入会被阻塞，但是 1 和 10 两条记录行并不会被锁住。
  GAP锁的目的，是为了防止同一事务的两次当前读，出现幻读的情况
- `临键锁(Next-key Locks)`:它的封锁范围，既包含索引记录，又包含索引区间。通过临键锁只与非唯一索引列有关.当某个事务持有该数据行的临键锁时，会锁住一段左开右闭区间的数据。

## select for update的含义

`for update`仅适用于InnoDB，且必须在事务块(BEGIN/COMMIT)中才能生效.通过这条语句,MySQL会对查询结果集中每行数据都添加排他锁，其他线程对该记录的更新与删除操作都会阻塞。

只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁

## 获取InnoDB行锁争用情况

可以通过检查InnoDB_row_lock状态变量来分析系统上的行锁的争夺情况：

```
mysql> show status like 'innodb_row_lock%';  
+-------------------------------+-------+  
| Variable_name                 | Value |  
+-------------------------------+-------+  
| InnoDB_row_lock_current_waits | 0     |  
| InnoDB_row_lock_time          | 0     |  
| InnoDB_row_lock_time_avg      | 0     |  
| InnoDB_row_lock_time_max      | 0     |  
| InnoDB_row_lock_waits         | 0     |  
+-------------------------------+-------+  
```

## InnoDB存储引擎中不同SQL在不同隔离级别下锁的比较

<table>
  <tr>
    <td colspan="2">隔离级别 一致性读和锁 SQL </td>
    <td>Read Uncommited</td>
    <td>Read Commited</td>
    <td>Repeatable Read</td>
    <td>Serializable</td>
  </tr>
  <tr>
    <td>SQL</td>
    <td>条件</td>
    <td></td>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td rowspan="2">select</td>
    <td>相等</td>
    <td>None locks</td>
    <td>Consisten read/None lock</td>
    <td>Consisten read/None lock</td>
    <td>Share locks</td>
  </tr>
  <tr>
    <td>范围</td>
    <td>None locks</td>
    <td>Consisten read/None lock</td>
    <td>Consisten read/None lock</td>
    <td>Share Next-Key</td>
  </tr>
  <tr>
    <td rowspan="2">update</td>
    <td>相等</td>
    <td>exclusive locks</td>
    <td>exclusive locks</td>
    <td>exclusive locks</td>
    <td>Exclusive locks</td>
  </tr>
  <tr>
    <td>范围</td>
    <td>exclusive next-key</td>
    <td>exclusive next-key</td>
    <td>exclusive next-key</td>
    <td>exclusive next-key</td>
  </tr>
  <tr>
    <td>insert</td>
    <td>N/A</td>
    <td>exclusive locks</td>
    <td>exclusive locks</td>
    <td>exclusive locks</td>
    <td>Exclusive locks</td>
  </tr>
  <tr>
    <td rowspan="2">replace</td>
    <td>无键冲突</td>
    <td>exclusive locks</td>
    <td>exclusive locks</td>
    <td>exclusive locks</td>
    <td>Exclusive locks</td>
  </tr>
  <tr>
    <td>键冲突</td>
    <td>exclusive next-key</td>
    <td>exclusive next-key</td>
    <td>exclusive next-key</td>
    <td>exclusive next-key</td>
  </tr>
  <tr>
    <td rowspan="2">delete</td>
    <td>相等</td>
    <td>exclusive locks</td>
    <td>exclusive locks</td>
    <td>exclusive locks</td>
    <td>Exclusive locks</td>
  </tr>
  <tr>
    <td>范围</td>
    <td>exclusive next-key</td>
    <td>exclusive next-key</td>
    <td>exclusive next-key</td>
    <td>exclusive next-key</td>
  </tr>
  <tr>
    <td rowspan="2">select ... from ... lock in share mode</td>
    <td>相等</td>
    <td>Share locks</td>
    <td>Share locks</td>
    <td>Share locks</td>
    <td>Share locks</td>
  </tr>
  <tr>
    <td>范围</td>
    <td>Share locks</td>
    <td>Share locks</td>
    <td>share next-key</td>
    <td>share next-key</td>
  </tr>
  <tr>
    <td rowspan="2">select * from ... for update</td>
    <td>相等</td>
    <td>exclusive locks</td>
    <td>exclusive locks</td>
    <td>exclusive locks</td>
    <td>Exclusive locks</td>
  </tr>
  <tr>
    <td>范围</td>
    <td>exclusive locks</td>
    <td>share locks</td>
    <td>exclusive next-key</td>
    <td>exclusive next-key</td>
  </tr>
  <tr>
    <td rowspan="2">insert into ... select ...(指源表锁)</td>
    <td>innodb_locks_unsafe_for_binlog=off</td>
    <td>Share next-key</td>
    <td>Share next-key</td>
    <td>Share next-key</td>
    <td>Share next-key</td>
  </tr>
  <tr>
    <td>innodb_locks_unsafe_for_binlog=on</td>
    <td>none locks</td>
    <td>Consisten read/None lock</td>
    <td>Consisten read/None lock</td>
    <td>Share Next-Key</td>
  </tr>
  <tr>
    <td rowspan="2">create table ... select ...(指源表锁)</td>
    <td>innodb_locks_unsafe_for_binlog=off</td>
    <td>Share next-key</td>
    <td>Share next-key</td>
    <td>Share next-key</td>
    <td>Share next-key</td>
  </tr>
  <tr>
    <td>innodb_locks_unsafe_for_binlog=on</td>
    <td>none locks</td>
    <td>Consisten read/None lock</td>
    <td>Consisten read/None lock</td>
    <td>Share Next-Key</td>
  </tr>
</table>

[InnoDB存储引擎中不同SQL在不同隔离级别下锁的比较](https://www.cnblogs.com/jpfss/p/8890250.html#)

## 数据库死锁怎么处理

1.每个事务都有一个时间阀值，如果该事务超时，那么就回滚该事务。

这样实现简单，但是，如果事务操作很多行，占用了较多的undolog，而另外一个事务占用较少，这样不合适，而且超时不是一种主动检查死锁的方式。

2.使用等待图

比如，row1事务2上写锁，事务1上读锁，那么事务1就要等事务2，就是说事务1指向事务2，可以用深度遍历，如果存在环，那么挑一个undo log量最小的来进行回滚。

## 如何避免死锁

MyISAM避免死锁:

在自动加锁的情况下，MyISAM 总是一次获得 SQL 语句所需要的全部锁，所以 MyISAM 表不会出现死锁。

InnoDB避免死锁:

- 为了在单个InnoDB表上执行多个并发写入操作时避免死锁，可以在事务开始时通过为预期要修改的每个元祖（行）使用SELECT ... FOR UPDATE语句来获取必要的锁，即使这些行的更改语句是在之后才执行的。
- 在事务中，如果要更新记录，应该直接申请足够级别的锁，即排他锁，而不应先申请共享锁、更新时再申请排他锁，因为这时候当用户再申请排他锁时，其他事务可能又已经获得了相同记录的共享锁，从而造成锁冲突，甚至死锁
- 如果事务需要修改或锁定多个表，则应在每个事务中以相同的顺序使用加锁语句。 在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序来访问表，这样可以大大降低产生死锁的机会
- 通过SELECT ... LOCK IN SHARE MODE获取行的读锁后，如果当前事务再需要对该记录进行更新操作，则很有可能造成死锁。
- 改变事务隔离级别

## 数据恢复策略

[数据恢复策略](https://www.cnblogs.com/gxcstyle/p/6881477.html)

系统故障
系统故障的恢复是由系统在重新启动时候自动完成的，不需要用户干预。
系统的恢复步骤是：
（1）正向扫描日志文件（即从头扫描日志文件），找出在故障发生前已经提交的事务（这些事务既有BEGIN TRANSACTION记录，也有COMMIT记录），将其事务标识记入重做（REDO）队列。同时找出故障发生时尚未完成的事务（这些事务只有BEGIN TRANSACTION记录，无相应的COMMIT记录）,将其事务标识记入撤销队列。
（2）对撤销队列中的各个事务进行撤销（UNDO）处理。
进行UNDO处理的方法是，反向扫描日志文件，对每一个UNDO事务的更新操作执行逆操作，将将日志记录中"更新前的值"写入数据库（该方法和事务故障的解决方法一致）。
（3）对重做队列中的各个事务进行重做（REDO）处理。
进行REDO处理的方法是：正向扫描日志文件，对每一个REDO事务从新执行日志文件登记的操作。即将日志记录中"更新后的值"写入数据库。

MySQL的恢复机制要求：在一个事务未提交前，其他并发事务不能插入满足其锁定条件的任何记录，也就是不允许出现幻读

## 日志 

- 错误日志：对MySQL启动，运行，关闭过程进行了记录

- 慢查询日志：帮助DBA定位可能存在问题的SQL语句，进行SQL语句层面的优化

- 查询日志：记录所有对MySQL数据库请求的信息，无论这些请求是否得到了正确的执行。

- 二进制日志：记录对MySQL数据库执行更改的所有操作。

  作用：

  - 恢复：某些数据的恢复需要二进制日志

  - 复制：通过复制和执行二进制日志使一台远程的MySQL数据库和一台MySQL数据库进行实时同步

  - 审计：用户可以通过二进制日志中的信息来进行审计，判断是否有对数据库进行注入的攻击

### bin log和redo log的区别

`binlog`记载的是`update/delete/insert`这样的SQL语句，而`redo log`记载的是物理修改的内容（xxxx页修改了xxx）。`redo log` 记录的是数据的**物理变化**，`binlog` 记录的是数据的**逻辑变化**

### bin log

MySQL的Binlog是按照事务提交的先后顺序记录的，恢复也是按这个顺序进行的。

### undo log

`undo log`主要有两个作用：回滚和多版本控制(MVCC)

`undo log`主要存储的也是逻辑日志，比如我们要`insert`一条数据了，那`undo log`会记录的一条对应的`delete`日志。我们要`update`一条记录时，它会记录一条对应**相反**的update记录。

innodb 通过段的方式来管理 undo log，每一条记录占用一个 undo log segment，每 1024 个 undo log segment 被组织为一个回滚段

#### undo log的写入时机

- DML操作修改聚簇索引前，记录undo日志
- 二级索引记录的修改，不记录undo日志

需要注意的是，undo页面的修改，同样需要记录redo日志。

#### undo log的存储位置

在InnoDB存储引擎中，undo存储在回滚段(Rollback Segment)中,每个回滚段记录了1024个undo log segment，而在每个undo log segment段中进行undo 页的申请，在5.6以前，Rollback Segment是在共享表空间里的，5.6.3之后，可通过 innodb_undo_tablespace设置undo存储的位置。

### redo log 重做日志

Redo log可以简单分为以下两个部分：

- 一是内存中重做日志缓冲 (redo log buffer),是易失的，在内存中

- 二是重做日志文件 (redo log file)，是持久的，保存在磁盘中

#### 什么时候写入?

写入Redo的时机：

- 在数据页修改完成之后，在脏页刷出磁盘之前，写入redo日志。注意的是先修改数据，后写日志

- **redo日志比数据页先写回磁盘**

- 聚集索引、二级索引、undo页面的修改，均需要记录Redo日志。

#### 整体流程

第一步：先将原始数据从磁盘中读入内存中来，修改数据的内存拷贝

第二步：生成一条重做日志并写入redo log buffer，记录的是数据被修改后的值

第三步：当事务commit时，将redo log buffer中的内容刷新到 redo log file，对 redo log file采用追加写的方式

第四步：定期将内存中修改的数据刷新到磁盘中

### binlog和redo log写入的细节

`redo log`**事务开始**的时候，就开始记录每次的变更信息，而`binlog`是在**事务提交**的时候才记录。

于是新有的问题又出现了：我写其中的某一个`log`，失败了，那会怎么办？现在我们的前提是先写`redo log`，再写`binlog`，我们来看看：

- 如果写`redo log`失败了，那我们就认为这次事务有问题，回滚，不再写`binlog`。
- 如果写`redo log`成功了，写`binlog`，写`binlog`写一半了，但失败了怎么办？我们还是会对这次的**事务回滚**，将无效的`binlog`给删除（因为`binlog`会影响从库的数据，所以需要做删除操作）
- 如果写`redo log`和`binlog`都成功了，那这次算是事务才会真正成功。

简单来说：MySQL需要保证`redo log`和`binlog`的**数据是一致**的，如果不一致，那就乱套了。

- 如果`redo log`写失败了，而`binlog`写成功了。那假设内存的数据还没来得及落磁盘，机器就挂掉了。那主从服务器的数据就不一致了。（从服务器通过`binlog`得到最新的数据，而主服务器由于`redo log`没有记载，没法恢复数据）
- 如果`redo log`写成功了，而`binlog`写失败了。那从服务器就拿不到最新的数据了。

MySQL通过**两阶段提交**来保证`redo log`和`binlog`的数据是一致的。

### 为什么有了redo log还需要bin log

- `redo log`的大小是固定的，日志上的记录修改落盘后，日志会被覆盖掉，无法用于数据回滚/数据恢复等操作
- `redo log`是innodb引擎层实现的，并不是所有引擎都有
- `bin log`是server层实现的，意味着所有引擎都可以使用binlog日志
- `bin log`是通过追加的方式写入的，可通过配置参数`max_binlog_size`设置每个binlog文件的大小，当文件大小大于给定值后，日志会发生滚动，之后的日志记录到新的文件上。
- `bin log`有两种记录模式，statement格式的话是记sql语句， row格式会记录行的内容，记两条，更新前和更新后都有。

## 排序

当排序的字段没有索引时，先根据查询条件获取结果集，然后在内存中对这个结果集进行排序，如果结果集数量特别大，还需要将结果集写入到多个文件里，然后单独对每个文件里的数据进行排序，然后在文件之间进行归并，排序完成后在进行 limit 操作。

```
CREATE TABLE `person` (
  `id` int(11) NOT NULL,
  `city` varchar(16) NOT NULL,
  `name` varchar(16) NOT NULL,
  `age` int(11) NOT NULL,
  `addr` varchar(128) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `city` (`city`)
) ENGINE=InnoDB;

select city,name,age from person where city='武汉' order by name limit 100  ;
```
使用 explain 发现该语句会使用 city 索引，并且会有 filesort . 我们分析下该语句的执行流程

- 1.初始化 sortbuffer ，用来存放结果集

- 2.找到 city 索引，定位到 city 等于武汉的第一条记录，获取主键索引ID

- 3.根据 ID 去主键索引上找到对应记录，取出 city,name,age 字段放入 sortbuffer

- 4.在 city 索引取下一个 city 等于武汉的记录的主键ID

- 5.重复上面的步骤，直到所有 city 等于武汉的记录都放入 sortbuffer

- 6.对 sortbuffer 里的数据根据 name 做快速排序

- 7.根据排序结果取前面 1000 条返回

  这里是查询 city,name,age 3个字段，比较少，如果查询的字段较多，则多个列如果都放入 sortbuffer 将占有大量内存空间，另一个方案是只区出待排序的字段和主键放入 sortbuffer 这里是 name 和 id ,排序完成后在根据 id 取出需要查询的字段返回，其实就是时间换取空间的做法，这里通过 max_length_for_sort_data 参数控制，是否采用后面的方案进行排序。

另外如果 sortbuffer 里的条数很多，同样会占有大量的内存空间，可以通过参数 sort_buffer_size 来控制是否需要借助文件进行排序，这里会把 sortbuffer 里的数据放入多个文件里，用归并排序的思路最终输出一个大的文件。

以上方案主要是 name 字段没有加上索引，如果 name 字段上有索引，由于索引在构建的时候已经是有序的了，所以就不需要进行额外的排序流程只需要在查询的时候查出指定的条数就可以了，这将大大提升查询速度。我们现在加一个 city 和 name 的联合索引。

```
alter table person add index city_user(city, name);
```

这样查询过程如下：

- 1.根据 city,name 联合索引定位到 city 等于武汉的第一条记录，获取主键索引ID
- 2.根据 ID 去主键索引上找到对应记录，取出 city,name,age 字段作为结果集返回
- 3.继续重复以上步骤直到 city 不等于武汉，或者条数大于 1000

由于联合所以在构建索引的时候，在 city 等于武汉的索引节点中的数据已经是根据 name 进行排序了的，所以这里只需要直接查询就可，另外这里如果加上 city, name, age 的联合索引，则可以用到索引覆盖，不行到主键索引上进行回表。

总结一下，我们在有排序操作的时候，最好能够让排序字段上建有索引，另外由于查询第一百万条开始的一百条记录，需要过滤掉前面一百万条记录，即使用到索引也很慢，所以可以根据 ID 来进行区分，分页遍历的时候每次缓存上一次查询结果最后一条记录的 id ， 下一次查询加上 id > xxxx limit 0,1000 这样可以避免前期扫描到的结果被过滤掉的情况。

## MySQL中有一条SQL比较慢

回答Pass标准：

1. 先看explain sql， 看看SQL的执行计划。

2. 执行计划中重点关注，走到了哪个索引，如果没有索引，则建立索引

 原因，好的索引可以减少查找全表的数据遍历。

3. 额外能够回答出：关注临时表创建，关注回表，关注索引覆盖，关注驱动表之中的最少一个。 

## explain详解（没写）

[explain详解](https://www.jianshu.com/p/be1c86303c80)

## 主从复制的基本原理

slave会从master读取binlog来进行数据同步

步骤：

- master将改变记录到二进制日志（binary log）。这些记录过程叫做二进制日志事件，binary log events
- slave 将 master 的 binary log events 拷贝到它的中继日志（relay log）;
- slave 重做中继日志中的事件，将改变应用到自己的数据库中。MySQL 复制是异步且是串行化的。

![](https://user-gold-cdn.xitu.io/2020/7/14/1734bff3c7c7b231?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

## MySQL分区分库分表

**分区**：

一般情况下我们创建的表对应一组存储文件，使用MyISAM存储引擎时是一个.MYI和.MYD文件，使用Innodb存储引擎时是一个.ibd和.frm（表结构）文件。

分区是将数据分散到多组存储文件,保证其单个文件的执行效率

作用：

- 逻辑数据分割
- 提高单一的写和读应用速度
- 提高分区范围读查询的速度
- 高效的保存历史数据

分区类型：

- RANGE分区：基于属于一个给定连续区间的列值，把多行分配给分区。根据指定的拆分策略，把数据放在不同的表文件上。
- LIST分区：类似于RANGE分区，区别在于LIST分区中每个分区的定义和选择是基于某列的值从属于一个值列表集中的一个值，而RANGE分区是从属于一个连续区间值的集合。
- HASH分区：基于用户定义的表达式的返回值来进行选择的分区，该表达式使用将要插入到表中的这些行的列值进行计算。
- KEY分区：类似于按HASH分区，区别在于KEY分区只支持计算一列或多列，且MySQL服务器提供其自身的哈希函数。必须有一列或多列包含整数值。

**分表**:

垂直拆分：

通常是按照业务功能的使用频次，把主要的、热门的字段放在一起做为主要表。然后把不常用的，按照各自的业务属性进行聚集，拆分到不同的次要表中；主要表和次要表的关系一般都是一对一的。

水平拆分:

单表的容量不超过500W，否则建议水平拆分。是把一个表复制成同样表结构的不同表，然后把数据按照一定的规则划分，分别存储到这些表中，从而保证单表的容量不会太大，提升性能；当然这些结构一样的表，可以放在一个或多个数据库中。

几种方法:

- 使用MD5哈希
- 根据时间
- 按热度拆分,高点击率的词条生成各自的一张表
- 根据ID的值放入对应的表

**分库**:

一个库里表太多了，导致了海量数据，系统性能下降，把原本存储于一个库的表拆分存储到多个库上， 通常是将表按照功能模块、关系密切程度划分出来，部署到不同库上。

## 分布式数据库数据一致性原理说明与实现（没写）

[分布式数据库数据一致性原理说明与实现](https://cloud.tencent.com/developer/article/1013767)

Raft算法保障的

## Join算法原理（没写）

[Join算法原理](https://zhuanlan.zhihu.com/p/54275505)

![](https://user-gold-cdn.xitu.io/2020/7/14/1734bff37ac0e7f6?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

## SQL truncate,delete与drop区别(没写)

[SQL truncate,delete与drop区别](https://www.cnblogs.com/8765h/archive/2011/11/25/2374167.html)

1. truncate 和 delete 只删除数据不删除表的结构(定义)
   drop 语句将删除表的结构被依赖的约束(constrain)、触发器(trigger)、索引(index)；依赖于该表的存储过程/函数将保留,但是变为 invalid 状态。

2. delete 语句是数据库操作语言(dml)，这个操作会放到 rollback segement 中，事务提交之后才生效；如果有相应的 trigger，执行的时候将被触发。
   truncate、drop 是数据库定义语言(ddl)，操作立即生效，原数据不放到 rollback segment 中，不能回滚，操作不触发 trigger。

## 预编译语句

通常我们的一条sql在db接收到最终执行完毕返回可以分为下面三个过程：

1. 词法和语义解析
2. 优化sql语句，制定执行计划
3. 执行并返回结果

我们把这种普通语句称作**Immediate Statements**。

但是很多情况，我们的一条sql语句可能会反复执行，或者每次执行的时候只有个别的值不同（比如query的where子句值不同，update的set子句值不同,insert的values值不同）。
如果每次都需要经过上面的词法语义解析、语句优化、制定执行计划等，则效率就明显不行了。

所谓预编译语句就是将这类语句中的值用占位符替代，可以视为将sql语句模板化或者说参数化，一般称这类语句叫**Prepared Statements**或者**Parameterized Statements**
预编译语句的优势在于归纳为：**一次编译、多次运行，省去了解析优化等过程；此外预编译语句能防止sql注入。**

# Netty(学习笔记)

## 零拷贝

**定义**：

在操作数据时, 不需要将数据 buffer 从一个内存区域拷贝到另一个内存区域.

### 传统IO模型

DMA(Direct Memory Access，直接存储器访问):

![](https://user-gold-cdn.xitu.io/2020/4/19/17192eabce20cdee?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

这里一共复制了四次，上下文切换了四次。

读操作（复制两次，上下文切换两次）：
1. 用户进程通过 read() 函数向内核（kernel）发起系统调用，上下文从用户态（user space）切换为内核态（kernel space）
2. CPU利用DMA控制器将数据从主存或硬盘拷贝到内核空间（kernel space）的读缓冲区（read buffer）
3. CPU将读缓冲区（read buffer）中的数据拷贝到用户空间（user space）的用户缓冲区（user buffer）
4. 上下文从内核态（kernel space）切换回用户态（user space），read 调用执行返回。

写操作（复制两次，上下文切换两次）：
1. 用户进程通过 write() 函数向内核（kernel）发起系统调用，上下文从用户态（user space）切换为内核态（kernel space）
2. CPU 将用户缓冲区（user buffer）中的数据拷贝到内核空间（kernel space）的网络缓冲区（socket buffer）
3. CPU 利用 DMA 控制器将数据从网络缓冲区（socket buffer）拷贝到网卡进行数据传输
4. 上下文从内核态（kernel space）切换回用户态（user space），write 系统调用执行返回

### 减少内核空间到用户空间的拷贝次数

#### mmap系统调用

和传统的区别就是read操作变成了mmap，之后用户空间会和内核态共享同一块内核缓冲区，读入的数据都在这个内核缓冲区里面。写入的话还是和原来一样。这样,在进行网络传输时，就可以减少内核空间到用户空间的拷贝次数.

![](https://user-gold-cdn.xitu.io/2020/4/19/17192eabce006740?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

#### sendfile系统调用

sendfile对于mmap来说更加优化了一步，数据从缓冲复制到到socket直接都是在内核空间一次性完成的，用户空间只是发起了sendfile的调用，减少了复制和上下文切换的开销。

![](https://user-gold-cdn.xitu.io/2020/4/19/17192eabce189bb9?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

#### splice系统调用

splice又在上面两位前辈的基础上变更更加强大，之前sendfile只能是内核缓冲区向socket复制数据，而splice直接让它和缓冲区和socket之间建立了一个管道可以直接相互交换数据。

![](https://user-gold-cdn.xitu.io/2020/4/19/17192eabd179a71f?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

### 优化Linux页缓存和用户进程的缓存区之间的传输过程

**写时复制**：

如果有多个应用程序需要同时访问同一块数据，那么可以为这些应用程序分配指向这块数据的指针，在每一个应用程序看来，它们都拥有这块数据的一份数据拷贝，当其中一个应用程序需要对自己的这份数据拷贝进行修改的时候，就需要将数据真正地拷贝到该应用程序的地址空间中去。

**Netty 的Zero-copy 体现在如下几个方面**:

- Netty 提供了CompositeByteBuf 类, 它可以将多个 ByteBuf 合并为一个逻辑上的 ByteBuf, 避免了各个 ByteBuf 之间的拷贝.
- 通过 wrap 操作, 我们可以将 byte[] 数组、ByteBuf、ByteBuffer等包装成一个** Netty** ByteBuf 对象, 进而避免了拷贝操作.
- ByteBuf 支持 slice 操作, 因此可以将 ByteBuf 分解为多个共享同一个存储区域的 ByteBuf, 避免了内存的拷贝.
- 通过 FileRegion 包装的FileChannel.tranferTo 实现文件传输, 可以直接将文件缓冲区的数据发送到目标 Channel, 避免了传统通过循环** write** 方式导致的内存拷贝问题.

## Reactor模式

**基本角色**：

- Reactor: 负责响应事件，将事件分发绑定了该事件的Handler处理
- Handler: 事件处理器，绑定了某类事件，负责执行对应事件的任务对事件进行处理
- Acceptor：Handler的一种，绑定了 connect 事件，当客户端发起connect请求时，Reactor会将accept事件分发给Acceptor处理

### 单Reactor单线程

![](https://user-gold-cdn.xitu.io/2018/9/20/165f6bd23ca497e5?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

方案的具体步骤如下:

- Reactor对象通过select监控连接事件，收到事件后通过dispatch进行分发
- 如果是连接建立的事件，则交由 Acceptor 通过accept 处理连接请求，然后创建一个 Handler 对象处理连接完成后的后续业务处理
- 如果不是建立连接事件，则 Reactor 会分发调用连接对应的 Handler来响应
- Handler 会完成 read -> 业务处理 -> send 的完整业务流程

**优点**：

模型简单，没有多线程，进程通信，竞争的问题，全部都在一个线程中完成

**缺点**：

- 只有一个进程，无法发挥多核 CPU的性能，只能采取部署多个系统来利用多核CPU,但这样会带来运维复杂度
- Handler 在处理某个连接上的业务时，整个进程无法处理其他连接的事件，很容易导致性能瓶颈

### 单Reactor多线程

![](https://user-gold-cdn.xitu.io/2018/9/20/165f6bd23cd1ac70?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

方案步骤:

- 主线程中，Reactor对象通过select 监听连接事件，收到事件后通过 dispatch进行分发
- 如果是连接建立的事件，则由Acceptor处理，Acceptor通过 accept接受连接，并创建一个 Handler 来处理连接后续的各种事件。
- 如果不是连接建立事件，则Reactor会调用连接对应的Handler来进行相应
- Handler 只负责响应事件，不进行业务处理，Handler 通过 read 读取到数据后，会发给 processor 进行业务处理
- Processor 会在独立的子线程中完成真正的 业务处理，然后将响应结果发给主进程的 Handler处理，Handler 收到响应后通过 send 将响应结果返回给 client

**优点**:

- 能够充分利用多核多CPU的处理能力

**缺点**：

- 多线程数据共享和访问比较复杂
- Reactor 承担所有事件的监听和响应，只在主线程中运行，瞬间高并发时会成为性能瓶颈

### 多Reactor多进程/线程

![](https://user-gold-cdn.xitu.io/2018/9/20/165f6bd255e9574b?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

方案说明:

- 主进程中mainReactor对象通过 select监控连接建立事件，收到事件后通过 Acceptor接收，将新的连接分配给某个子进程。
- 子进程中的 subReactor 将 mainReactor 分配的连接加入连接队列进行监听，并创建一个 Handler 用于处理连接的各种事件
- 当有新的事件发生时，subReactor 会调用里连接对应的 Handler 来响应
- Handler完成 read -> 业务处理 -> send 的完整业务流程

特点:

- 主进程和子进程的职责非常明确，主进程只负责接收新连接，子进程负责完成后续的业务处理
- 主进程和子进程的交互很简单，主进程只需要把新的连接传递给子进程，子进程无需返回数据
- 子进程之间是相互独立的，无需同步共享之类的处理（这里仅限于网络模型相关的 select,read,send等无须同步共享，"业务处理"还是有可能需要同步共享的）

### Netty中的零拷贝

Netty 的“零拷贝”主要体现在如下三个方面：

1. Netty 的接收和发送 ByteBuffer 采用 DIRECT BUFFERS，使用堆外直接内存进行 Socket 读写，不需要进行字节缓冲区的二次拷贝。如果使用传统的堆内存（HEAP BUFFERS）进行 Socket 读写，JVM 会将堆内存 Buffer 拷贝一份到直接内存中，然后才写入 Socket 中。相比于堆外直接内存，消息在发送过程中多了一次缓冲区的内存拷贝。

2. Netty 提供了组合 Buffer 对象，可以聚合多个 ByteBuffer 对象，用户可以像操作一个 Buffer 那样方便的对组合 Buffer 进行操作，避免了传统通过内存拷贝的方式将几个小 Buffer 合并成一个大的 Buffer。

3. Netty 的文件传输采用了 transferTo 方法，它可以直接将文件缓冲区的数据发送到目标 Channel，避免了传统通过循环 write 方式导致的内存拷贝问题。

## 组件

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a5f98a9134ff48e3aa16e7d266ee4edc~tplv-k3u1fbpfcp-watermark.image)

**Channel**:

可以理解为socket连接，客户端和服务端连接的时候会创建一个channel。负责基本的IO操作.

常见的Channel:

- `NioSocketChannel`: NIO的客户端 TCP Socket 连接
- `NioServerSocketChannel`: NIO的服务器端 TCP Socket 连接
- `NioDatagramChannel`: UDP连接
- `NioSctpChannel`: 客户端Sctp连接

**EventLoopGroup、EventLoop**：

有了Channel连接服务，连接之间消息流动。服务器发出消息称为出站，服务器接受消息称为入站。
那么消息出站和入站就产生了事件例如：连接已激活；数据读取；用户事件；异常事件；打开连接；
关闭连接等等。有了事件，有了事件就需要机制来监控和协调事件，这个机制就是EventLoop。

- 一个EventLoopGroup包含一个或者多个EventLoop
- 一个EventLoop在生命周期内之和一个Thread绑定
- EventLoop上所有的IO事件在它专有的Thread上被处理。
- Channel在它生命周期只注册于一个Event Loop
- 一个Event Loop可能被分配给一个或者多个Channel

**ChannelHandler**：

数据出站和入站的业务逻辑

ChannelInboundHandler ⼊站事件处理器
ChannelOutBoundHandler 出站事件处理器

**ChannelPipeline**:

将ChannelHandler串起来。一个Channel包含一个ChannelPipeline,而ChannelPipeline维护者一个ChannelHandler列表。
ChannelHandler与Channel和ChannelPipeline之间的映射关系，由ChannelHandlerContext进⾏维护。

**Bootstrap**:

是引导作用，配置整个netty程序，将各个组件串起来，最后绑定接口，启动服务。

**Future**:

操作完成时通知应用程序的方式。这个对象可以看做异步操作执行结果占位符，它在将来某个时刻完成，并提供对其结果的访问。

## 主要流程

1. Client发起连接CONNECT请求，boss中的NioEventLoop不断轮循是否有新的客户端请求，如果有，ACCEPT事件触发
2. ACCEPT事件触发后，worker中NioEventLoop会通过NioServerSocketChannel获取到对应的代表客户端的NioSocketChannel，并将其注册到worker中
3. worker中的NioEventLoop不断检测自己管理的NioSocketChannel是否有读写事件准备好，如果有的话，调用对应的ChannelHandler进行处理

![](https://user-gold-cdn.xitu.io/2020/1/13/16f9e268d7430845?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

## WebSocket

- 当使用WebSocket时，服务端可以主动推送信息给客户端了，不必在意客户端等待了多久，不必担心超时断线，解决了被动性问题。
- Websocket只需要一次HTTP交互，来进行协议上的切换，整个通讯过程是建立在一次连接/状态中，也就避免了HTTP的无状态性，服务端会一直知道你的信息，直到你关闭请求，这样就解决了服务端要反复解析HTTP请求头的问题。

![](https://user-gold-cdn.xitu.io/2018/8/11/165297933e4426ae?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

- 建立在TCP协议上
- 与 HTTP 协议有着良好的兼容性。默认端口也是80或443，并且握手阶段采用 HTTP 协议，因此握手时不容易屏蔽，能通过各种 HTTP 代理服务器。
- 它是一种双向通信协议，采用异步回调的方式接受消息，当建立通信连接，可以做到持久性的连接，WebSocket服务器和Browser都能主动的向对方发送或接收数据，实质的推送方式是服务器主动推送，只要有数据就推送到请求方。
- 协议标识符是ws（如果加密，则为wss）

## RPC框架

**是什么**：

RPC就是要像调用本地的函数一样去调远程函数，也就是说两台服务器A，B，一个应用部署在A服务器上，想要调用B服务器上应用提供的函数/方法，由于不在一个内存空间，不能直接调用，需要通过网络来表达调用的语义和传达调用的数据。

[具体看这个回答](https://www.zhihu.com/question/25536695/answer/221638079)

[演变](https://www.zhihu.com/question/25536695/answer/154614906)

# Dubbo



# 设计模式

## 单例模式

双重校验锁实现:

```
public class Singleton {  
    private volatile static Singleton singleton;  
    private Singleton (){}  
    public static Singleton getSingleton() {  
    if (singleton == null) {  
        synchronized (Singleton.class) {  
        if (singleton == null) {  
            singleton = new Singleton();  
        }  
        }  
    }  
    return singleton;  
    }  
}  
```

# 操作系统(Linux)

## cpu负载和cpu利用率的区别

# ElasticSearch

## 全文搜索

全文搜索也叫全文检索，是指扫描文章中的每一个词，对每一个词进建立一个索引，指明该词在文章中出现的次数和位置，当前端用户输入的关键词发起查询请求后，搜索引擎就会根据事先建立的索引进行查找，并将查询的结果响应给用户

## 倒排索引

全文搜索过程根据关键词创建的索引叫倒排索引，建立成“关键词-文本内容”的关系。

## 核心概念

### Index

索引，包含一堆有相似结构的文档数据，索引有一个名称。一个index包含很多document，一个index就代表了一类类似的或者相同的document。

### Document&field

文档，es中的最小数据单元，一个document可以是一条客户数据，一条商品分类数据，一条订单数据，通常用JSON数据结构表示，每个index下的type中，都可以去存储多个document。一个document里面有多个field，每个field就是一个数据字段。

### elasticsearch核心概念vs数据库核心概念

| elasticsearch | 数据库 |
| :-: | :-: |
| Document | 行 |
| Type | 表 |
| Index | 库 |

# 算法题

## 只出现一次的数字(136)

因为剩下的数字只出现两次，一异或就没了

```java
// a^a=0 0^a=a
class Solution {
    public int singleNumber(int[] nums) {
        if(nums.length == 0)
            return 0;
        else {
            int ans = 0;
            for(int i = 0; i < nums.length; i ++) {
                ans ^= nums[i];
            }
            return ans;
        }
    }
}
```

## 阶乘后的零(172)

算0即找有多少对5和2.f(n)=n/5+n/25+n/125...

```
class Solution {
    public int trailingZeroes(int n) {
        int res = 0;
        while(n > 0) {
            n /= 5;
            res += n;
        }
        return res;
    }
}
```

# 还没看完的文章

## MySQL

[史上最详尽，一文讲透 MVCC 实现原理](https://blog.csdn.net/DILIGENT203/article/details/100751755?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&tdsourcetag=s_pctim_aiomsg)

[超全面的MySQL语句加锁分析](https://blog.csdn.net/bjweimengshu/article/details/90056126)

[MySQL事务隔离级别和实现原理（看这一篇文章就够了！）](https://zhuanlan.zhihu.com/p/117476959)
